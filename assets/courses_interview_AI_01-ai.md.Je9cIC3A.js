import{_ as e,o as r,c as a,R as o}from"./chunks/framework.FHZ5yb6k.js";const T=JSON.parse('{"title":"Elasticsearch","description":"","frontmatter":{"title":"Elasticsearch","author":"Se7en","categories":["Interview"],"tags":["AI"]},"headers":[],"relativePath":"courses/interview/AI/01-ai.md","filePath":"courses/interview/AI/01-ai.md","lastUpdated":1730386196000}'),i={name:"courses/interview/AI/01-ai.md"},t=o('<h2 id="为什么模型训练通常需要分布式进行-而分布式模型预测并不常见" tabindex="-1">为什么模型训练通常需要分布式进行，而分布式模型预测并不常见？ <a class="header-anchor" href="#为什么模型训练通常需要分布式进行-而分布式模型预测并不常见" aria-label="Permalink to &quot;为什么模型训练通常需要分布式进行，而分布式模型预测并不常见？&quot;">​</a></h2><p>计算模式不同：</p><ul><li>训练需要各个 worker 保持通信，从而协调统一地更新模型参数。</li><li>预测中的模型参数是固定的，各个 worker 分别使用只读副本，无需相互通信协调。</li></ul><h2 id="ai-集群规模越大越好-大集群拥有大算力" tabindex="-1">AI 集群规模越大越好？大集群拥有大算力？ <a class="header-anchor" href="#ai-集群规模越大越好-大集群拥有大算力" aria-label="Permalink to &quot;AI 集群规模越大越好？大集群拥有大算力？&quot;">​</a></h2><p>集群训练引入通信开销，集群的算力并不是线性增长，增加 GPU 计算节点，并不能线性地提升算力收益。 要想通过 AI 集群提升更多算力，需要优化服务器间通信、拓扑、模型并行、分布式框架等软硬件协同。</p><p>对于网络而言，高速、低延迟的网络可以缩短节点间同步梯度的时间，加快训练过程；对于计算而言，降低不必要的计算资源消耗，使计算节点能够专注于训练任务。</p><h2 id="什么是-tensor-core" tabindex="-1">什么是 Tensor Core？ <a class="header-anchor" href="#什么是-tensor-core" aria-label="Permalink to &quot;什么是 Tensor Core？&quot;">​</a></h2><p>Tensor Core 是英伟达推出专门用于深度学习和 AI 计算的硬件单元。Tensor Core 的设计旨在加速矩阵乘法运算，这在深度学习中是非常常见的计算操作。Tensor Core 主要有以下特点和优势：</p><ul><li>并行计算能力：Tensor Core 能够同时处理多个矩阵乘法运算，从而大幅提高计算效率。</li><li>混合精度计算：Tensor Core 支持混合精度计算，即同时使用浮点 16 位（half-precision）和浮点 32 位（single-precision）数据类型进行计算，以在保证计算精度的同时提高计算速度。</li><li>高性能计算：Tensor Core 具有非常高的计算性能，能够快速处理大规模的神经网络模型和数据集。</li><li>节能优势：由于其高效的并行计算和混合精度计算能力，Tensor Core 在相同计算任务下通常能够比传统的计算单元更节能。</li></ul>',9),s=[t];function n(l,c,_,h,d,p){return r(),a("div",null,s)}const f=e(i,[["render",n]]);export{T as __pageData,f as default};
