import{_ as h}from"./chunks/ArticleMetadata.Et6qEObI.js";import{_ as p,C as g,c as o,o as e,k as n,G as k,P as d,a as A,w as c,b as y,e as u}from"./chunks/framework.BhFhJsV2.js";import"./chunks/md5.Ek22RXBH.js";const H=JSON.parse('{"title":"AI 网关对决：Higress 与 OneAPI 的功能对比","description":"","frontmatter":{"title":"AI 网关对决：Higress 与 OneAPI 的功能对比","author":"Se7en","date":"2025/01/22 22:30","categories":["AI"],"tags":["Higress","AI"]},"headers":[],"relativePath":"blogs/original/2025/05-higress-vs-oneapi.md","filePath":"blogs/original/2025/05-higress-vs-oneapi.md","lastUpdated":1739676107000}'),m={name:"blogs/original/2025/05-higress-vs-oneapi.md"};function I(i,s,b,f,D,F){const l=h,r=g("ClientOnly");return e(),o("div",null,[s[0]||(s[0]=n("h1",{id:"ai-网关对决-higress-与-oneapi-的功能对比",tabindex:"-1"},[A("AI 网关对决：Higress 与 OneAPI 的功能对比 "),n("a",{class:"header-anchor",href:"#ai-网关对决-higress-与-oneapi-的功能对比","aria-label":'Permalink to "AI 网关对决：Higress 与 OneAPI 的功能对比"'},"​")],-1)),k(r,null,{default:c(()=>{var t,a;return[(((t=i.$frontmatter)==null?void 0:t.aside)??!0)&&(((a=i.$frontmatter)==null?void 0:a.showArticleMetadata)??!0)?(e(),y(l,{key:0,article:i.$frontmatter},null,8,["article"])):u("",!0)]}),_:1}),s[1]||(s[1]=d(`<h2 id="什么是-ai-网关" tabindex="-1">什么是 AI 网关？ <a class="header-anchor" href="#什么是-ai-网关" aria-label="Permalink to &quot;什么是 AI 网关？&quot;">​</a></h2><p>AI 网关旨在统一管理与各种大型语言模型（LLMs）的交互。通过提供单一入口点，它解决了使用来自不同供应商的多个 AI 模型所带来的复杂性问题。这不仅简化了访问流程，提高了系统稳定性，还降低了成本，并灵活地利用了不同模型的优势。</p><h2 id="什么是-oneapi" tabindex="-1">什么是 OneAPI？ <a class="header-anchor" href="#什么是-oneapi" aria-label="Permalink to &quot;什么是 OneAPI？&quot;">​</a></h2><p><a href="https://github.com/songquanpeng/one-api" target="_blank" rel="noreferrer">OneAPI</a> 是一个开源的 LLM API 管理 &amp; 分发系统，可以帮助统一管理和转发各类大语言模型（如 DeepSeek 等）的 API 请求。它提供了一个兼容 OpenAI API 格式的统一接口，让用户能够方便地切换和管理不同的 AI 模型服务，同时支持令牌管理、负载均衡等功能。</p><h2 id="什么是-higress" tabindex="-1">什么是 Higress? <a class="header-anchor" href="#什么是-higress" aria-label="Permalink to &quot;什么是 Higress?&quot;">​</a></h2><p><a href="https://github.com/alibaba/higress" target="_blank" rel="noreferrer">Higress</a> 是一款云原生 API 网关，内核基于 Istio 和 Envoy，可以用 Go/Rust/JS 等编写 Wasm 插件，提供了数十个现成的通用插件。Higress 在阿里内部为解决 Tengine reload 对长连接业务有损，以及 gRPC/Dubbo 负载均衡能力不足而诞生。阿里云基于 Higress 构建了云原生 API 网关产品，为大量企业客户提供 99.99% 的网关高可用保障服务能力。</p><p>Higress 同时也能够作为 AI 网关，通过统一的协议对接国内外所有 LLM 模型厂商，同时具备丰富的 AI 可观测、多模型负载均衡/fallback、AI token 流控、AI 缓存等能力。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202502132101971.png" alt=""></p><h2 id="higress-和-oneapi-的对比" tabindex="-1">Higress 和 OneAPI 的对比 <a class="header-anchor" href="#higress-和-oneapi-的对比" aria-label="Permalink to &quot;Higress 和 OneAPI 的对比&quot;">​</a></h2><p>下面的表格从多个维度对比了 OneAPI 和 Higress 之前的差异：</p><table><thead><tr><th style="text-align:left;">差异项</th><th style="text-align:left;">OneAPI</th><th style="text-align:left;">Higress</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>核心功能</strong></td><td style="text-align:left;">AI 网关</td><td style="text-align:left;">具有 AI 网关功能的 API 网关</td></tr><tr><td style="text-align:left;"><strong>维护方式</strong></td><td style="text-align:left;">由个人维护的项目</td><td style="text-align:left;">由阿里云 API 网关团队维护的项目</td></tr><tr><td style="text-align:left;"><strong>系统安全</strong></td><td style="text-align:left;">易受<a href="https://mp.weixin.qq.com/s/cGMVehT-8QSKLwbNLnFdHQ" target="_blank" rel="noreferrer">安全漏洞</a>影响，如 DockerHub 镜像被注入加密挖矿脚本</td><td style="text-align:left;">商业版由阿里云托管，无此风险；开源版本集成了阿里云容器镜像服务以存储镜像，提供安全扫描和自动阻止风险镜像的功能</td></tr><tr><td style="text-align:left;"><strong>内容安全</strong></td><td style="text-align:left;">无</td><td style="text-align:left;">通过集成阿里云内容安全实现实时内容过滤，同时支持数据脱敏等功能</td></tr><tr><td style="text-align:left;"><strong>模型管理</strong></td><td style="text-align:left;">只有模型和 API Key 配置管理</td><td style="text-align:left;">支持 API Key 管理（多密钥轮询、屏蔽不可用密钥）、消费者管理（API Key 二级分发、访问控制）、兜底模型以及模型灰度发布。</td></tr><tr><td style="text-align:left;"><strong>可观测性</strong></td><td style="text-align:left;">无</td><td style="text-align:left;">提供监控仪表板用于查看模型及消费者令牌消耗和调用延迟。提供全面的可观测性，包括内容安全、速率限制和缓存的监控。</td></tr><tr><td style="text-align:left;"><strong>可扩展性</strong></td><td style="text-align:left;">无</td><td style="text-align:left;">插件市场提供了现成插件（提示词模板、AI缓存、数据脱敏、内容安全），支持自定义插件开发及热加载。</td></tr><tr><td style="text-align:left;"><strong>云集成</strong></td><td style="text-align:left;">无</td><td style="text-align:left;">可以和阿里云上的各类云产品集成，例如借助 SLS 实现 AI <a href="https://mp.weixin.qq.com/s/0NokzM9SGPkAJgl0c9JiEA" target="_blank" rel="noreferrer">数据分析能力</a></td></tr></tbody></table><h2 id="higress-作为-ai-网关的优势" tabindex="-1"><strong>Higress 作为 AI 网关的优势</strong> <a class="header-anchor" href="#higress-作为-ai-网关的优势" aria-label="Permalink to &quot;**Higress 作为 AI 网关的优势**&quot;">​</a></h2><p>Higress 作为 AI 网关，具备以下几大优势：</p><ul><li><strong>统一管理与灵活扩展</strong>：Higress 提供一个集中的入口，能够统一管理多个大型语言模型（LLMs），简化了与不同供应商模型的接入和配置，支持灵活扩展，方便在需求变化时加入新的模型。</li><li><strong>高可用性与稳定性</strong>：Higress 通过自动故障转移机制，确保当某个 AI 模型服务不可用时，能够快速切换到备选模型，保持系统的高可用性和稳定性，极大减少了服务中断的风险。</li><li><strong>AI 缓存</strong>：Higress 支持将 AI 模型的结果缓存在 Elasticsearch、Redis、Weaviate 等数据库中。这样不仅可以在后续处理相似问题的请求时快速返回结果，还能减少 LLM 调用的费用开销。</li><li><strong>意图识别</strong>：Higress 能根据用户需求智能地选择最合适的 LLM，从而在不同场景下提供最佳响应。</li><li><strong>API Key 治理</strong>：支持配置 API Key 池实现多 Key 均衡，API Key 被限流等不可用情况会自动屏蔽，并在可用时自动恢复。</li><li><strong>消费者管理</strong>：可以通过创建消费者，实现 API Key 的二次分租，无需将真正的供应商 API Key 暴露给调用方，并且可以精细化管理不同消费者的调用权限和调用额度。</li><li><strong>强大的可观测性</strong>：Higress 提供关于模型性能、令牌使用情况及安全相关指标的详细洞察，帮助团队全面监控系统健康状况。</li><li><strong>云原生集成</strong>：与阿里云服务紧密集成，Higress 提供了托管的云原生 API 网关选项，简化了云环境中的部署与管理。</li><li><strong>内容安全</strong>：Higress 集成了阿里云内容安全技术，为 AI 内容提供强大的安全保障。</li></ul><h2 id="快速体验-higress-ai-网关" tabindex="-1">快速体验 Higress AI 网关 <a class="header-anchor" href="#快速体验-higress-ai-网关" aria-label="Permalink to &quot;快速体验 Higress AI 网关&quot;">​</a></h2><p>Higress AI 网关支持一行命令安装：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">curl</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> -sS</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> https://higress.cn/ai-gateway/install.sh</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;"> bash</span></span></code></pre></div><p>执行完命令后可以通过命令行初始化配置，可以看到，Higress 的 AI 网关能力支持对接国内外所有主流 LLM 模型供应商：</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202502132048127.png" alt=""></p><p>也可以选择跳过这个步骤，到 Higress 的控制台进行配置对应供应商的 API Key：</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202502132048913.png" alt=""></p><p>配置后，就可以直接使用了，例如使用 OpenAI 的 SDK：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> json</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">xxxxx, </span><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 👉 可以通过 Higress 生成消费者 Key 实现 API Key 的二次分租</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;http://127.0.0.1:8080/v1&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> client.chat.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;deepseek-chat&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#6A737D;--shiki-dark:#768390;"># 👉 可以填写任意模型名称，Higress 会根据模型名称路由到对应的 LLM 供应商</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">[</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">        {</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">&quot;你好&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">    ],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#F69D50;">    stream</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> chunk </span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> completion:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">(chunk.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;">].delta)</span></span></code></pre></div><p>可以在监控面板看到每个模型，以及每个消费者的 token 消耗情况以及调用延时：</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202502132049888.png" alt=""></p><h2 id="参考链接" tabindex="-1">参考链接 <a class="header-anchor" href="#参考链接" aria-label="Permalink to &quot;参考链接&quot;">​</a></h2><ul><li>Higress：<a href="https://github.com/alibaba/higress" target="_blank" rel="noreferrer">https://github.com/alibaba/higress</a></li><li>OneAPI：<a href="https://github.com/songquanpeng/one-api" target="_blank" rel="noreferrer">https://github.com/songquanpeng/one-api</a></li></ul>`,27))])}const q=p(m,[["render",I]]);export{H as __pageData,q as default};
