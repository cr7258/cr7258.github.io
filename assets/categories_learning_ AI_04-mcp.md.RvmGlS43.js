import{_ as s}from"./chunks/ArticleMetadata.Yw6SSleQ.js";import{_ as n,D as c,o as a,c as p,I as h,w as d,k as l,a as m,R as g,b as u,e as C}from"./chunks/framework.FHZ5yb6k.js";import"./chunks/md5.0oexlRJv.js";const I=JSON.parse('{"title":"Model Context Protocol（MCP）","description":"","frontmatter":{"title":"Model Context Protocol（MCP）","author":"Se7en","categories":["AI"],"tags":["AI","MCP"]},"headers":[],"relativePath":"categories/learning/ AI/04-mcp.md","filePath":"categories/learning/ AI/04-mcp.md","lastUpdated":1736243876000}'),P={name:"categories/learning/ AI/04-mcp.md"},k=l("h1",{id:"model-context-protocol-mcp-模型上下文协议",tabindex:"-1"},[m("Model Context Protocol（MCP，模型上下文协议） "),l("a",{class:"header-anchor",href:"#model-context-protocol-mcp-模型上下文协议","aria-label":'Permalink to "Model Context Protocol（MCP，模型上下文协议）"'},"​")],-1),M=g(`<h2 id="什么是-mcp" tabindex="-1">什么是 MCP？ <a class="header-anchor" href="#什么是-mcp" aria-label="Permalink to &quot;什么是 MCP？&quot;">​</a></h2><p>模型上下文协议（MCP）是 Anthropic 推出的开放标准，旨在通过统一的客户端-服务器架构解决 LLM 应用与数据源连接的难题。它支持通过同一协议访问本地资源（如数据库、文件）和远程资源（如 Slack、GitHub API）。</p><h2 id="mcp-架构" tabindex="-1">MCP 架构 <a class="header-anchor" href="#mcp-架构" aria-label="Permalink to &quot;MCP 架构&quot;">​</a></h2><p>MCP 遵循客户端-服务器架构（client-server），其中：</p><ul><li><strong>MCP 主机（MCP Hosts）</strong>：希望通过 MCP 访问资源的程序（例如 Claude Desktop、IDE 或 AI 工具），用于发起连接。</li><li><strong>MCP 客户端（MCP Clients）</strong>：与服务器保持 1:1 连接的协议客户端。</li><li><strong>MCP 服务器（MCP Servers）</strong>：轻量级程序，每个程序都通过标准化模型上下文协议公开特定功能。为客户端提供上下文、工具和 prompt 信息。</li><li><strong>本地资源（Local Resources）</strong>：你的计算机资源中可供 MCP 服务器安全访问的资源（数据库、文件、服务）。</li><li><strong>远程资源（Remote Resources）</strong>：MCP 服务器可以连接到的互联网资源（例如通过 API）。</li></ul><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202501021941097.png" alt=""></p><h2 id="mcp-client" tabindex="-1">MCP Client <a class="header-anchor" href="#mcp-client" aria-label="Permalink to &quot;MCP Client&quot;">​</a></h2><p>MCP client 的工作流程如下：</p><ul><li>MCP client 首先从 MCP server 获取可用的工具列表。</li><li>将用户的查询连同工具描述通过 <a href="https://platform.openai.com/docs/guides/function-calling" target="_blank" rel="noreferrer">function calling</a> 一起发送给 LLM。</li><li>LLM 决定是否需要使用工具以及使用哪些工具。</li><li>如果需要使用工具，MCP client 会通过 MCP server 执行相应的工具调用。</li><li>工具调用的结果会被发送回 LLM。</li><li>LLM 基于所有信息生成自然语言响应。</li><li>最后将响应展示给用户。</li></ul><p><a href="./(https://github.com/cr7258/hands-on-lab/tree/main/ai/claude/mcp/client/mcp-client)">以下代码</a>使用的是 OpenAI 作为 LLM。<a href="https://modelcontextprotocol.io/quickstart/client" target="_blank" rel="noreferrer">官方示例使用的是 Claude</a>。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#ADBAC7;"> OPENAI_API_KEY</span><span style="--shiki-light:#D73A49;--shiki-dark:#F47067;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;">sk-xxx</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">uv</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> client-openai.py</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> ../../server/weather/src/weather/server.py</span></span></code></pre></div><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202501031826596.png" alt=""></p><h2 id="mcp-学习资料" tabindex="-1">MCP 学习资料 <a class="header-anchor" href="#mcp-学习资料" aria-label="Permalink to &quot;MCP 学习资料&quot;">​</a></h2><table><thead><tr><th>资料</th><th>描述</th></tr></thead><tbody><tr><td><a href="https://github.com/punkpeye/awesome-mcp-servers" target="_blank" rel="noreferrer">awesome-mcp-servers</a><br><a href="https://github.com/modelcontextprotocol/servers" target="_blank" rel="noreferrer">Model Context Protocol Servers</a></td><td>MCP Server 汇总</td></tr></tbody></table><h2 id="参考资料" tabindex="-1">参考资料 <a class="header-anchor" href="#参考资料" aria-label="Permalink to &quot;参考资料&quot;">​</a></h2><ul><li><a href="https://mp.weixin.qq.com/s/ASmcjW53HKokdYt1m-xyXA" target="_blank" rel="noreferrer">深度解析：Anthropic MCP 协议</a></li><li><a href="https://www.anthropic.com/news/model-context-protocol" target="_blank" rel="noreferrer">Introducing the Model Context Protocol</a></li><li><a href="https://sspai.com/post/94360" target="_blank" rel="noreferrer">Claude 的 MCP (模型上下文协议）有啥用？</a></li><li><a href="https://www.bilibili.com/video/BV1H5z3YzEii" target="_blank" rel="noreferrer">Claude MCP：claude开源万能数据插头MCP协议</a></li><li><a href="https://www.100ai.xyz/mcpservers" target="_blank" rel="noreferrer">MCP Server 汇总</a></li><li><a href="https://spring.io/blog/2024/12/11/spring-ai-mcp-announcement" target="_blank" rel="noreferrer">Announcing Spring AI MCP: A Java SDK for the Model Context Protocol</a></li><li><a href="https://mp.weixin.qq.com/s/Fg59pSdVIGTjDyEC3pAWXQ" target="_blank" rel="noreferrer">Spring AI 智能体通过 MCP 集成本地文件数据</a></li><li><a href="https://github.com/punkpeye/awesome-mcp-servers" target="_blank" rel="noreferrer">awesome-mcp-servers</a></li><li>Claude高级玩法：MCP多工具组合，自动化工作流搭建指南 | GitHub、SQLite、Fetch、Filesystem等: <a href="https://www.youtube.com/watch?v=EMfBscUM2v8" target="_blank" rel="noreferrer">https://www.youtube.com/watch?v=EMfBscUM2v8</a></li></ul>`,16);function f(e,b,_,w,A,v){const i=s,o=c("ClientOnly");return a(),p("div",null,[k,h(o,null,{default:d(()=>{var t,r;return[(((t=e.$frontmatter)==null?void 0:t.aside)??!0)&&(((r=e.$frontmatter)==null?void 0:r.showArticleMetadata)??!0)?(a(),u(i,{key:0,article:e.$frontmatter},null,8,["article"])):C("",!0)]}),_:1}),M])}const S=n(P,[["render",f]]);export{I as __pageData,S as default};
