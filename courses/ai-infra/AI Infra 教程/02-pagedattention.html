<!DOCTYPE html>
<html lang="zh" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>vLLM 核心技术 PagedAttention 原理详解 | Se7en的架构笔记</title>
    <meta name="description" content="个人技术知识库，记录 & 分享个人碎片化、结构化、体系化的技术知识内容。">
    <meta name="generator" content="VitePress v1.0.0-rc.31">
    <link rel="preload stylesheet" href="/assets/style.Dd95PEZQ.css" as="style">
    
    <script type="module" src="/assets/app.BnRTcjTY.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Bu8hRsVA.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.PU6D6dP3.js">
    <link rel="modulepreload" href="/assets/chunks/theme.Bm6wu3x-.js">
    <link rel="modulepreload" href="/assets/chunks/md5.BwKp3kP6.js">
    <link rel="modulepreload" href="/assets/chunks/use-popup-manager.Dyp0-4xE.js">
    <link rel="modulepreload" href="/assets/chunks/DirectoryList.ByNdyoTq.js">
    <link rel="modulepreload" href="/assets/chunks/ArticleMetadata.CHA3f0eO.js">
    <link rel="modulepreload" href="/assets/courses_ai-infra_AI Infra 教程_02-pagedattention.md.CIYNRQGM.lean.js">
    <link rel="icon" href="/favicon.ico">
    <meta name="author" content="Se7en">
    <meta name="keywords" content="Se7en的架构笔记, 知识库, 博客, Se7en">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="theme-color" content="#3c8772">
    <meta property="og:type" content="website">
    <meta property="og:locale" content="zh_CN">
    <meta property="og:title" content="Se7en的架构笔记">
    <meta property="og:description" content="个人技术知识库，记录 &amp; 分享个人碎片化、结构化、体系化的技术知识内容。">
    <meta property="og:site" content="https://blog.charles7c.top">
    <meta property="og:site_name" content="Se7en的架构笔记">
    <meta property="og:image" content="https://blog.charles7c.top/logo.jpg">
    <script>var _hmt=_hmt||[];(function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?53af4b1a12fbe40810ca7ad39f8db9c7";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)})();</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9ba95e2><!--[--><!--]--><!--[--><span tabindex="-1" data-v-d4c7870c></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-d4c7870c> Skip to content </a><!--]--><!----><header class="VPNav" data-v-a9ba95e2 data-v-1afe695c><div class="VPNavBar" data-v-1afe695c data-v-ca562552><div class="container" data-v-ca562552><div class="title" data-v-ca562552><div class="VPNavBarTitle has-sidebar" data-v-ca562552 data-v-845133fb><a class="title" href="/" data-v-845133fb><!--[--><!--]--><!--[--><img class="VPImage logo" src="/logo.png" alt data-v-c7369dbe><!--]--><!--[-->Se7en的架构笔记<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-ca562552><div class="curtain" data-v-ca562552></div><div class="content-body" data-v-ca562552><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ca562552><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg class="DocSearch-Search-Icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ca562552 data-v-9ea1c0bb><span id="main-nav-aria-label" class="visually-hidden" data-v-9ea1c0bb>Main Navigation</span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-9ea1c0bb data-v-87c644b9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-87c644b9><span class="text" data-v-87c644b9><!----><span data-v-87c644b9>博客</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-87c644b9><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-87c644b9><div class="VPMenu" data-v-87c644b9 data-v-100612c1><div class="items" data-v-100612c1><!--[--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/blogs/original/index" data-v-5a986eae><!--[-->原创<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/blogs/translate/index" data-v-5a986eae><!--[-->翻译<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-9ea1c0bb data-v-87c644b9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-87c644b9><span class="text" data-v-87c644b9><!----><span data-v-87c644b9>我的分类</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-87c644b9><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-87c644b9><div class="VPMenu" data-v-87c644b9 data-v-100612c1><div class="items" data-v-100612c1><!--[--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/categories/issues/index" data-v-5a986eae><!--[-->Bug万象集<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/categories/fragments/index" data-v-5a986eae><!--[-->个人速查手册<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/categories/tools/index" data-v-5a986eae><!--[-->精选工具箱<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/categories/open-source/index" data-v-5a986eae><!--[-->开源项目<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/categories/learning/index" data-v-5a986eae><!--[-->学习笔记<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-9ea1c0bb data-v-87c644b9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-87c644b9><span class="text" data-v-87c644b9><!----><span data-v-87c644b9>我的小册</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-87c644b9><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-87c644b9><div class="VPMenu" data-v-87c644b9 data-v-100612c1><div class="items" data-v-100612c1><!--[--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link active" href="/courses/ai-infra/index" data-v-5a986eae><!--[-->AI Infra 教程<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/courses/elastic-stack/index" data-v-5a986eae><!--[-->Elastic Stack 实战教程<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/courses/observability/index" data-v-5a986eae><!--[-->Observability 教程<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/courses/interview/index" data-v-5a986eae><!--[-->面试宝典<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/courses/algorithm/index" data-v-5a986eae><!--[-->数据结构与算法<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/tags" tabindex="0" data-v-9ea1c0bb data-v-79d93176><!--[--><span data-v-79d93176>我的标签</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/archives" tabindex="0" data-v-9ea1c0bb data-v-79d93176><!--[--><span data-v-79d93176>我的归档</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-9ea1c0bb data-v-87c644b9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-87c644b9><span class="text" data-v-87c644b9><!----><span data-v-87c644b9>关于</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-87c644b9><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-87c644b9><div class="VPMenu" data-v-87c644b9 data-v-100612c1><div class="items" data-v-100612c1><!--[--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/about/index" data-v-5a986eae><!--[-->关于知识库<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-100612c1 data-v-5a986eae><a class="VPLink link" href="/about/me" data-v-5a986eae><!--[-->关于我<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-ca562552 data-v-78a55203 data-v-87c644b9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-87c644b9><span class="text" data-v-87c644b9><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="option-icon" data-v-87c644b9><path d="M0 0h24v24H0z" fill="none"></path><path d=" M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z " class="css-c4d79v"></path></svg><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-87c644b9><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-87c644b9><div class="VPMenu" data-v-87c644b9 data-v-100612c1><!----><!--[--><!--[--><div class="items" data-v-78a55203><p class="title" data-v-78a55203>中文</p><!--[--><div class="VPMenuLink" data-v-78a55203 data-v-5a986eae><a class="VPLink link" href="/en/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/02-pagedattention" data-v-5a986eae><!--[-->English<!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-ca562552 data-v-a70b4fa7><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-a70b4fa7 data-v-8fe015a8 data-v-d0868b80><span class="check" data-v-d0868b80><span class="icon" data-v-d0868b80><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-8fe015a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-8fe015a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ca562552 data-v-108f13b8 data-v-8465e2a2><!--[--><a class="VPSocialLink no-icon" href="https://github.com/cr7258/cr7258.github.io" aria-label="github" target="_blank" rel="noopener" data-v-8465e2a2 data-v-adf4ea02><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ca562552 data-v-731eb830 data-v-87c644b9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-87c644b9><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-87c644b9><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-87c644b9><div class="VPMenu" data-v-87c644b9 data-v-100612c1><!----><!--[--><!--[--><div class="group translations" data-v-731eb830><p class="trans-title" data-v-731eb830>中文</p><!--[--><div class="VPMenuLink" data-v-731eb830 data-v-5a986eae><a class="VPLink link" href="/en/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/02-pagedattention" data-v-5a986eae><!--[-->English<!--]--></a></div><!--]--></div><div class="group" data-v-731eb830><div class="item appearance" data-v-731eb830><p class="label" data-v-731eb830>切换日光/暗黑模式</p><div class="appearance-action" data-v-731eb830><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-731eb830 data-v-8fe015a8 data-v-d0868b80><span class="check" data-v-d0868b80><span class="icon" data-v-d0868b80><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-8fe015a8><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-8fe015a8><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-731eb830><div class="item social-links" data-v-731eb830><div class="VPSocialLinks social-links-list" data-v-731eb830 data-v-8465e2a2><!--[--><a class="VPSocialLink no-icon" href="https://github.com/cr7258/cr7258.github.io" aria-label="github" target="_blank" rel="noopener" data-v-8465e2a2 data-v-adf4ea02><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ca562552 data-v-603a7519><span class="container" data-v-603a7519><span class="top" data-v-603a7519></span><span class="middle" data-v-603a7519></span><span class="bottom" data-v-603a7519></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav reached-top" data-v-a9ba95e2 data-v-dc514f15><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-dc514f15><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-dc514f15><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-dc514f15>文章</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-dc514f15 data-v-aad35ce9><button data-v-aad35ce9>返回顶部</button><!----></div></div><aside class="VPSidebar" data-v-a9ba95e2 data-v-f729279a><div class="curtain" data-v-f729279a></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-f729279a><span class="visually-hidden" id="sidebar-aria-label" data-v-f729279a> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-f729279a><section class="VPSidebarItem level-0 collapsible has-active" data-v-f729279a data-v-be12326c><div class="item" role="button" tabindex="0" data-v-be12326c><div class="indicator" data-v-be12326c></div><h2 class="text" data-v-be12326c>AI Infra 教程 (4篇)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-be12326c><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-be12326c><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-be12326c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-be12326c data-v-be12326c><div class="item" data-v-be12326c><div class="indicator" data-v-be12326c></div><a class="VPLink link link" href="/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/01-vllm-quickstart" data-v-be12326c><!--[--><p class="text" data-v-be12326c><div class="text-color-red mr-[6px]" style="font-weight: 550; display: inline-block;">1</div>vLLM 快速部署指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-be12326c data-v-be12326c><div class="item" data-v-be12326c><div class="indicator" data-v-be12326c></div><a class="VPLink link link" href="/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/02-pagedattention" data-v-be12326c><!--[--><p class="text" data-v-be12326c><div class="text-color-orange mr-[6px]" style="font-weight: 550; display: inline-block;">2</div>vLLM 核心技术 PagedAttention 原理详解</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-be12326c data-v-be12326c><div class="item" data-v-be12326c><div class="indicator" data-v-be12326c></div><a class="VPLink link link" href="/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/03-prefix-caching" data-v-be12326c><!--[--><p class="text" data-v-be12326c><div class="text-color-yellow mr-[6px]" style="font-weight: 550; display: inline-block;">3</div>Prefix Caching 详解：实现 KV Cache 的跨请求高效复用</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-be12326c data-v-be12326c><div class="item" data-v-be12326c><div class="indicator" data-v-be12326c></div><a class="VPLink link link" href="/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/04-speculative-decoding" data-v-be12326c><!--[--><p class="text" data-v-be12326c><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">4</div>Speculative Decoding 推测解码方案详解</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9ba95e2 data-v-b672dd29><div class="VPDoc has-sidebar has-aside" data-v-b672dd29 data-v-2a93c244><!--[--><!--]--><div class="container" data-v-2a93c244><div class="aside" data-v-2a93c244><div class="aside-curtain" data-v-2a93c244></div><div class="aside-container" data-v-2a93c244><div class="aside-content" data-v-2a93c244><div class="VPDocAside" data-v-2a93c244 data-v-d46a3164><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-d46a3164 data-v-515af6cc><div class="content" data-v-515af6cc><div class="outline-marker" data-v-515af6cc></div><div class="outline-title" role="heading" aria-level="2" data-v-515af6cc>目录</div><nav aria-labelledby="doc-outline-aria-label" data-v-515af6cc><span class="visually-hidden" id="doc-outline-aria-label" data-v-515af6cc> Table of Contents for current page </span><ul class="root" data-v-515af6cc data-v-65fb6e81><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-d46a3164></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-2a93c244><div class="content-container" data-v-2a93c244><!--[--><!--]--><!----><main class="main" data-v-2a93c244><div style="position:relative;" class="vp-doc _courses_ai-infra_AI%20Infra%20%E6%95%99%E7%A8%8B_02-pagedattention" data-v-2a93c244><div><h1 id="vllm-核心技术-pagedattention-原理详解" tabindex="-1">vLLM 核心技术 PagedAttention 原理详解 <a class="header-anchor" href="#vllm-核心技术-pagedattention-原理详解" aria-label="Permalink to &quot;vLLM 核心技术 PagedAttention 原理详解&quot;">​</a></h1><!----><p>本文是 vLLM 系列文章的第 2 篇，介绍 vLLM 核心技术 PagedAttention 的设计理念与实现机制。</p><p>vLLM PagedAttention 论文精读视频可以在这里观看：<a href="https://www.bilibili.com/video/BV1GWjjzfE1b" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1GWjjzfE1b</a></p><p>往期文章：</p><ul><li><a href="https://mp.weixin.qq.com/s/rVW6jjLQabHGMMwnbIzB7Q" target="_blank" rel="noreferrer">vLLM 快速部署指南</a></li></ul><h2 id="_1-引言-为什么大模型推理的内存管理如此关键" tabindex="-1">1 引言：为什么大模型推理的内存管理如此关键？ <a class="header-anchor" href="#_1-引言-为什么大模型推理的内存管理如此关键" aria-label="Permalink to &quot;1 引言：为什么大模型推理的内存管理如此关键？&quot;">​</a></h2><p>随着大语言模型（LLM）在聊天机器人、代码补全、智能问答等场景中的广泛应用，越来越多的公司开始将其作为核心服务进行部署。但运行这类模型的成本极高。相比传统的关键词搜索请求，处理一次 LLM 推理的代价可能高出十倍以上，而背后的主要成本之一，正是 GPU 内存的使用效率。</p><p>在大多数主流 LLM 中，推理过程需要缓存每一步生成过程中的 Key 和 Value 向量（即 KV Cache），以便后续生成阶段引用。这部分缓存并不会随模型权重一起常驻 GPU，而是随着用户请求的长度动态增长和释放。在高并发场景下，不合理的 KV Cache 管理方式会导致大量内存碎片和资源浪费，最终限制可并发处理的请求数量，拉低整体吞吐量。</p><p>为了解决这一瓶颈，vLLM 引入了一个全新的注意力机制 —— <strong>PagedAttention</strong>。它借鉴了操作系统中的虚拟内存分页技术，将 KV Cache 分块存储在非连续的内存地址中，配合 block-level 的共享与 copy-on-write 机制，极大提升了内存利用率，从而显著提高了模型的吞吐能力。</p><p>vLLM 团队将 vLLM 的推理吞吐量与 <a href="https://huggingface.co/docs/transformers/main_classes/text_generation" target="_blank" rel="noreferrer">HuggingFace Transformers（HF）</a> 和 <a href="https://github.com/huggingface/text-generation-inference" target="_blank" rel="noreferrer">HuggingFace Text Generation Inference（TGI）</a> 进行了对比。评估在两种硬件设置下进行：在 NVIDIA A10G GPU 上运行 LLaMA-7B 模型，以及在 NVIDIA A100（40GB）GPU 上运行 LLaMA-13B 模型。实验结果表明，与 HF 相比，vLLM 的吞吐量最高可达 24 倍，与 TGI 相比，吞吐量最高可达 3.5 倍。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505272016382.png" alt=""></p><p>本文将结合 PagedAttention 的论文<a href="https://arxiv.org/abs/2309.06180" target="_blank" rel="noreferrer">《Efficient Memory Management for Large Language Model Serving with PagedAttention》</a>，深入解析 PagedAttention 的设计理念与实现细节，并说明它是如何有效缓解内存瓶颈，显著提升大模型推理性能的。</p><h2 id="_2-背景知识-llm-推理中-kv-cache-的角色" tabindex="-1">2 背景知识：LLM 推理中 KV Cache 的角色 <a class="header-anchor" href="#_2-背景知识-llm-推理中-kv-cache-的角色" aria-label="Permalink to &quot;2 背景知识：LLM 推理中 KV Cache 的角色&quot;">​</a></h2><p>在大语言模型（LLM）如 GPT、OPT、LLaMA 的推理过程中，一个关键机制是<strong>自回归生成（autoregressive generation）</strong>。这意味着模型会基于用户提供的 prompt（提示词），逐步生成下一个 token，每一步都依赖之前生成的 token。这种生成方式的效率，极大依赖于 Transformer 架构中的<strong>自注意力机制（self-attention）</strong>。</p><p>在 self-attention 中，模型为每个 token 计算三个向量：<strong>Query（Q）</strong>、<strong>Key（K）</strong> 和 <strong>Value（V）</strong>。每生成一个新 token，模型会将当前的 Query 向量与之前所有 token 的 Key 向量进行点积计算注意力分数，再据此对 Value 向量做加权求和。这种计算需要频繁访问此前的 token 信息。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505270815621.png" alt=""></p><p>为了避免重复计算这些历史 Key 和 Value 向量，推理系统通常会将它们缓存下来，称为 <strong>KV Cache（Key-Value 缓存）</strong>。这不仅节省了大量重复计算，也显著提升了推理效率。</p><p>推理过程可以划分为两个阶段：</p><ul><li><p><strong>prefill 阶段</strong>：模型接收完整的用户输入 prompt，并一次性并行计算所有 token 的 Query、Key 和 Value 向量。这一阶段是高度并行的，能够充分利用 GPU 的算力资源，因此属于 <strong>compute-bound（计算受限）</strong>，瓶颈在于算力而非内存。</p></li><li><p><strong>decode 阶段</strong>：此阶段模型开始逐个 token 地生成输出。每一步仅处理一个新的 token，模型首先计算其对应的 Query、Key 和 Value 向量。当前 token 的 Query 会与历史及当前的 Key 向量进行点积计算，通过 softmax 得到 attention 权重后，再与历史及当前的 Value 向量进行加权求和，得到当前 token 的 attention 输出。随后，当前步骤产生的 Key 和 Value 向量会被追加写入 KV Cache，以供后续使用。由于该过程是串行的、难以并行加速，且频繁读写缓存数据，因此整体表现为 <strong>memory-bound（内存受限）</strong>，瓶颈主要在 KV Cache 的存储与访问效率。</p></li></ul><p>可以看出，prefill 阶段更侧重于并行计算，而 decode 阶段的性能很大程度上取决于 KV Cache 的内存管理能力。随着生成的 token 数量增加，KV Cache 会线性增长，并逐步占据大量 GPU 显存。</p><p>下图展示了一个 13B 参数规模的大语言模型在 NVIDIA A100 40GB 显存 GPU 上推理时的显存使用分布。其中：</p><ul><li><strong>Parameters（26GB, 65%）</strong>：指模型的权重参数，这部分在加载模型后常驻显存，大小固定；</li><li><strong>KV Cache（&gt;30%）</strong>：用于存储每个请求的历史 Key 和 Value 向量，随着生成 token 数量动态增长，是最主要的动态内存开销来源；</li><li><strong>Others</strong>：主要指推理过程中暂时产生的中间计算结果（如 activation），生命周期短，通常在计算完一层后即被释放，占用较少。</li></ul><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505270835072.png" alt=""></p><p>从这张图可以直观看出，KV Cache 是模型推理过程中最主要的“动态”显存负担，它不仅大，而且会随着请求数量和序列长度迅速膨胀。因此，如何高效管理 KV Cache，决定了一个推理系统能否支撑大批量并发请求，是提高吞吐量的关键。</p><h2 id="_3-内存管理的挑战-kv-cache-为什么成了-llm-推理的瓶颈" tabindex="-1">3 内存管理的挑战：KV Cache 为什么成了 LLM 推理的瓶颈？ <a class="header-anchor" href="#_3-内存管理的挑战-kv-cache-为什么成了-llm-推理的瓶颈" aria-label="Permalink to &quot;3 内存管理的挑战：KV Cache 为什么成了 LLM 推理的瓶颈？&quot;">​</a></h2><p>当前主流的 LLM 推理系统在 KV Cache 的内存管理上普遍存在 3 类结构性问题：显存占用增长快、内存碎片严重，以及缓存难以复用。</p><h3 id="_3-1-kv-cache-占用迅速增长-极易耗尽显存" tabindex="-1">3.1 KV Cache 占用迅速增长，极易耗尽显存 <a class="header-anchor" href="#_3-1-kv-cache-占用迅速增长-极易耗尽显存" aria-label="Permalink to &quot;3.1 KV Cache 占用迅速增长，极易耗尽显存&quot;">​</a></h3><p>以 OPT-13B 为例，论文指出其每个 token 的 KV Cache 占用约为 <strong>800KB</strong>，计算方式为：</p><blockquote><p>2（Key 和 Value）× 5120（hidden size）× 40（Transformer 层数）× 2 字节（FP16） = 819,200 字节 ≈ 800KB</p></blockquote><p>如果生成完整的 2048 个 token，单个请求的 KV Cache 占用就可达约 1.6GB。在一块 40GB 显存的 A100 GPU 上，这种增长速度意味着仅同时处理少量请求，就可能达到内存瓶颈，直接限制了批处理规模和系统吞吐量。</p><h3 id="_3-2-预分配导致内存碎片严重" tabindex="-1">3.2 预分配导致内存碎片严重 <a class="header-anchor" href="#_3-2-预分配导致内存碎片严重" aria-label="Permalink to &quot;3.2 预分配导致内存碎片严重&quot;">​</a></h3><p>传统推理系统（如 FasterTransformer 和 Orca）通常采用<strong>预分配</strong>策略：请求开始时，就按最大可能生成的长度（如 2048 token）为每个请求分配一整块连续内存空间。这种方式带来 3 类显著的内存浪费：</p><ul><li><strong>已预留但尚未使用的空间（Reserved）</strong>：虽然未来会使用，但当前暂未使用到。</li><li><strong>内部碎片（Internal Fragmentation）</strong>：实际 token 数小于预留长度，剩余空间浪费。</li><li><strong>外部碎片（External Fragmentation）</strong>：不同请求所需内存大小不一，造成内存块间不连续，产生碎片。</li></ul><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505270830601.png" alt=""></p><p>论文中的实验结果显示，再传统系统中真正用于存放 KV Cache 的有效内存占比最低仅约 20.4%，其余全为浪费。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505272126728.png" alt=""></p><h3 id="_3-3-kv-cache-难以共享-内存复用受限" tabindex="-1">3.3 KV Cache 难以共享，内存复用受限 <a class="header-anchor" href="#_3-3-kv-cache-难以共享-内存复用受限" aria-label="Permalink to &quot;3.3 KV Cache 难以共享，内存复用受限&quot;">​</a></h3><p>在 <strong>Parallel Sampling</strong> 或 <strong>Beam Search</strong> 等复杂推理模式中，一个请求可能包含多个生成分支（如多个候选答案），这些分支共享相同的 prompt，因此理论上可以共享其 KV Cache。但传统系统将每个分支的 KV Cache 存放在独立的连续内存中，物理上无法实现共享，只能进行冗余复制，进而显著增加了内存开销。</p><h2 id="_4-核心创新-pagedattention-是什么" tabindex="-1">4 核心创新：PagedAttention 是什么？ <a class="header-anchor" href="#_4-核心创新-pagedattention-是什么" aria-label="Permalink to &quot;4 核心创新：PagedAttention 是什么？&quot;">​</a></h2><p>为了解决 KV Cache 内存管理中的高占用、严重碎片和复用困难等问题，vLLM 提出了一种全新的注意力机制 —— <strong>PagedAttention</strong>。它的核心思想，借鉴自操作系统中广泛应用的<strong>虚拟内存分页机制（Virtual Memory &amp; Paging）</strong>。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505271030527.png" alt=""></p><p>在操作系统中，虚拟内存将程序的地址空间划分为固定大小的“页”（Page），这些页可以映射到物理内存中任意位置，实现非连续分配，从而有效解决了内存碎片和共享问题。PagedAttention 将这一思路引入 KV Cache 的管理中，并带来了 3 项关键改进：</p><ol><li><p><strong>KV Cache 被切分为固定大小的 block</strong>：PagedAttention 将每个序列的 KV Cache 切分为固定大小的 block（默认是 16 个 token），每个 block 存储若干个 token 的 Key 和 Value 向量。这种设计统一了内存分配粒度，使系统能够以更标准化的方式管理 KV Cache 的分配与回收，从而提升内存复用效率，并有效减少内存碎片。</p></li><li><p><strong>block 可以存放在非连续的物理内存中</strong>：与传统的 Attention 不同，PagedAttention 不再要求这些 KV 向量在内存中连续排列，而是通过逻辑 block 与物理 block 的映射，实现非连续存储。映射关系由 block table 维护，它类似于操作系统中的页表，用于记录每个逻辑 block 对应的物理内存位置，确保模型在推理过程中可以正确读取所需的 KV Cache。</p></li><li><p><strong>支持灵活的分配与释放，以及共享机制</strong>：PagedAttention 支持按需分配和回收 block，并允许多个序列共享 block。PagedAttention 使用了 copy-on-write（CoW）机制，允许多个生成样本共享大部分输入 prompt 的 KV Cache，只有当某个分支需要写入新 token 的 KV 数据时，系统才会将相关 block 复制到新的物理位置，从而在保证数据隔离的同时极大地节省显存资源，提升推理效率与吞吐量。</p></li></ol><h2 id="_5-实现细节-vllm-如何利用-pagedattention-实现高效推理" tabindex="-1">5 实现细节：vLLM 如何利用 PagedAttention 实现高效推理 <a class="header-anchor" href="#_5-实现细节-vllm-如何利用-pagedattention-实现高效推理" aria-label="Permalink to &quot;5 实现细节：vLLM 如何利用 PagedAttention 实现高效推理&quot;">​</a></h2><h3 id="_5-1-推理过程中的内存管理" tabindex="-1">5.1 推理过程中的内存管理 <a class="header-anchor" href="#_5-1-推理过程中的内存管理" aria-label="Permalink to &quot;5.1 推理过程中的内存管理&quot;">​</a></h3><p>vLLM 在 decode 阶段使用 PagedAttention 配合 block-level 的内存管理机制，实现了高效、动态的 KV Cache 管理。</p><p>如下图所示，用户请求的 prompt 为 <code>&quot;Four score and seven years ago our&quot;</code>，共包含 7 个 token：</p><ol><li><p><strong>prefill 阶段</strong>：vLLM 为前 7 个 token 分配两个逻辑块 block 0 和 block 1，分别映射到物理块 7 和 1。block 0 存储前 4 个 token，block 1 存储后 3 个 token 及第一个生成 token <code>&quot;fathers&quot;</code>，填充数为 4。</p></li><li><p><strong>decode 阶段 - 生成第 1 个词</strong>：生成 token <code>&quot;brought&quot;</code>，由于 block 1 尚未填满（最多容纳 4 个 token），因此直接将新 KV Cache 写入该块，填充计数从 3 更新为 4。</p></li><li><p><strong>decode 阶段 - 生成第 2 个词</strong>：生成下一个 token，此时 block 1 已满，系统为逻辑块 block 2 分配新的物理块 block 3，并写入 KV Cache，同时更新映射表。</p></li></ol><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505272140169.png" alt=""></p><p>整个过程中，每个逻辑块仅在前一个块被填满后才会分配新的物理块，从而最大程度地减少内存浪费。不难发现，在计算时我们操作的是逻辑块，也就是说，这些 token 在形式上是连续排列的；与此同时，vLLM 会通过 block table 映射关系，在后台将逻辑块映射到实际的物理块，从而完成数据的读取与计算。通过这种方式，每个请求仿佛都在一个连续且充足的内存空间中运行，尽管这些数据在物理内存中实际上是非连续存储的。</p><h3 id="_5-2-支持多样化的推理策略" tabindex="-1">5.2 支持多样化的推理策略 <a class="header-anchor" href="#_5-2-支持多样化的推理策略" aria-label="Permalink to &quot;5.2 支持多样化的推理策略&quot;">​</a></h3><p>PagedAttention 中采用的基于分页的 KV Cache 管理机制，不仅在常规单序列生成中表现出色，也天然适合多种复杂的解码策略。</p><h4 id="_5-2-1-并行采样-parallel-sampling" tabindex="-1">5.2.1 并行采样（Parallel Sampling） <a class="header-anchor" href="#_5-2-1-并行采样-parallel-sampling" aria-label="Permalink to &quot;5.2.1 并行采样（Parallel Sampling）&quot;">​</a></h4><p>在 Parallel Sampling 中，同一个 prompt 会生成多个候选输出，便于用户从多个备选中选择最佳响应，常用于内容生成或模型对比测试。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505232255681.png" alt=""></p><p>在 vLLM 中，这些采样序列共享相同的 prompt，其对应的 KV Cache 也可以共用同一组物理块。PagedAttention 通过引用计数和 block-level 的 copy-on-write 机制实现共享与隔离的平衡：只有当序列出现不同分支时，才会触发复制操作。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505271114181.png" alt=""></p><h4 id="_5-2-2-束搜索-beam-search" tabindex="-1">5.2.2 束搜索（Beam Search） <a class="header-anchor" href="#_5-2-2-束搜索-beam-search" aria-label="Permalink to &quot;5.2.2 束搜索（Beam Search）&quot;">​</a></h4><p>Beam Search 是机器翻译等任务中常见的解码策略。它会维护多个“beam”路径，每轮扩展最优候选并保留 top-k 序列。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505232256066.png" alt=""></p><p>在 vLLM 中，多个 beam 可以共享公共前缀部分的 KV Cache，不仅包括输入 prompt，还包括生成过程中的公共前缀 token。只要这些 beam 的生成路径尚未分叉，它们就会复用相同的物理块。当路径分叉发生后，vLLM 才通过 copy-on-write 机制对共享块进行拆分，从而保证每个 beam 的独立性。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505271120044.png" alt=""></p><h4 id="_5-2-3-共享前缀-shared-prefix" tabindex="-1">5.2.3 共享前缀（Shared Prefix） <a class="header-anchor" href="#_5-2-3-共享前缀-shared-prefix" aria-label="Permalink to &quot;5.2.3 共享前缀（Shared Prefix）&quot;">​</a></h4><p>在许多提示工程实践中，多个请求会以相同的系统提示或 few-shot 示例开头（例如翻译任务中的多个例句）。这些共享前缀同样可以被 vLLM 缓存并复用。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505271121514.png" alt=""></p><h4 id="_5-2-4-混合解码-mixed-decoding" tabindex="-1">5.2.4 混合解码（Mixed Decoding） <a class="header-anchor" href="#_5-2-4-混合解码-mixed-decoding" aria-label="Permalink to &quot;5.2.4 混合解码（Mixed Decoding）&quot;">​</a></h4><p>前面提到的几种解码方式（如 Parallel Sampling、Beam Search、Shared Prefix 等）在内存的共享和访问方式上存在差异，传统系统很难同时高效地处理这些不同策略的请求。而 vLLM 则通过一个通用的映射层（block table）屏蔽了这些差异，让系统能够在统一框架下处理多样化的请求。</p><h3 id="_5-3-推理任务的调度与抢占" tabindex="-1">5.3 推理任务的调度与抢占 <a class="header-anchor" href="#_5-3-推理任务的调度与抢占" aria-label="Permalink to &quot;5.3 推理任务的调度与抢占&quot;">​</a></h3><p>当请求量超过系统处理能力时，vLLM 需要在有限的显存资源下合理调度推理请求，并对部分请求进行抢占（Preemption）。为此，vLLM 采用了 <strong>FCFS（first-come-first-serve）</strong> 的策略，确保请求被公平处理：优先服务最早到达的请求，优先抢占最近到达的请求，避免资源饥饿。</p><p>由于大模型的输入 prompt 长度差异大，输出长度也无法预估，随着请求和生成的 token 增加，GPU 中用于存储 KV Cache 的物理块可能耗尽。此时，vLLM 面临两个核心问题：</p><ol><li><strong>应该回收哪些块？</strong></li><li><strong>如果后续仍需使用，被回收的块如何恢复？</strong></li></ol><h4 id="_5-3-1-块回收策略-all-or-nothing" tabindex="-1">5.3.1 块回收策略：All-or-Nothing <a class="header-anchor" href="#_5-3-1-块回收策略-all-or-nothing" aria-label="Permalink to &quot;5.3.1 块回收策略：All-or-Nothing&quot;">​</a></h4><p>vLLM 中每个序列的所有 KV Cache 块始终一起被访问，因此采用 “<strong>All-or-Nothing</strong>” 的回收策略：要么完全回收一个请求的全部 KV Cache，要么不回收。此外，像 Beam Search 这类单请求中含多个子序列（beam）的情况，这些序列之间可能共享 KV Cache，必须作为一个 “<strong>sequence group</strong>” 整体抢占或恢复，确保共享关系不被破坏。</p><h4 id="_5-3-2-块恢复策略-swapping-与-recomputation" tabindex="-1">5.3.2 块恢复策略：Swapping 与 Recomputation <a class="header-anchor" href="#_5-3-2-块恢复策略-swapping-与-recomputation" aria-label="Permalink to &quot;5.3.2 块恢复策略：Swapping 与 Recomputation&quot;">​</a></h4><p>对于被抢占请求的 KV Cache，vLLM 提供两种恢复机制：</p><ul><li><p><strong>Swapping（交换）</strong>：将被抢占请求的 KV Cache 块从 GPU 移动到 CPU 内存。当有空闲 GPU 块时再从 CPU 恢复回来继续执行。为了控制资源使用，被交换（swapped）到 CPU 内存中的 KV Cache 块数量，永远不会超过 GPU 中物理块的总数。</p></li><li><p><strong>Recomputation（重计算）</strong>：直接丢弃已生成的 KV Cache，待请求恢复后重新计算。Recomputation 可将已生成的 token 与原始 prompt 拼接为新的输入，一次性完成所有 KV Cache 的预填充，其开销显著低于原始 decode 阶段逐 token 生成的方式，随后可以继续后续的 decode 过程。</p></li></ul><p>根据论文中的实验结果，Swapping 更适用于 block size 较大的场景，而 Recomputation 则在不同 block size 下的表现更为稳定。在中等 block size（16 到 64）范围内，两种方式的端到端性能基本相当。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505271139291.png" alt=""></p><h3 id="_5-4-分布式架构" tabindex="-1">5.4 分布式架构 <a class="header-anchor" href="#_5-4-分布式架构" aria-label="Permalink to &quot;5.4 分布式架构&quot;">​</a></h3><p>随着大语言模型（LLM）参数规模的不断扩大，许多模型的总参数量早已超出单张 GPU 的显存上限。因此，必须将模型参数切分并分布在多张 GPU 上，以实现并行执行，这种策略被称为 <strong>模型并行（Model Parallelism）</strong>。这不仅要求模型本身具备良好的并行性，也对系统提出了更高要求——需具备能够协调跨设备内存访问与管理的能力。</p><p>为应对这一挑战，vLLM 构建了一套面向分布式推理的执行架构，原生支持 <a href="https://github.com/NVIDIA/Megatron-LM" target="_blank" rel="noreferrer">Megatron-LM</a> 风格的张量并行策略，并通过统一调度与基于分页的 KV Cache 管理机制，实现了跨 GPU 的高效协同推理与资源共享。</p><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202505272000111.png" alt=""></p><p>在每一步 decode 过程中，调度器首先为每个 batch 中的请求准备控制信息，其中包括：</p><ul><li>输入 token 的 ID；</li><li>以及该请求的块表（block table，即逻辑块到物理块的映射信息）。</li></ul><p>接下来，调度器会将这些控制信息广播给所有的 GPU worker。</p><p>然后，GPU worker 开始使用这些输入 token ID 执行模型推理。在注意力层中，GPU worker 会根据控制信息中提供的块表，读取对应的 KV Cache。在执行过程中，GPU worker 会通过 all-reduce 通信原语同步中间计算结果，这一过程无需调度器参与协调。最后，GPU worker 会将本轮生成的 token（采样结果）发送回调度器。</p><h3 id="_5-5-gpu-kernel-优化" tabindex="-1">5.5 GPU kernel 优化 <a class="header-anchor" href="#_5-5-gpu-kernel-优化" aria-label="Permalink to &quot;5.5 GPU kernel 优化&quot;">​</a></h3><p>PagedAttention 引入了非连续、按块访问 KV Cache 的内存访问模式，而这些访问模式并不适配现有推理系统中的通用 kernel 实现。为此，vLLM 专门实现了一系列 GPU kernel 优化，以充分发挥硬件性能：</p><ul><li><p><strong>融合 reshape 与块写入（Fused reshape and block write）</strong> 在 Transformer 的每一层，新生成的 KV Cache 需要被分块、reshape 成适合按块读取的内存布局，并根据 block table 的位置写入显存。vLLM 将这些操作融合为一个 kernel 执行，避免了多次 kernel 启动的开销，从而提升执行效率。</p></li><li><p><strong>融合块读取与注意力计算（Fusing block read and attention）</strong> vLLM 在 FasterTransformer 的基础上改造了注意力 kernel，使其能够根据 block table 实时读取 KV Cache 并执行 attention 操作。为了确保内存访问的合并性（coalesced access），vLLM 为每个块分配一个 GPU warp 来读取数据，并支持同一 batch 中不同序列长度的处理，增强了执行灵活性。</p></li><li><p><strong>优化块复制操作（Fused block copy）</strong> copy-on-write 机制触发的块复制可能涉及多个非连续内存块。若使用 <code>cudaMemcpyAsync</code>，会造成频繁的小数据移动，效率低下。vLLM 实现了一个融合的 kernel，可将多个块复制操作批量合并为一次 kernel 启动，显著降低了调度开销与执行延迟。</p></li></ul><h2 id="_6-总结" tabindex="-1">6 总结 <a class="header-anchor" href="#_6-总结" aria-label="Permalink to &quot;6 总结&quot;">​</a></h2><p>本文系统梳理了 vLLM 核心技术 PagedAttention 的设计理念与实现机制。文章从 KV Cache 在推理中的关键作用与内存管理挑战切入，介绍了 vLLM 在请求调度、分布式执行及 GPU kernel 优化等方面的核心改进。PagedAttention 通过分页机制与动态映射，有效提升了显存利用率，使 vLLM 在保持低延迟的同时显著提升了吞吐能力。</p><h2 id="_7-参考资料" tabindex="-1">7 参考资料 <a class="header-anchor" href="#_7-参考资料" aria-label="Permalink to &quot;7 参考资料&quot;">​</a></h2><ul><li>How To Reduce LLM Decoding Time With KV-Caching: <a href="https://newsletter.theaiedge.io/p/how-to-reduce-llm-decoding-time-with" target="_blank" rel="noreferrer">https://newsletter.theaiedge.io/p/how-to-reduce-llm-decoding-time-with</a></li><li>Introduction to vLLM and PagedAttention：<a href="https://blog.runpod.io/introduction-to-vllm-and-how-to-run-vllm-on-runpod-serverless/" target="_blank" rel="noreferrer">https://blog.runpod.io/introduction-to-vllm-and-how-to-run-vllm-on-runpod-serverless/</a></li><li>The First vLLM Meetup：<a href="https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing" target="_blank" rel="noreferrer">https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing</a></li><li>图解大模型计算加速系列之：vLLM核心技术PagedAttention原理：<a href="https://mp.weixin.qq.com/s/-5EniAmFf1v9RdxI5-CwiQ" target="_blank" rel="noreferrer">https://mp.weixin.qq.com/s/-5EniAmFf1v9RdxI5-CwiQ</a></li><li>The KV Cache: Memory Usage in Transformers：<a href="https://www.youtube.com/watch?v=80bIUggRJf4&amp;t=319s" target="_blank" rel="noreferrer">https://www.youtube.com/watch?v=80bIUggRJf4&amp;t=319s</a></li><li>vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention：<a href="https://blog.vllm.ai/2023/06/20/vllm.html" target="_blank" rel="noreferrer">https://blog.vllm.ai/2023/06/20/vllm.html</a></li></ul><h2 id="_8-欢迎关注" tabindex="-1">8 欢迎关注 <a class="header-anchor" href="#_8-欢迎关注" aria-label="Permalink to &quot;8 欢迎关注&quot;">​</a></h2><p><img src="https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202503222156941.png" alt=""></p></div></div></main><footer class="VPDocFooter" data-v-2a93c244 data-v-30828d04><!--[--><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--><!--]--><div class="edit-info" data-v-30828d04><div class="edit-link" data-v-30828d04><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/cr7258/cr7258.github.io/edit/main/docs/courses/ai-infra/AI Infra 教程/02-pagedattention.md" target="_blank" rel="noreferrer" data-v-30828d04><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" aria-label="edit icon" data-v-30828d04><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> 不妥之处，敬请雅正<!--]--></a></div><div class="last-updated" data-v-30828d04><p class="VPLastUpdated" data-v-30828d04 data-v-a63b3a55>最后更新: <time datetime="2025-06-08T14:12:31.000Z" data-v-a63b3a55></time></p></div></div><nav class="prev-next" data-v-30828d04><div class="pager" data-v-30828d04><a class="VPLink link pager-link prev" href="/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/01-vllm-quickstart" data-v-30828d04><!--[--><span class="desc" data-v-30828d04>上一篇</span><span class="title" data-v-30828d04><div class="text-color-red mr-[6px]" style="font-weight: 550; display: inline-block;">1</div>vLLM 快速部署指南</span><!--]--></a></div><div class="pager" data-v-30828d04><a class="VPLink link pager-link next" href="/courses/ai-infra/AI%20Infra%20%E6%95%99%E7%A8%8B/03-prefix-caching" data-v-30828d04><!--[--><span class="desc" data-v-30828d04>下一篇</span><span class="title" data-v-30828d04><div class="text-color-yellow mr-[6px]" style="font-weight: 550; display: inline-block;">3</div>Prefix Caching 详解：实现 KV Cache 的跨请求高效复用</span><!--]--></a></div></nav></footer><!--[--><!--[--><!--[--><div id="comment-container"></div><!--]--><!--]--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_index.md\":\"ClTyGAWD\",\"about_me.md\":\"BmxhEx6m\",\"archives.md\":\"D4aOyovv\",\"blogs_original_2022_01-kubernetes-setup.md\":\"DGnvN2Cj\",\"blogs_original_2022_02-kubectl-debug.md\":\"CFQyDDJ1\",\"blogs_original_2022_03-finalizer.md\":\"CNJPLl7A\",\"blogs_original_2022_04-kubeasz.md\":\"ClomVKnm\",\"blogs_original_2022_05-docker-rootless.md\":\"BRiDYQFe\",\"blogs_original_2022_06-kafka-setup.md\":\"Db2BnE37\",\"blogs_original_2022_07-kafka-big-message.md\":\"CPaqUMuu\",\"blogs_original_2022_08-reset-kafka-consumer-offset.md\":\"B164RPKM\",\"blogs_original_2022_09-pulsar.md\":\"BYhBDMBq\",\"blogs_original_2022_10-harbor.md\":\"CWuqOk_6\",\"blogs_original_2022_11.nebula.md\":\"DWXG9nBo\",\"blogs_original_2022_12.lru.md\":\"mtC7nES1\",\"blogs_original_2022_13-envoy-quickstart.md\":\"DKmLL6N6\",\"blogs_original_2023_01-argocd-quickstart.md\":\"CGKXLOsc\",\"blogs_original_2023_02-wasm-in-cloud-native.md\":\"BZwGn2Zp\",\"blogs_original_2023_03-kubectl-patch.md\":\"r90t1DlM\",\"blogs_original_2023_04-kubernetes-keycloak-oidc.md\":\"DT18blPJ\",\"blogs_original_2023_05-kubernetes-multi-cluster-1.md\":\"8FG5At_c\",\"blogs_original_2023_06-kubernetes-multi-cluster-2.md\":\"Ca7J7J3N\",\"blogs_original_2023_07-vcluster.md\":\"BSm-4oDC\",\"blogs_original_2023_08-cilium-cluster-mesh.md\":\"By5fkCQR\",\"blogs_original_2023_09-clusterresourceset.md\":\"mbspsDH5\",\"blogs_original_2023_10-cilium-bgp.md\":\"CiLvNX9z\",\"blogs_original_2024_01-crossplane.md\":\"D8U3n6uf\",\"blogs_original_2024_02-sidecar-containers.md\":\"CV1C_pmm\",\"blogs_original_2024_03-higress-ai-plugins.md\":\"DiSeg59U\",\"blogs_original_2025_01-mcp.md\":\"Drb9UbUX\",\"blogs_original_2025_02-elasticsearch-mcp-server.md\":\"DqLNWIN9\",\"blogs_original_2025_03-mcp-client.md\":\"CTMoJ01v\",\"blogs_original_2025_04-mcp-sse.md\":\"D0xxO_eO\",\"blogs_original_2025_05-higress-vs-oneapi.md\":\"Dw6eRPBe\",\"blogs_original_2025_06-higress-ai-gateway.md\":\"DUlW53BR\",\"blogs_original_2025_07-deepseek-flashmla.md\":\"JvAg4apN\",\"blogs_original_2025_08-deepseek-deepep.md\":\"DeBX73Nr\",\"blogs_original_2025_09-deepseek-deepgemm.md\":\"Uue9ny-S\",\"blogs_original_2025_10-deepseek-parallelism.md\":\"Bc0cxSLj\",\"blogs_original_2025_11-deepseek-3fs.md\":\"mspgTQa2\",\"blogs_original_2025_12-manus-ai.md\":\"C1aFzgxo\",\"blogs_original_2025_13-gpu-kind-cluster.md\":\"C7fzgXv_\",\"blogs_original_2025_14-gateway-api-inference-extension.md\":\"DqbTwS9b\",\"blogs_original_2025_15-rag-higress-es-langchain.md\":\"BAcds50S\",\"blogs_original_2025_16-context7.md\":\"DxEGJGRQ\",\"blogs_original_2025_17-runai-model-streamer.md\":\"1bvtbuxc\",\"blogs_original_2025_18-higress-llmaz-vllm.md\":\"D5Y0G-4t\",\"blogs_original_index.md\":\"DN9UqtDc\",\"blogs_translate_2023_01-life-of-a-packet-in-kubernetes-part-1.md\":\"0xUOSUHs\",\"blogs_translate_2023_02-life-of-a-packet-in-kubernetes-part-2.md\":\"DddehrVM\",\"blogs_translate_2023_03-life-of-a-packet-in-kubernetes-part-3.md\":\"CDFTnUCG\",\"blogs_translate_2023_04-life-of-a-packet-in-kubernetes-part-4.md\":\"pJ3LT-Vk\",\"blogs_translate_2023_05-git-cheat-sheet-1.md\":\"CfcuTCcq\",\"blogs_translate_2023_06-git-cheat-sheet-2.md\":\"Bbqgr9ll\",\"blogs_translate_2023_07-git-cheat-sheet-3.md\":\"DexGNnp2\",\"blogs_translate_index.md\":\"BRIzbW49\",\"categories_fragments_index.md\":\"CJzrOsUp\",\"categories_fragments_个人速查手册_01-git.md\":\"Bwee3awt\",\"categories_fragments_个人速查手册_02-find-docker-file.md\":\"C2-cvOlG\",\"categories_fragments_个人速查手册_03-idea-shortcut.md\":\"CXhJo2Fj\",\"categories_fragments_个人速查手册_04-ssh-proxy.md\":\"CuzGmrJZ\",\"categories_fragments_个人速查手册_05-docker-command.md\":\"OehTLbyU\",\"categories_fragments_个人速查手册_06-kubernetes-command.md\":\"YWBP312t\",\"categories_fragments_个人速查手册_07.uv.md\":\"DDOHobMc\",\"categories_issues_bug万象集_01-ebpf.md\":\"CZgDP3pT\",\"categories_issues_bug万象集_02-ide.md\":\"Cx9fNzlF\",\"categories_issues_index.md\":\"Cr6geNu3\",\"categories_learning_ai_01-ai.md\":\"5_078oRQ\",\"categories_learning_ai_02-gpu.md\":\"CH-170fa\",\"categories_learning_ai_03-pytorch.md\":\"CKyUdctk\",\"categories_learning_ai_04-mcp.md\":\"EzwK4uuG\",\"categories_learning_ai_05-transformer.md\":\"BU7MRZEg\",\"categories_learning_ebpf_01-ebpf.md\":\"BDitH2ab\",\"categories_learning_ebpf_02-bpftool.md\":\"BA1AtK9W\",\"categories_learning_index.md\":\"DVn2roQ2\",\"categories_learning_云原生_01-istio.md\":\"CeGeAq71\",\"categories_learning_云原生_02-observability.md\":\"Bg8z7QvW\",\"categories_learning_编程语言_01-rust.md\":\"BvnCzpfq\",\"categories_learning_编程语言_02-golang-concurrency.md\":\"DQsIgrIt\",\"categories_learning_编程语言_02-golang-gmp.md\":\"1nEhgtkq\",\"categories_learning_编程语言_03-design-pattern.md\":\"CrCIAyKx\",\"categories_open-source_index.md\":\"Cm43Y61l\",\"categories_open-source_开源项目_01-ai.md\":\"DK2qd-ka\",\"categories_open-source_开源项目_02-web.md\":\"TG4mAMUC\",\"categories_open-source_开源项目_03-mcp.md\":\"DiE4NNHD\",\"categories_open-source_开源项目_04-cloud-native.md\":\"In2N0kcq\",\"categories_tools_index.md\":\"BLtkSH0V\",\"categories_tools_云原生_01-k8s-resource.md\":\"BuwJ9HOA\",\"courses_ai-infra_ai infra 教程_01-vllm-quickstart.md\":\"D234vKKS\",\"courses_ai-infra_ai infra 教程_02-pagedattention.md\":\"CIYNRQGM\",\"courses_ai-infra_ai infra 教程_03-prefix-caching.md\":\"DSKFDszX\",\"courses_ai-infra_ai infra 教程_04-speculative-decoding.md\":\"be_IeiNq\",\"courses_ai-infra_index.md\":\"CrT7bxeu\",\"courses_algorithm_index.md\":\"DxWXY9a4\",\"courses_algorithm_算法_01-hot100.md\":\"D7An9J6j\",\"courses_algorithm_算法_02-template.md\":\"Bdwhp0YT\",\"courses_algorithm_算法_03-design-problem.md\":\"B8XkxTft\",\"courses_algorithm_算法_04-shell.md\":\"BWjnHwM3\",\"courses_elastic-stack_elastic stack 实战教程_01-quick-start.md\":\"B7eKl6jv\",\"courses_elastic-stack_elastic stack 实战教程_02-ilm.md\":\"BIcR8oK-\",\"courses_elastic-stack_elastic stack 实战教程_03-snapshot.md\":\"B50tMZtn\",\"courses_elastic-stack_elastic stack 实战教程_04-fleet.md\":\"uq1AgBeI\",\"courses_elastic-stack_elastic stack 实战教程_05-java-client.md\":\"DD1xDMiS\",\"courses_elastic-stack_index.md\":\"DJlJs71Q\",\"courses_interview_ai_01-ai.md\":\"DlXZQqdx\",\"courses_interview_elastic stack_01-elasticsearch.md\":\"CaWnNa_A\",\"courses_interview_index.md\":\"CkH95BIi\",\"courses_interview_云原生_01-kubernetes.md\":\"vB7IQtHp\",\"courses_interview_云原生_02-container.md\":\"YitjOKar\",\"courses_interview_云原生_03-storage.md\":\"DWYAqEcl\",\"courses_interview_云原生_04-network.md\":\"bUtIrZOb\",\"courses_interview_云原生_05-security.md\":\"CtNpyM6y\",\"courses_interview_云原生_06-rollout.md\":\"BuKoUbs_\",\"courses_interview_云原生_07-operator.md\":\"DhmcWqz3\",\"courses_interview_大数据_01-message-queue.md\":\"D5V5WZeg\",\"courses_interview_操作系统_01-cpu.md\":\"Do2O_AUc\",\"courses_interview_操作系统_02-memory.md\":\"Jd1TtDIX\",\"courses_interview_操作系统_03-storage.md\":\"BVvKZyAf\",\"courses_interview_操作系统_04-network.md\":\"DQ72_ZC3\",\"courses_interview_操作系统_05-cgroup.md\":\"NKcSVzxo\",\"courses_interview_编程语言_01-golang.md\":\"BqapVU-t\",\"courses_interview_编程语言_02-python.md\":\"Cu5F-eXt\",\"courses_interview_编程语言_03-algorithm.md\":\"q_xOy3J5\",\"courses_observability_opentelemetry_01-opentelemetry-elastic.md\":\"Cx6Rtl-l\",\"courses_observability_index.md\":\"C3Ru8TBp\",\"en_about_index.md\":\"CmCa7_BU\",\"en_about_me.md\":\"BKEqH-v9\",\"en_archives.md\":\"D_CswlkS\",\"en_courses_elastic-stack_01-elastic-stack-hands-on-lab_01-quick-start.md\":\"5WDgvhl-\",\"en_courses_elastic-stack_01-elastic-stack-hands-on-lab_02-ilm.md\":\"ChJNma7W\",\"en_courses_elastic-stack_01-elastic-stack-hands-on-lab_03-snapshot.md\":\"CgSi6deN\",\"en_courses_elastic-stack_01-elastic-stack-hands-on-lab_04-fleet.md\":\"DVNVb1xI\",\"en_courses_elastic-stack_01-elastic-stack-hands-on-lab_05-java-client.md\":\"BIxxeplW\",\"en_courses_elastic-stack_index.md\":\"UltvLXFf\",\"en_index.md\":\"Crk_ARIP\",\"en_tags.md\":\"CeJ_tbPI\",\"index.md\":\"C48x9QOL\",\"meetup_network_01-network_01-cni.md\":\"Vud6wYrY\",\"meetup_network_index.md\":\"BAywDmvY\",\"tags.md\":\"B-_mAu9f\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"Se7en的架构笔记\",\"description\":\"个人技术知识库，记录 & 分享个人碎片化、结构化、体系化的技术知识内容。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"博客\",\"items\":[{\"text\":\"原创\",\"link\":\"/blogs/original/index\",\"activeMatch\":\"/blogs/original/\"},{\"text\":\"翻译\",\"link\":\"/blogs/translate/index\",\"activeMatch\":\"/blogs/translate/\"}],\"activeMatch\":\"/blogs/\"},{\"text\":\"我的分类\",\"items\":[{\"text\":\"Bug万象集\",\"link\":\"/categories/issues/index\",\"activeMatch\":\"/categories/issues/\"},{\"text\":\"个人速查手册\",\"link\":\"/categories/fragments/index\",\"activeMatch\":\"/categories/fragments/\"},{\"text\":\"精选工具箱\",\"link\":\"/categories/tools/index\",\"activeMatch\":\"/categories/tools/\"},{\"text\":\"开源项目\",\"link\":\"/categories/open-source/index\",\"activeMatch\":\"/categories/open-source/\"},{\"text\":\"学习笔记\",\"link\":\"/categories/learning/index\",\"activeMatch\":\"/categories/learning/\"}],\"activeMatch\":\"/categories/\"},{\"text\":\"我的小册\",\"items\":[{\"text\":\"AI Infra 教程\",\"link\":\"/courses/ai-infra/index\",\"activeMatch\":\"/courses/ai-infra/\"},{\"text\":\"Elastic Stack 实战教程\",\"link\":\"/courses/elastic-stack/index\",\"activeMatch\":\"/courses/elastic-stack/\"},{\"text\":\"Observability 教程\",\"link\":\"/courses/observability/index\",\"activeMatch\":\"/courses/observability/\"},{\"text\":\"面试宝典\",\"link\":\"/courses/interview/index\",\"activeMatch\":\"/courses/interview/\"},{\"text\":\"数据结构与算法\",\"link\":\"/courses/algorithm/index\",\"activeMatch\":\"/courses/algorithm/\"}],\"activeMatch\":\"/courses/\"},{\"text\":\"我的标签\",\"link\":\"/tags\",\"activeMatch\":\"/tags\"},{\"text\":\"我的归档\",\"link\":\"/archives\",\"activeMatch\":\"/archives\"},{\"text\":\"关于\",\"items\":[{\"text\":\"关于知识库\",\"link\":\"/about/index\",\"activeMatch\":\"/about/index\"},{\"text\":\"关于我\",\"link\":\"/about/me\",\"activeMatch\":\"/about/me\"}],\"activeMatch\":\"/about/\"}],\"sidebar\":{\"/categories/issues/\":[{\"text\":\"Bug万象集 (2篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>eBPF\",\"link\":\"/categories/issues/Bug万象集/01-ebpf\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>IDE\",\"link\":\"/categories/issues/Bug万象集/02-ide\"}],\"collapsed\":false}],\"/categories/fragments/\":[{\"text\":\"个人速查手册 (7篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Git 速查手册\",\"link\":\"/categories/fragments/个人速查手册/01-git\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>5 种快速查找容器中文件的方法\",\"link\":\"/categories/fragments/个人速查手册/02-find-docker-file\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>IDEA 快捷键\",\"link\":\"/categories/fragments/个人速查手册/03-idea-shortcut\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>使用 ClashX 代理 SSH 连接\",\"link\":\"/categories/fragments/个人速查手册/04-ssh-proxy\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>Docker 常用命令\",\"link\":\"/categories/fragments/个人速查手册/05-docker-command\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>Kubernetes 常用命令\",\"link\":\"/categories/fragments/个人速查手册/06-kubernetes-command\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>uv 速查手册\",\"link\":\"/categories/fragments/个人速查手册/07.uv\"}],\"collapsed\":false}],\"/categories/tools/\":[{\"text\":\"云原生 (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>查询 Kubernetes 核心资源字段\",\"link\":\"/categories/tools/云原生/01-k8s-resource\"}],\"collapsed\":false}],\"/categories/learning/\":[{\"text\":\"AI (5篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>AI\",\"link\":\"/categories/learning/AI/01-ai\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>GPU\",\"link\":\"/categories/learning/AI/02-gpu\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>PyTorch\",\"link\":\"/categories/learning/AI/03-pytorch\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>Model Context Protocol（MCP）\",\"link\":\"/categories/learning/AI/04-mcp\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>Transformer\",\"link\":\"/categories/learning/AI/05-transformer\"}],\"collapsed\":false},{\"text\":\"eBPF (2篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>eBPF 基础\",\"link\":\"/categories/learning/eBPF/01-ebpf\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>bpftool\",\"link\":\"/categories/learning/eBPF/02-bpftool\"}],\"collapsed\":false},{\"text\":\"云原生 (2篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Istio\",\"link\":\"/categories/learning/云原生/01-istio\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>Observability\",\"link\":\"/categories/learning/云原生/02-observability\"}],\"collapsed\":false},{\"text\":\"编程语言 (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Rust\",\"link\":\"/categories/learning/编程语言/01-rust\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>Go 并发编程\",\"link\":\"/categories/learning/编程语言/02-golang-concurrency\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Go GMP\",\"link\":\"/categories/learning/编程语言/02-golang-gmp\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>设计模式\",\"link\":\"/categories/learning/编程语言/03-design-pattern\"}],\"collapsed\":false}],\"/categories/open-source/\":[{\"text\":\"开源项目 (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>AI\",\"link\":\"/categories/open-source/开源项目/01-ai\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>Web\",\"link\":\"/categories/open-source/开源项目/02-web\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>MCP\",\"link\":\"/categories/open-source/开源项目/03-mcp\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>云原生\",\"link\":\"/categories/open-source/开源项目/04-cloud-native\"}],\"collapsed\":false}],\"/blogs/original/\":[{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/snake.svg\\\" title=\\\"蛇年\\\" alt=\\\"生肖\\\">\\n            2025年 (18篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>使用 Higress AI 网关代理 vLLM 推理服务\",\"link\":\"/blogs/original//2025/18-higress-llmaz-vllm\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>使用 Run:ai Model Streamer 实现模型的高效加载\",\"link\":\"/blogs/original//2025/17-runai-model-streamer\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>AI 乱写代码怎么破？使用 Context7 MCP Server 让 AI 写出靠谱代码!\",\"link\":\"/blogs/original//2025/16-context7\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>使用 LangChain + Higress + Elasticsearch 构建 RAG 应用\",\"link\":\"/blogs/original//2025/15-rag-higress-es-langchain\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>为 Kubernetes 提供智能的 LLM 推理路由：Gateway API Inference Extension 深度解析\",\"link\":\"/blogs/original//2025/14-gateway-api-inference-extension\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>一键部署 GPU Kind 集群，体验 vLLM 极速推理\",\"link\":\"/blogs/original//2025/13-gpu-kind-cluster\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>Manus 刷屏，全网求邀请码！这款 AI Agent 究竟有多强？\",\"link\":\"/blogs/original//2025/12-manus-ai\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>DeepSeek 开源周第五弹：3FS —— 专为 AI 训练和推理设计的分布式存储\",\"link\":\"/blogs/original//2025/11-deepseek-3fs\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>DeepSeek 开源周第四弹：DualPipe 和 EPLB —— 优化并行策略\",\"link\":\"/blogs/original//2025/10-deepseek-parallelism\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>DeepSeek 开源周第三弹：DeepGEMM —— 高效的 FP8 GEMM 库，核心代码仅 300 行！\",\"link\":\"/blogs/original//2025/09-deepseek-deepgemm\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>DeepSeek 开源周第二弹：DeepEP —— 首个 MoE 模型训练和推理的 EP 通信库\",\"link\":\"/blogs/original//2025/08-deepseek-deepep\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">12</div>DeepSeek 开源周第一弹：FlashMLA —— 大模型推理的“涡轮增压器”\",\"link\":\"/blogs/original//2025/07-deepseek-flashmla\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">13</div>提升 AI 服务的稳定性：Higress AI 网关的降级功能介绍\",\"link\":\"/blogs/original//2025/06-higress-ai-gateway\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">14</div>AI 网关对决：Higress 与 OneAPI 的功能对比\",\"link\":\"/blogs/original//2025/05-higress-vs-oneapi\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">15</div>构建基于 SSE 协议通信的 MCP Server 和 Client\",\"link\":\"/blogs/original//2025/04-mcp-sse\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">16</div>快速上手：实现你的第一个 MCP Client\",\"link\":\"/blogs/original//2025/03-mcp-client\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">17</div>MCP Server 开发实战：无缝对接 LLM 和 Elasticsearch\",\"link\":\"/blogs/original//2025/02-elasticsearch-mcp-server\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">18</div>一文带你入门 MCP（模型上下文协议）\",\"link\":\"/blogs/original//2025/01-mcp\"}],\"collapsed\":false},{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/dragon.svg\\\" title=\\\"龙年\\\" alt=\\\"生肖\\\">\\n            2024年 (3篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>使用 Higress AI 插件对接通义千问大语言模型\",\"link\":\"/blogs/original//2024/03-higress-ai-plugins\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>深入剖析 Kubernetes 原生 Sidecar 容器\",\"link\":\"/blogs/original//2024/02-sidecar-containers\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Crossplane 实战：构建统一的云原生控制平面\",\"link\":\"/blogs/original//2024/01-crossplane\"}],\"collapsed\":false},{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/rabbit.svg\\\" title=\\\"兔年\\\" alt=\\\"生肖\\\">\\n            2023年 (10篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>使用 Containerlab + Kind 快速部署 Cilium BGP 环境\",\"link\":\"/blogs/original//2023/10-cilium-bgp\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>使用 ClusterResourceSet 为 Cluster API 集群自动安装 CNI 插件\",\"link\":\"/blogs/original//2023/09-clusterresourceset\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Cilium 多集群 Cluster Mesh 介绍\",\"link\":\"/blogs/original//2023/08-cilium-cluster-mesh\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>vCluster -- 基于虚拟集群的多租户方案\",\"link\":\"/blogs/original//2023/07-vcluster\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>Kubernetes 多集群网络方案系列 2 -- Submariner 监控\",\"link\":\"/blogs/original//2023/06-kubernetes-multi-cluster-2\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>Kubernetes 多集群网络方案系列 1 -- Submariner 介绍\",\"link\":\"/blogs/original//2023/05-kubernetes-multi-cluster-1\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>在 Kubernetes 中使用 Keycloak OIDC Provider 对用户进行身份验证\",\"link\":\"/blogs/original//2023/04-kubernetes-keycloak-oidc\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>使用 Kubectl Patch 命令更新资源\",\"link\":\"/blogs/original//2023/03-kubectl-patch\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>WebAssembly 在云原生中的实践指南\",\"link\":\"/blogs/original//2023/02-wasm-in-cloud-native\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>ArgoCD 简明教程\",\"link\":\"/blogs/original//2023/01-argocd-quickstart\"}],\"collapsed\":false},{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/tiger.svg\\\" title=\\\"虎年\\\" alt=\\\"生肖\\\">\\n            2022年 (13篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>使用 Envoy 作为前端代理\",\"link\":\"/blogs/original//2022/13-envoy-quickstart\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>实现 LRU 缓存算法\",\"link\":\"/blogs/original//2022/12.lru\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Nebula 分布式图数据库介绍\",\"link\":\"/blogs/original//2022/11.nebula\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>Habor 部署指南\",\"link\":\"/blogs/original//2022/10-harbor\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>Pulsar 介绍与部署\",\"link\":\"/blogs/original//2022/09-pulsar\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>如何重置 Kafka 中的 Consumer Offset？\",\"link\":\"/blogs/original//2022/08-reset-kafka-consumer-offset\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>如何往 Kafka 发送大消息？\",\"link\":\"/blogs/original//2022/07-kafka-big-message\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>Kafka 生产环境部署指南\",\"link\":\"/blogs/original//2022/06-kafka-setup\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>Docker Rootless 在非特权模式下运行 Docker\",\"link\":\"/blogs/original//2022/05-docker-rootless\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>使用 ezctl 工具部署和管理 Kubernetes 集群\",\"link\":\"/blogs/original//2022/04-kubeasz\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>Kubernetes 中的对象是如何删除的：Finalizers 字段介绍\",\"link\":\"/blogs/original//2022/03-finalizer\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">12</div>Kubectl debug 调试容器\",\"link\":\"/blogs/original//2022/02-kubectl-debug\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">13</div>Kubenetes 高可用集群搭建\",\"link\":\"/blogs/original//2022/01-kubernetes-setup\"}],\"collapsed\":false}],\"/blogs/translate/\":[{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/rabbit.svg\\\" title=\\\"兔年\\\" alt=\\\"生肖\\\">\\n            2023年 (7篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Git 速查表：专家必备的 14 个 Git 命令\",\"link\":\"/blogs/translate//2023/07-git-cheat-sheet-3\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>Git 速查表：中级用户必备的 12 个 Git 命令\",\"link\":\"/blogs/translate//2023/06-git-cheat-sheet-2\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Git 速查表：初学者必备的 12 个 Git 命令\",\"link\":\"/blogs/translate//2023/05-git-cheat-sheet-1\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>Kubernetes 中数据包的生命周期 -- 第 4 部分\",\"link\":\"/blogs/translate//2023/04-life-of-a-packet-in-kubernetes-part-4\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>Kubernetes 中数据包的生命周期 -- 第 3 部分\",\"link\":\"/blogs/translate//2023/03-life-of-a-packet-in-kubernetes-part-3\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>Kubernetes 中数据包的生命周期 -- 第 2 部分\",\"link\":\"/blogs/translate//2023/02-life-of-a-packet-in-kubernetes-part-2\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>Kubernetes 中数据包的生命周期 -- 第 1 部分\",\"link\":\"/blogs/translate//2023/01-life-of-a-packet-in-kubernetes-part-1\"}],\"collapsed\":false}],\"/courses/elastic-stack/\":[{\"text\":\"Elastic Stack 实战教程 (5篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Elastic Stack 8 快速上手\",\"link\":\"/courses/elastic-stack/Elastic Stack 实战教程/01-quick-start\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>ILM 索引生命周期管理\",\"link\":\"/courses/elastic-stack/Elastic Stack 实战教程/02-ilm\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>快照备份与恢复\",\"link\":\"/courses/elastic-stack/Elastic Stack 实战教程/03-snapshot\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>使用 Fleet 管理 Elastic Agent 监控应用\",\"link\":\"/courses/elastic-stack/Elastic Stack 实战教程/04-fleet\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>Elasticsearch Java API Client 开发\",\"link\":\"/courses/elastic-stack/Elastic Stack 实战教程/05-java-client\"}],\"collapsed\":false}],\"/courses/ai-infra/\":[{\"text\":\"AI Infra 教程 (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>vLLM 快速部署指南\",\"link\":\"/courses/ai-infra/AI Infra 教程/01-vllm-quickstart\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>vLLM 核心技术 PagedAttention 原理详解\",\"link\":\"/courses/ai-infra/AI Infra 教程/02-pagedattention\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Prefix Caching 详解：实现 KV Cache 的跨请求高效复用\",\"link\":\"/courses/ai-infra/AI Infra 教程/03-prefix-caching\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>Speculative Decoding 推测解码方案详解\",\"link\":\"/courses/ai-infra/AI Infra 教程/04-speculative-decoding\"}],\"collapsed\":false}],\"/courses/observability/\":[{\"text\":\"OpenTelemetry (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>OpenTelemetry × Elastic Observability 系列（一）：整体架构介绍\",\"link\":\"/courses/observability/OpenTelemetry/01-opentelemetry-elastic\"}],\"collapsed\":false}],\"/courses/interview/\":[{\"text\":\"AI (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>AI\",\"link\":\"/courses/interview/AI/01-ai\"}],\"collapsed\":false},{\"text\":\"Elastic Stack (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Elasticsearch\",\"link\":\"/courses/interview/Elastic Stack/01-elasticsearch\"}],\"collapsed\":false},{\"text\":\"云原生 (7篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Kubernetes\",\"link\":\"/courses/interview/云原生/01-kubernetes\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>容器\",\"link\":\"/courses/interview/云原生/02-container\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>存储\",\"link\":\"/courses/interview/云原生/03-storage\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>网络\",\"link\":\"/courses/interview/云原生/04-network\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>安全\",\"link\":\"/courses/interview/云原生/05-security\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>发布\",\"link\":\"/courses/interview/云原生/06-rollout\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>Operator\",\"link\":\"/courses/interview/云原生/07-operator\"}],\"collapsed\":false},{\"text\":\"大数据 (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>消息队列\",\"link\":\"/courses/interview/大数据/01-message-queue\"}],\"collapsed\":false},{\"text\":\"操作系统 (5篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>CPU\",\"link\":\"/courses/interview/操作系统/01-cpu\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>内存\",\"link\":\"/courses/interview/操作系统/02-memory\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>存储\",\"link\":\"/courses/interview/操作系统/03-storage\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>网络\",\"link\":\"/courses/interview/操作系统/04-network\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>cgroup\",\"link\":\"/courses/interview/操作系统/05-cgroup\"}],\"collapsed\":false},{\"text\":\"编程语言 (3篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Golang\",\"link\":\"/courses/interview/编程语言/01-golang\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>Python\",\"link\":\"/courses/interview/编程语言/02-python\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>数据结构与算法\",\"link\":\"/courses/interview/编程语言/03-algorithm\"}],\"collapsed\":false}],\"/courses/algorithm/\":[{\"text\":\"算法 (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Hot 100 算法题\",\"link\":\"/courses/algorithm/算法/01-hot100\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>算法解题套路框架\",\"link\":\"/courses/algorithm/算法/02-template\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>经典设计问题\",\"link\":\"/courses/algorithm/算法/03-design-problem\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>Shell 命令\",\"link\":\"/courses/algorithm/算法/04-shell\"}],\"collapsed\":false}],\"/meetup/network/\":[{\"text\":\"network (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>CNI (Container Network Interface)\",\"link\":\"/meetup/network/01-network/01-cni\"}],\"collapsed\":false}]},\"sidebarCollapsible\":false,\"logo\":\"/logo.png\",\"outline\":{\"level\":\"deep\",\"label\":\"目录\"},\"darkModeSwitchLabel\":\"切换日光/暗黑模式\",\"sidebarMenuLabel\":\"文章\",\"returnToTopLabel\":\"返回顶部\",\"lastUpdatedText\":\"最后更新\",\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"editLink\":{\"pattern\":\"https://github.com/cr7258/cr7258.github.io/edit/main/docs/:path\",\"text\":\"不妥之处，敬请雅正\"},\"search\":{\"provider\":\"local\",\"options\":{\"locales\":{\"root\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\"}}}}}}},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/cr7258/cr7258.github.io\"}],\"articleMetadataConfig\":{\"author\":\"Se7en\",\"authorLink\":\"/about/me\",\"showViewCount\":false},\"copyrightConfig\":{\"license\":\"署名-相同方式共享 4.0 国际 (CC BY-SA 4.0)\",\"licenseLink\":\"http://creativecommons.org/licenses/by-sa/4.0/\"},\"commentConfig\":{\"type\":\"gitalk\",\"showComment\":true},\"footerConfig\":{\"showFooter\":true,\"copyright\":\"Copyright  2023-2025 Se7en\"}},\"locales\":{\"root\":{\"label\":\"中文\",\"lang\":\"zh\"},\"en\":{\"label\":\"English\",\"lang\":\"en\"}},\"scrollOffset\":90,\"cleanUrls\":true}");</script>
    
  </body>
</html>