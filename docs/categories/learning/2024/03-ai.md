---
title: AI
author: Se7en
date: 2024/09/21 09:00
categories:
 - AI
tags:
 - AI
 - GPU
---

## CUDA

CUDA 可以分为 Grid，Block 和 Thread 三个层次结构：

- 线程层次结构Ⅰ-Grid：kernel 在 device 上执行时，实际上是启动很多线程，一个 kernel 所启动的所有线程称为一个网格（grid），同一个网格上的线程共享相同的全局内存空间，grid 是线程结构的第一层次。
- 线程层次结构Ⅱ-Block：Grid 分为多个线程块（block），一个 block 里面包含很多线程，Block 之间并行执行，并且无法通信，也没有执行顺序，每个 block 包含共享内存（shared memory），可以共享里面的 Thread。
- 线程层次结Ⅲ-Thread：CUDA 并行程序实际上会被多个 threads 执行，多个 threads 会被群组成一个线程 block，同一个 block 中 threads 可以同步，也可以通过 shared memory 通信。

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302346976.png)

因此 CUDA 和英伟达硬件架构有以下对应关系，从软件侧看到的是线程的执行，对应于硬件上的 CUDA Core，每个线程对应于 CUDA Core，软件方面线程数量是超配的，硬件上 CUDA Core 是固定数量的。Block 线程块只在一个 SM 上通过 Warp 进行调度，一旦在 SM 上调用了 Block 线程块，就会一直保留到执行完 kernel，SM 可以同时保存多个 Block 线程块，多个 SM 组成的 TPC 和 GPC 硬件实现了 GPU 并行计算。

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302347553.png)

## 分布式并行

- **数据并行**是将整个数据集划分为多个子集，每个子集在不同的计算设备上进行处理。每个设备都使用相同的模型参数，但处理不同的数据部分。
- **张量并行**是将模型的参数或计算过程在多个设备上进行切分，允许在不同设备上并行处理模型的不同部分。这种方法特别适合于大型深度学习模型，尤其是当单个设备无法容纳整个模型时。
- **流水线并行**是一种将模型按层切分的方法，不同层放置在不同的计算节点上。数据流通过这些层，形成一个流水线，允许在一个 batch 结束前开始下一个 batch 的处理。



## 分布式训练

### 通信协调

#### 硬件

#### 软件

### 集合式通信方式

- 一对多：Scatter / Broadcast
- 多对一：Gather / Reduce
- 多对多：All-Reduce / All-Gather

https://juejin.cn/post/7063102006059237406#heading-3

### 分布式训练与模型算法关系

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410301920531.png)

### 分布式架构

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302131703.png)

## AI 集群

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302033413.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302032477.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410301939303.png)

### 为什么需要 AI 集群？

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302052602.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302053183.png)  

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302057787.png)

### AI 集群训练的关键指标

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302105850.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302108683.png)

### AI 集群的硬件组成

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302114930.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302114055.png)


## 数据存储

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302154838.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302156214.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302157018.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302158014.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302159069.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302201467.png)

### 大模型训练的存储优化方案

训练之前的存储优化

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302219909.png)

训练流程的存储优化

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302226519.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302228491.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302229066.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302236711.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302239875.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302241706.png)

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202410302243748.png)



