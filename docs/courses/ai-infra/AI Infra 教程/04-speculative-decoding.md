---
title: Speculative Decoding æ¨æµ‹è§£ç æ–¹æ¡ˆè¯¦è§£
author: Se7en
date: 2025/06/22 20:00
categories:
 - AI Infra æ•™ç¨‹
tags:
 - AI
 - LLM
 - Inference
---

## Speculative Decoding æ¨æµ‹è§£ç æ–¹æ¡ˆè¯¦è§£

Speculative Decoding æ¨æµ‹è§£ç æ–¹æ¡ˆçš„è®²è§£è§†é¢‘å¯ä»¥åœ¨è¿™é‡Œè§‚çœ‹ï¼šhttps://www.bilibili.com/video/BV1Q5KWzQEhn

æœ¬æ–‡æ˜¯ LLM æ¨ç†ç³»åˆ—çš„ç¬¬ 4 ç¯‡ï¼Œä»‹ç» Speculative Decoding æ¨æµ‹è§£ç æ–¹æ¡ˆè¯¦è§£ï¼Œè¯¦ç»†ä»‹ç»äº† EAGLEã€Medusaã€Lookahead ç­‰ä¸»æµçš„ Speculative Decoding æ–¹æ¡ˆã€‚

å¾€æœŸæ–‡ç« ï¼š

- [vLLM å¿«é€Ÿéƒ¨ç½²æŒ‡å—](https://mp.weixin.qq.com/s/rVW6jjLQabHGMMwnbIzB7Q)
- [vLLM æ ¸å¿ƒæŠ€æœ¯ PagedAttention åŸç†è¯¦è§£](https://mp.weixin.qq.com/s/94-kEyHui0BLO5S-80eAiw)
- [Prefix Caching è¯¦è§£ï¼šå®ç° KV Cache çš„è·¨è¯·æ±‚é«˜æ•ˆå¤ç”¨](https://mp.weixin.qq.com/s/_FnXC7hiQtwyzU-ISvU0CA)

å½“å‰ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†é˜¶æ®µæ™®éé‡‡ç”¨è‡ªå›å½’è§£ç ç­–ç•¥ï¼Œå…¶æ ¸å¿ƒç‰¹æ€§æ˜¯**é€æ­¥ä¸²è¡Œç”Ÿæˆ tokenï¼Œæ¯ä¸€æ­¥éƒ½ä¾èµ–å‰ä¸€æ­¥çš„è¾“å‡º**ã€‚è¿™ä¸€è®¡ç®—æ¨¡å¼å¯¼è‡´æ¨ç†è¿‡ç¨‹åœ¨ç³»ç»Ÿå±‚é¢é¢ä¸´ä¸¥é‡çš„**å†…å­˜å¸¦å®½ç“¶é¢ˆ**ï¼šæ¯ä¸€æ­¥å‰å‘è®¡ç®—éƒ½éœ€è¦å°†**å®Œæ•´çš„æ¨¡å‹å‚æ•°ä»é«˜å¸¦å®½å†…å­˜ï¼ˆHBMï¼‰åŠ è½½åˆ°åŠ é€Ÿå™¨ç¼“å­˜**ï¼Œä½†ä»…ç”Ÿæˆä¸€ä¸ª tokenã€‚ç”±äºæ¯æ¬¡åªç”Ÿæˆä¸€ä¸ª tokenï¼Œå¯¼è‡´å¤§é‡çš„è®¡ç®—èµ„æºè¢«é—²ç½®ï¼Œæ— æ³•å……åˆ†å‘æŒ¥åŠ é€Ÿå™¨çš„ç®—åŠ›æ½œåŠ›ï¼Œæœ€ç»ˆé€ æˆæ•´ä½“æ¨ç†æ•ˆç‡ä½ä¸‹ã€‚

ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œä¸€ç§åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„æ€è·¯æ˜¯**æé«˜è§£ç è¿‡ç¨‹çš„ç®—æœ¯å¼ºåº¦**ï¼ˆå³æ€»æµ®ç‚¹è¿ç®—æ¬¡æ•° FLOPs ä¸æ•°æ®ä¼ è¾“é‡ä¹‹é—´çš„æ¯”å€¼ï¼‰ï¼ŒåŒæ—¶**å‡å°‘è§£ç æ­¥éª¤**ã€‚åŸºäºè¿™ä¸€ç†å¿µï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†**æ¨æµ‹è§£ç /æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰** æŠ€æœ¯ã€‚Speculative Decoding çš„æ ¸å¿ƒæ€è·¯å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé¦–å…ˆä»¥ä½æˆæœ¬çš„æ–¹å¼ï¼ˆä¸€èˆ¬æ¥è¯´æ˜¯ç”¨å°æ¨¡å‹ï¼‰å¿«é€Ÿç”Ÿæˆå¤šä¸ªå€™é€‰ tokenï¼Œç„¶åé€šè¿‡ä¸€æ¬¡å¹¶è¡ŒéªŒè¯é˜¶æ®µå¿«é€ŸéªŒè¯å¤šä¸ª tokenï¼Œè¿›è€Œå‡å°‘å¤§æ¨¡å‹çš„ decode æ¬¡æ•°ï¼Œä»è€Œè¾¾åˆ°åŠ é€Ÿçš„ç›®çš„ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221203921.png)

è¿™ç§æ–¹æ³•åœ¨å®é™…ä¸­ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºå¤§å¤šæ•°æ—¶å€™è‰ç¨¿æ¨¡å‹ç”Ÿæˆçš„ token éƒ½ä¼šè¢«æ¥å—ã€‚è¿™äº› token æœ¬èº«å°±å®¹æ˜“é¢„æµ‹ï¼Œå³ä½¿æ˜¯ä¸€ä¸ªå°å¾—å¤šçš„è‰ç¨¿æ¨¡å‹ä¹Ÿèƒ½å‡†ç¡®ç”Ÿæˆã€‚å½“è¿™äº›å®¹æ˜“çš„ token è¢«æ¥å—æ—¶ï¼Œæ¨¡å‹å°±å¯ä»¥å¿«é€Ÿè·³è¿‡è¿™äº›éƒ¨åˆ†ã€‚å¯¹äºé‚£äº›è¾ƒéš¾é¢„æµ‹çš„ tokenï¼Œå¦‚æœç›®æ ‡å¤§æ¨¡å‹ä¸åŒæ„è‰ç¨¿æ¨¡å‹çš„è¾“å‡ºï¼Œå°±ä¼šé€€å›åˆ°åŸå§‹çš„è§£ç é€Ÿåº¦ï¼Œç”šè‡³ç•¥å¾®å˜æ…¢ï¼Œå› ä¸ºè¿˜éœ€è¦è¿›è¡Œé¢å¤–çš„éªŒè¯è®¡ç®—ã€‚

è¿™é‡Œä¸¾ä¸¤ä¸ªä¾‹å­ï¼š

æ¯”å¦‚ prompt æ˜¯ `The capital of South Korea is ?`ï¼Œé‚£ä¹ˆè¾“å‡ºå¤§æ¦‚ç‡æ˜¯ `The capital of` å¼€å¤´ï¼Œè¿™äº› token éƒ½å¾ˆå¸¸è§ï¼Œè‰ç¨¿æ¨¡å‹å¾ˆå®¹æ˜“é¢„æµ‹æ­£ç¡®ï¼Œå› æ­¤å¯ä»¥è¢«ç›®æ ‡æ¨¡å‹æ¥å—ï¼Œå¿«é€Ÿè·³è¿‡ã€‚

åœ¨ä»£ç æç¤ºçš„åœºæ™¯ä¸‹ï¼Œä¹Ÿå¾ˆå¥½é¢„æµ‹ï¼Œæ¯”å¦‚ prompt æ˜¯ï¼š

```python
å¾ªç¯ä»¥ä¸‹æ•°ç»„ï¼š
nums = [1, 2, 3]
```

è¾“å‡ºå¤§æ¦‚ç‡æ˜¯ï¼š

```python
for num in nums:
    xxx
```

## 1 åœ¨ vLLM ä¸­ä½¿ç”¨ Speculative Decoding

åœ¨ vLLM ä¸­å¯ä»¥é€šè¿‡ `speculative_config` å‚æ•°æ¥ä½¿ç”¨ Speculative Decodingã€‚ä»¥ä¸‹ä»£ç é€šè¿‡ç¦»çº¿æ¨¡å¼ä½¿ç”¨è‰ç¨¿æ¨¡å‹è¿›è¡Œ Speculative Decodingï¼Œæ¯æ¬¡æ¨æµ‹ 5 ä¸ª tokenã€‚

```python
from vllm import LLM, SamplingParams

prompts = [
    "The future of AI is",
]
sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

llm = LLM(
    model="facebook/opt-6.7b",
    tensor_parallel_size=1,
    speculative_config={
        "model": "facebook/opt-125m",
        "num_speculative_tokens": 5,
    },
)
outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f"Prompt: {prompt!r}, Generated text: {generated_text!r}")
```

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ä»¥ä»¥åœ¨çº¿æ¨¡å¼è¿è¡Œ Speculative Decodingã€‚

```bash
vllm serve \
  --model facebook/opt-6.7b \
  --speculative_config '{"model": "facebook/opt-125m", "num_speculative_tokens": 5}'
```

## 2 æ—©æœŸçš„ Speculative Decoding

> è®ºæ–‡ï¼š
>
> Fast Inference from Transformers via Speculative Decodingï¼šhttps://arxiv.org/abs/2211.17192
>
> Accelerating Large Language Model Decoding with Speculative Samplingï¼šhttps://arxiv.org/abs/2302.01318

Speculative Decoding æœ€æ—©æºè‡ª Google åœ¨ 2023 å¹´å‘è¡¨çš„ä¸€ç¯‡è®ºæ–‡ï¼Œæ ‡é¢˜ä¸º **"Fast Inference from Transformers via Speculative Decoding"**ï¼Œè¯¥è®ºæ–‡é¦–æ¬¡æå‡ºäº†é€šè¿‡â€œè‰ç¨¿æ¨¡å‹ + éªŒè¯æ¨¡å‹â€çš„æ–¹å¼æ¥åŠ é€Ÿ Transformer æ¨¡å‹çš„æ¨ç†ã€‚

åŒä¸€æ—¶æœŸï¼ŒDeepMind ä¹Ÿç‹¬ç«‹å‘å¸ƒäº†å¦ä¸€ç¯‡ç›¸å…³è®ºæ–‡ **"Accelerating Large Language Model Decoding with Speculative Sampling"**ï¼Œå…¶èƒŒåçš„æ ¸å¿ƒæ€æƒ³ä¸ Google çš„è¿™ç¯‡ç±»ä¼¼ã€‚

ä¸‹å›¾å±•ç¤ºäº† Speculative Decoding ç®—æ³•çš„æ‰§è¡Œæµç¨‹ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506141646185.png)

ä¸ºäº†æ›´ç›´è§‚åœ°ç†è§£ Speculative Decoding ç®—æ³•çš„æ‰§è¡Œæµç¨‹ï¼Œæˆ‘ä»¬ä»¥ä¸‹é¢çš„åœºæ™¯ä¸ºä¾‹ï¼Œèµ°ä¸€éæ•´ä¸ªç”Ÿæˆè¿‡ç¨‹ã€‚

å‡è®¾å½“å‰çš„ä¸Šä¸‹æ–‡ä¸ºï¼š`"This apple"`ï¼Œè¯è¡¨å¦‚ä¸‹ï¼š

```python
vocab = ["This", "apple", "is", "very", "delicious", "bad", "today"]
```

æœ¬è½®è‰ç¨¿é•¿åº¦ K=2ï¼Œä¹Ÿå°±æ˜¯è¯´è‰ç¨¿æ¨¡å‹ `p` å°†å°è¯•ç”Ÿæˆä¸¤ä¸ª tokenã€‚

**ç¬¬ä¸€æ­¥ï¼šè‰ç¨¿æ¨¡å‹ç”Ÿæˆ token**

è‰ç¨¿æ¨¡å‹ `p` æ˜¯ä¸€ä¸ªè½»é‡çš„è‡ªå›å½’æ¨¡å‹ã€‚æ¯ä¸€æ­¥ä¼šè®¡ç®— logitsï¼Œå¹¶é€šè¿‡ softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒï¼Œä»ä¸­é‡‡æ ·å‡ºä¸‹ä¸€ä¸ª tokenã€‚**è‰ç¨¿æ¨¡å‹å¯¹æ¯ä¸ªç”Ÿæˆ token çš„æ¦‚ç‡ï¼ˆå³ softmax åçš„å€¼ï¼‰ä¼šè¢«ä¿ç•™ï¼Œç”¨äºä¹‹åç›®æ ‡æ¨¡å‹çš„éªŒåˆ†è¿‡ç¨‹ã€‚**

```python
# åŸºäºä¸Šä¸‹æ–‡ "This apple"ï¼Œé¢„æµ‹å‡ºä¸‹ä¸€ä¸ª tokenï¼š
p_logits_1 = [1.5, 1.8, 2.5, 1.1, 0.3, 0.05, -1.0]  # è‰ç¨¿æ¨¡å‹ logits for "This apple"
p_probs_1 = softmax(p_logits_1)                     # è‰ç¨¿æ¨¡å‹è®¡ç®— softmax æ¦‚ç‡
# â†’ è‰ç¨¿æ¨¡å‹ç”Ÿæˆï¼šğ‘¥Ìƒâ‚ = "is"

# æ¥ç€ä»¥ "This apple is" ä¸ºä¸Šä¸‹æ–‡ç»§ç»­é¢„æµ‹ï¼š
p_logits_2 = [0.7, 0.9, 1.0, 1.3, 0.4, 0.1, -0.8]  # è‰ç¨¿æ¨¡å‹ logits for "This apple is"
p_probs_2 = softmax(p_logits_2)                    # è‰ç¨¿æ¨¡å‹è®¡ç®— softmax æ¦‚ç‡
# â†’ è‰ç¨¿æ¨¡å‹ç”Ÿæˆï¼šğ‘¥Ìƒâ‚‚ = "very"
```

**ç¬¬äºŒæ­¥ï¼šç›®æ ‡æ¨¡å‹å¹¶è¡Œè®¡ç®— logits**

ç›®æ ‡æ¨¡å‹ `q` æ˜¯è¾ƒå¤§ä½†æ›´ç²¾ç¡®çš„æ¨¡å‹ï¼Œå¾—ç›Šäºè‰ç¨¿ token å·²ç»ç”Ÿæˆå®Œæ¯•ï¼Œå¯ä»¥**å¹¶è¡Œåœ°**å¯¹è‰ç¨¿åºåˆ—çš„æ¯ä¸ªä½ç½®è¿›è¡Œæ‰“åˆ†ï¼ˆå³è®¡ç®— logitsï¼‰ï¼Œä»è€ŒåŠ å¿«éªŒåˆ†è¿‡ç¨‹ã€‚

```python
q_logits_1 = [1.8, 2.0, 2.2, 1.2, 0.5, 0.1, -0.7]   # ç›®æ ‡æ¨¡å‹ q(x | "This apple")
q_logits_2 = [0.9, 1.1, 1.0, 1.1, 0.7, 0.2, -0.5]   # q(x | "This apple is")
q_logits_3 = [0.5, 0.4, 1.2, 0.7, 2.5, -0.2, 0.0]   # q(x | "This apple is very")

q_probs_1 = softmax(q_logits_1)
q_probs_2 = softmax(q_logits_2)
```

**ç¬¬ä¸‰æ­¥ï¼šç›®æ ‡æ¨¡å‹å¯¹è‰ç¨¿ token éªŒåˆ†**

å¯¹ç¬¬ä¸€ä¸ªè‰ç¨¿ tokenï¼š`ğ‘¥Ìƒâ‚ = "is"`ï¼Œåˆ†åˆ«æŸ¥æ‰¾ä¸¤ä¸ªæ¨¡å‹è®¡ç®—å‡ºçš„ softmax æ¦‚ç‡ï¼š

```python
# æå– token "is" å¯¹åº”çš„æ¦‚ç‡ï¼š
p_prob = p_probs_1["is"]  # è‰ç¨¿æ¨¡å‹è®¡ç®—çš„æ¦‚ç‡
q_prob = q_probs_1["is"]  # ç›®æ ‡æ¨¡å‹è®¡ç®—çš„æ¦‚ç‡

# å‡è®¾ï¼š
p_prob = 0.30
q_prob = 0.22
```

è®¡ç®—æ¥å—æ¦‚ç‡ï¼š

$$
\text{acceptprob}_1 = \min\left(1,\ \frac{qprob}{pprob} \right) = \min(1,\ \frac{0.22}{0.30}) = 0.733
$$

å‡è®¾é‡‡æ ·å‡ºçš„éšæœºæ•° $r_1 = 0.42$ï¼Œå› ä¸ºï¼š

$$
0.42 < 0.733 \quad \Rightarrow \quad æ¥å— "is"
$$

å¯¹ç¬¬äºŒä¸ªè‰ç¨¿ tokenï¼š`ğ‘¥Ìƒâ‚‚ = "very"`ï¼š

```python
p_prob = p_probs_2["very"] = 0.28  # è‰ç¨¿æ¨¡å‹è®¡ç®—çš„æ¦‚ç‡
q_prob = q_probs_2["very"] = 0.24  # ç›®æ ‡æ¨¡å‹è®¡ç®—çš„æ¦‚ç‡
```

$$
\text{acceptprob}_2 = \min\left(1,\ \frac{0.24}{0.28} \right) = 0.857
$$

éšæœºæ•° $r_2 = 0.62$ï¼Œå› ä¸ºï¼š

$$
0.62 < 0.857 \quad \Rightarrow \quad æ¥å— "very"
$$


**ç¬¬å››æ­¥ï¼šç”Ÿæˆå¥–åŠ± tokenï¼ˆbonus tokenï¼‰**

å› ä¸ºè‰ç¨¿ä¸­çš„æ‰€æœ‰ token éƒ½é€šè¿‡äº†ç›®æ ‡æ¨¡å‹çš„éªŒåˆ†ï¼Œæˆ‘ä»¬ä½¿ç”¨äº‹å…ˆè®¡ç®—å¥½çš„ï¼š

```text
q(x | "This apple is very") â†’ q_logits_3
```

å¯¹å…¶è¿›è¡Œ softmax æ“ä½œï¼Œå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒã€‚å‡è®¾é‡‡ç”¨è´ªå¿ƒè§£ç ç­–ç•¥ï¼Œåˆ™é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ tokenã€‚

```python
q_logits_3 = [0.5, 0.4, 1.2, 0.7, 2.5, -0.2, 0.0]
# softmax å "delicious" æ¦‚ç‡æœ€å¤§
```

å› æ­¤ç”Ÿæˆå¥–åŠ± tokenï¼š

```text
xâ‚™â‚Šâ‚–â‚Šâ‚ = "delicious"
```

## 3 è‰ç¨¿æ¨¡å‹çš„é™åˆ¶

è™½ç„¶ Speculative Decoding é€šè¿‡â€œçŒœæµ‹-éªŒè¯â€ç­–ç•¥ï¼Œåœ¨å¤šä¸ªåœºæ™¯ä¸‹æ˜¾è‘—æå‡äº†è§£ç é€Ÿåº¦ï¼Œä½†è‰ç¨¿æ¨¡å‹ä»ç„¶å­˜åœ¨ä»¥ä¸‹é™åˆ¶ï¼š

- **æ¥å—ç‡å—é™ï¼ŒåŠ é€Ÿæ•ˆæœä¸ç¨³å®š**ï¼šè‰ç¨¿æ¨¡å‹çš„é¢„æµ‹ç»“æœå¿…é¡»é€šè¿‡å¤§æ¨¡å‹çš„éªŒè¯æ‰èƒ½è¢«æ¥å—ã€‚åŠ é€Ÿæ•ˆæœé«˜åº¦ä¾èµ– token çš„æ¥å—ç‡ï¼ˆAcceptance Rateï¼‰ã€‚ä¸€æ—¦æ¥å—ç‡è¾ƒä½ï¼Œä¸ä»…æ— æ³•æå‡æ€§èƒ½ï¼Œåè€Œä¼šå› ä¸ºé‡å¤éªŒè¯å’Œå›é€€è€Œæ‹–æ…¢æ•´ä½“è§£ç é€Ÿåº¦ã€‚
- **éš¾ä»¥è·å¾—â€œåˆå°åˆå‡†â€çš„æ¨¡å‹**ï¼šè¦è®©è‰ç¨¿æ¨¡å‹æ—¢è½»é‡åˆèƒ½ç²¾å‡†æ¨¡æ‹Ÿå¤§æ¨¡å‹çš„è¡Œä¸ºéå¸¸å›°éš¾ã€‚ç°å®ä¸­ç»å¸¸å‡ºç° distribution shiftï¼ˆåˆ†å¸ƒåç§»ï¼‰ï¼Œå³è‰ç¨¿æ¨¡å‹ä¸å¤§æ¨¡å‹è¾“å‡ºä¹‹é—´å­˜åœ¨å·®å¼‚ï¼Œå¯¼è‡´é¢„æµ‹å¤±è´¥ç‡ä¸Šå‡ã€‚
- **è®­ç»ƒå’Œæ³›åŒ–å›°éš¾**ï¼šå¾ˆå¤š LLM å¹¶æ²¡æœ‰ç°æˆçš„è‰ç¨¿æ¨¡å‹ï¼Œå› æ­¤éœ€è¦é‡æ–°è®­ç»ƒä¸€ä¸ªé¢å¤–æ¨¡å‹ï¼Œè¿™å¸¦æ¥äº†æ˜¾è‘—çš„æˆæœ¬ã€‚è€Œä¸”è®­ç»ƒå‡ºçš„æ¨¡å‹å¾€å¾€æ— æ³•æ³›åŒ–åˆ°å…¶ä»–åŸºç¡€æ¨¡å‹æˆ–æ•°æ®é›†ä¸Šï¼Œéœ€è¦é¢‘ç¹åœ°è°ƒä¼˜å’Œç»´æŠ¤ã€‚
- **ç³»ç»Ÿæ¶æ„å¤æ‚åº¦ä¸Šå‡**ï¼šåŒæ—¶ç»´æŠ¤ä¸¤ä¸ªæ¨¡å‹ï¼ˆè‰ç¨¿æ¨¡å‹ + ç›®æ ‡æ¨¡å‹ï¼‰ä¼šå¢åŠ æ¨ç†ç³»ç»Ÿçš„å¤æ‚æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†å¸ƒå¼éƒ¨ç½²ä¸­ï¼Œéœ€è¦è§£å†³æ¨¡å‹è°ƒåº¦ã€èµ„æºéš”ç¦»å’Œè´Ÿè½½å‡è¡¡ç­‰å·¥ç¨‹é—®é¢˜ã€‚

## 4 Prompt Lookup Decoding

åœ¨è®¸å¤šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œä¾‹å¦‚æ‘˜è¦ç”Ÿæˆã€æ–‡æ¡£é—®ç­”ã€å¤šè½®å¯¹è¯å’Œä»£ç ç¼–è¾‘ï¼Œæ¨¡å‹çš„è¾“å…¥ï¼ˆpromptï¼‰ä¸è¾“å‡ºä¹‹é—´å¾€å¾€å­˜åœ¨å¤§é‡çš„ **n-gramï¼ˆè¿ç»­ token ç‰‡æ®µï¼‰é‡åˆ**ã€‚è¿™äº›é‡åˆå†…å®¹é€šå¸¸æ˜¯å®ä½“åç§°ã€å¸¸è§çŸ­è¯­æˆ–ä»£ç ç‰‡æ®µï¼Œæ¨¡å‹åœ¨ç”Ÿæˆæ—¶å¸¸å¸¸ç›´æ¥ä»è¾“å…¥ä¸­å¤åˆ¶å®ƒä»¬ã€‚

**Prompt Lookup Decoding** æ­£æ˜¯åˆ©ç”¨äº†è¿™ä¸€è§„å¾‹ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åŠ é€Ÿè‡ªå›å½’è§£ç ã€‚å®ƒé€šè¿‡é«˜æ•ˆçš„å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•ï¼ˆå¦‚ KMPï¼‰å¿«é€Ÿå®šä½åŒ¹é…ä½ç½®ï¼Œç›´æ¥åˆ©ç”¨ prompt ä¸­å·²æœ‰çš„ä¿¡æ¯è¿›è¡Œé¢„æµ‹ï¼Œè€Œ**æ— éœ€ä¾èµ–é¢å¤–çš„è‰ç¨¿æ¨¡å‹**ç”Ÿæˆå€™é€‰ tokenã€‚å°¤å…¶åœ¨æ¨¡å‹è¾“å‡ºé«˜åº¦é‡å¤ prompt å†…å®¹çš„åœºæ™¯ä¸‹ï¼Œè¿™ç§æ–¹æ³•èƒ½æ˜¾è‘—æå‡æ¨ç†æ•ˆç‡ã€‚å½“å¤§æ¨¡å‹åœ¨ç­”æ¡ˆä¸­é‡å¤ prompt çš„å†…å®¹æ—¶ï¼Œè¿™ç§æ–¹æ³•æ•ˆæœå°¤ä¸ºæ˜¾è‘—ã€‚

> vLLM çš„ n-gram Speculative Decoding ä¸ä»…ä»…ä½¿ç”¨åŸå§‹æç¤ºè¿›è¡ŒåŒ¹é…ï¼Œè€Œæ˜¯ä½¿ç”¨æ•´ä¸ªä¸Šä¸‹æ–‡åºåˆ—ï¼ˆåŒ…æ‹¬åŸå§‹æç¤ºå’Œå·²ç”Ÿæˆçš„æ ‡è®°ï¼‰ã€‚æ¯æ¬¡ç”Ÿæˆæ–°æ ‡è®°åï¼Œæ•´ä¸ªä¸Šä¸‹æ–‡åºåˆ—éƒ½ä¼šæ›´æ–°ï¼Œç„¶åç”¨äºä¸‹ä¸€è½®çš„ n-gram åŒ¹é…ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506211038538.png)

ä¸Šå›¾å±•ç¤ºäº†ä¸€ä¸ª Prompt Lookup Decoding çš„ç¤ºä¾‹ï¼šç»™å®šä¸€ä¸ª promptï¼Œæˆ‘ä»¬ä¼šæå–å…¶ä¸­æ‰€æœ‰çš„ 2-gram ä½œä¸ºæŸ¥æ‰¾é”®ï¼ˆkeyï¼‰ï¼Œå¹¶å°†å®ƒä»¬åé¢ç´§è·Ÿçš„ä¸‰ä¸ª token ä½œä¸ºæŸ¥æ‰¾å€¼ï¼ˆvalueï¼‰ã€‚åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šæ£€æŸ¥å½“å‰ç”Ÿæˆçš„ 2-gram æ˜¯å¦ä¸æŸ¥æ‰¾è¡¨ä¸­çš„æŸä¸ª key åŒ¹é…ã€‚å¦‚æœåŒ¹é…æˆåŠŸï¼Œå°±ä½¿ç”¨å¯¹åº”çš„ value ä½œä¸ºåç»­çš„å€™é€‰ token è¿›è¡Œç”Ÿæˆã€‚

åœ¨ä¸‹é¢è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† n-gram Speculative Decodingï¼Œæ¯æ¬¡æœ€å¤šæ¨æµ‹ 3 ä¸ª tokenï¼Œæœ€å¤šä½¿ç”¨ 2 ä¸ª n-gram è¿›è¡ŒåŒ¹é…ã€‚

```python
from vllm import LLM, SamplingParams

prompts = [
    "What is the capital of South Korea?",
]
sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

llm = LLM(
    model="facebook/opt-6.7b",
    tensor_parallel_size=1,
    speculative_config={
        "method": "ngram", # ä½¿ç”¨ n-gram Speculative Decoding
        "num_speculative_tokens": 3, # æ¯æ¬¡æœ€å¤šæ¨æµ‹ 3 ä¸ª token
        "prompt_lookup_max": 2, # æœ€å¤šä½¿ç”¨ 2 ä¸ª n-gram è¿›è¡ŒåŒ¹é…
    },
)
outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f"Prompt: {prompt!r}, Generated text: {generated_text!r}")
```

## 5 Jacobi Decoding

> è®ºæ–‡ï¼šAccelerating Transformer Inference for Translation via Parallel Decodingï¼šhttps://arxiv.org/pdf/2305.10427

Jacobi è¿­ä»£æ³•æ˜¯ä¸€ç§ç»å…¸çš„éçº¿æ€§æ–¹ç¨‹ç»„æ±‚è§£æ–¹æ³•ã€‚åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°†å…¶åº”ç”¨äº**å¹¶è¡Œç”Ÿæˆ token**ï¼Œä¸”**ä¸ä¾èµ–è‰ç¨¿æ¨¡å‹**ã€‚ä¼ ç»Ÿä¸Šï¼Œè‡ªå›å½’è§£ç è¢«è§†ä¸ºä¸€ä¸ª**é€æ­¥ç”Ÿæˆ token çš„ä¸²è¡Œè¿‡ç¨‹**ï¼Œå¦‚ä¸‹å›¾å·¦ä¾§æ‰€ç¤ºã€‚è€Œé€šè¿‡å¯¹ä¸€äº›å…¬å¼è¿›è¡Œç®€å•é‡æ’ï¼Œè¿™ä¸€è¿‡ç¨‹ä¹Ÿå¯ä»¥è¢«çœ‹ä½œæ˜¯åœ¨**æ±‚è§£ä¸€ä¸ªéçº¿æ€§æ–¹ç¨‹ç»„**ï¼Œå¦‚ä¸‹å›¾å³ä¾§æ‰€ç¤ºã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506212150921.png)

é€šè¿‡ Jacobi è¿­ä»£æ³•ï¼Œå¯ä»¥å¹¶è¡Œåœ°æ±‚è§£è¯¥éçº¿æ€§ç³»ç»Ÿä¸­çš„æ‰€æœ‰å˜é‡ $[y_1, y_2, \dots, y_m]$ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š

* ä¸ºæ‰€æœ‰å˜é‡ $\mathbf{y} = [y_1, y_2, \dots, y_m]$ è®¾å®šä¸€ä¸ªåˆå§‹çŒœæµ‹ï¼›
* ä½¿ç”¨å½“å‰çš„ $\mathbf{y}$ å€¼ï¼Œä¸ºæ¯ä¸ªæ–¹ç¨‹è®¡ç®—æ–°çš„ $\mathbf{y}'$ï¼›
* å°† $\mathbf{y}$ æ›´æ–°ä¸ºæ–°è®¡ç®—å¾—åˆ°çš„ $\mathbf{y}'$ï¼›
* é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°æ»¡è¶³æŸä¸ªåœæ­¢æ¡ä»¶ï¼ˆä¾‹å¦‚ $\mathbf{y} = \mathbf{y}'$ï¼‰ä¸ºæ­¢ã€‚

Jacobi Decoding ä¹‹æ‰€ä»¥å¯ä»¥è®©å¤§æ¨¡å‹å¹¶è¡Œé¢„æµ‹å¤šä¸ª tokenï¼Œæ˜¯å› ä¸ºå®ƒå°†åŸæœ¬è‡ªå›å½’çš„ä¸²è¡Œç”Ÿæˆè¿‡ç¨‹è½¬åŒ–ä¸ºäº†ä¸€ä¸ªéçº¿æ€§ç³»ç»Ÿçš„â€œå¹¶è¡Œè¿­ä»£æ±‚è§£â€é—®é¢˜ã€‚æ¯ä¸€è½®éƒ½ç”¨å¤§æ¨¡å‹ï¼Œåœ¨ä¸åŒä½ç½®ä¸Šå¹¶è¡Œé¢„æµ‹ tokenï¼Œå¹¶ä½¿ç”¨ä¸Šä¸€è½®çš„ç»“æœä½œä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯ä¾èµ–æœ¬è½®åˆšç”Ÿæˆçš„å†…å®¹ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506212210549.gif)

ä¸Šå›¾å±•ç¤ºäº†è¿™ä¸€å¹¶è¡Œè§£ç è¿‡ç¨‹ï¼ˆä¹Ÿç§°ä¸º Jacobi Decodingï¼‰ã€‚Jacobi Decoding èƒ½å¤Ÿåœ¨æœ€å¤š $m$ æ­¥å†…æ±‚è§£æ‰€æœ‰ $m$ ä¸ªå˜é‡ï¼ˆå³ï¼Œä¸è‡ªå›å½’è§£ç æ‰€éœ€æ­¥æ•°ç›¸åŒï¼‰ï¼Œå› ä¸ºæ¯ä¸€æ­¥è‡³å°‘èƒ½å¤Ÿä¿è¯ç¬¬ä¸€ä¸ª token è¢«æ­£ç¡®è§£ç ã€‚æœ‰æ—¶å€™ï¼Œå¤šä¸ª token å¯èƒ½ä¼šåœ¨ä¸€æ¬¡è¿­ä»£ä¸­åŒæ—¶æ”¶æ•›ï¼Œä»è€Œå‡å°‘æ•´ä½“è§£ç æ­¥æ•°ã€‚ä¾‹å¦‚ï¼ŒJacobi Decoding åœ¨ç¬¬ 4 æ­¥ä¸­åŒæ—¶é¢„æµ‹å¹¶æ¥å—äº†ä¸¤ä¸ª tokenï¼šâ€œcomputerâ€ å’Œ â€œscientistâ€ã€‚

ä¸è‡ªå›å½’è§£ç ç›¸æ¯”ï¼ŒJacobi Decoding çš„æ¯ä¸€æ­¥åœ¨è®¡ç®—ä¸Šä¼šç¨å¾®æ›´æ˜‚è´µä¸€äº›ï¼Œå› ä¸ºå®ƒéœ€è¦åœ¨å¤šä¸ª token ä¸ŠåŒæ—¶è¿›è¡Œè¯­è¨€æ¨¡å‹çš„å‰å‘è®¡ç®—ã€‚ä½†å¹¸è¿çš„æ˜¯ï¼Œç”±äº GPU çš„å¹¶è¡Œå¤„ç†ç‰¹æ€§ï¼Œè¿™ç§é¢å¤–è®¡ç®—é€šå¸¸ä¸ä¼šå¸¦æ¥æ˜¾è‘—çš„å»¶è¿Ÿã€‚

> Jacobi Decoding å°±åƒï¼šä½ å…ˆæŠŠæ•´ç¯‡æ–‡ç« è‰æ‹Ÿå‡ºæ¥ï¼Œç„¶åè®©è€å¸ˆä¸€æ®µæ®µæ£€æŸ¥ã€åˆ’æ‰ä¸å¯¹çš„ã€ä¿ç•™æ­£ç¡®çš„ï¼Œç„¶åç»§ç»­åœ¨æ­¤åŸºç¡€ä¸Šå†™åé¢çš„å†…å®¹ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒJacobi Decoding åœ¨å®ç°æ˜¾è‘—çš„å®é™…åŠ é€Ÿæ–¹é¢é¢ä¸´ä¸å°‘æŒ‘æˆ˜ã€‚å°½ç®¡å®ƒåœ¨å¤šè½®è¿­ä»£ä¸­ç¡®å®èƒ½å¤Ÿä¸€æ¬¡ç”Ÿæˆå¤šä¸ª tokenï¼Œä½†è¿™äº› token é€šå¸¸éš¾ä»¥è¢«å‡†ç¡®åœ°æ”¾ç½®åœ¨æ­£ç¡®çš„ä½ç½®ã€‚å³ä¾¿éƒ¨åˆ† token è¢«æ­£ç¡®é¢„æµ‹ï¼Œå®ƒä»¬ä¹Ÿå¸¸å¸¸åœ¨åç»­çš„è¿­ä»£ä¸­è¢«æ–°çš„é¢„æµ‹æ‰€æ›¿ä»£ã€‚æœ€ç»ˆï¼ŒçœŸæ­£èƒ½åšåˆ°å¤šä¸ª token åŒæ—¶ç”Ÿæˆä¸”ä½ç½®æ­£ç¡®çš„æƒ…å†µéå¸¸æœ‰é™ï¼Œéš¾ä»¥ä½“ç°å¹¶è¡Œ Jacobi Decoding åŸæœ¬è¿½æ±‚çš„æ•ˆç‡ä¼˜åŠ¿ã€‚

## 6 Lookahead Decoding

> è®ºæ–‡ï¼šBreak the Sequential Dependency of LLM Inference Using Lookahead Decodingï¼šhttps://arxiv.org/abs/2402.02057
>
> Githubï¼šhttps://github.com/hao-ai-lab/LookaheadDecoding

Lookahead Decoding çš„çµæ„Ÿæ¥æºäº Jacobi Decodingï¼Œå®ƒå°†è‡ªå›å½’è§£ç è§†ä¸ºæ±‚è§£éçº¿æ€§ç³»ç»Ÿçš„é—®é¢˜ï¼Œå¹¶é€šè¿‡å›ºå®šç‚¹è¿­ä»£ï¼ˆfixed-point iterationï¼‰ä¸€æ¬¡æ€§å¹¶è¡Œç”Ÿæˆå¤šä¸ªæœªæ¥ tokenã€‚è™½ç„¶ Jacobi Decoding ä¸­åˆå§‹åŒ–çš„ token å¾€å¾€ä¸å‡†ç¡®ï¼Œä½†å…¶ç”Ÿæˆè½¨è¿¹ï¼ˆJacobi trajectoryï¼‰ä¸­åŒ…å«çš„ n-gram ç‰‡æ®µå¯èƒ½åœ¨åç»­è§£ç ä¸­æˆä¸ºæœ‰æ•ˆçš„å€™é€‰ã€‚

Lookahead Decoding æ­£æ˜¯åˆ©ç”¨äº†è¿™ä¸€ç‰¹æ€§ï¼š**æ”¶é›† Jacobi ç”Ÿæˆè·¯å¾„ä¸­çš„ n-gramï¼Œå¹¶å°†å…¶ç¼“å­˜è‡³ n-gram æ± ä¸­**ã€‚éšåç³»ç»Ÿåœ¨è§£ç æ—¶ä»ä¸­æŒ‘é€‰å¯èƒ½å‘½ä¸­çš„ n-gram å¹¶é€šè¿‡ä¸»æ¨¡å‹éªŒè¯æ˜¯å¦å¯æ¥å—ï¼Œä»è€Œè·³è·ƒå¼æ¨è¿›ç”Ÿæˆè¿‡ç¨‹ï¼Œæ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿã€‚

æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼ŒLookahead Decoding ä¸ä¾èµ–è‰ç¨¿æ¨¡å‹ï¼Œéƒ¨ç½²ç®€æ´ï¼ŒåŒæ—¶å€ŸåŠ©å‰ç»ç”Ÿæˆä¸å¹¶è¡ŒéªŒè¯ä¸¤ä¸ªåˆ†æ”¯ï¼Œåœ¨å•æ­¥å†…å®Œæˆå¤šä¸ªå€™é€‰çš„ç”Ÿæˆä¸éªŒè¯ï¼Œæœ€å¤§åŒ–åˆ©ç”¨äº†åŸæœ¬æœªè¢«è‡ªå›å½’è§£ç å……åˆ†ä½¿ç”¨çš„è®¡ç®—èµ„æºã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506212230325.gif)

## 7 Medusa

> è®ºæ–‡ï¼šMedusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Headsï¼šhttps://arxiv.org/abs/2401.10774
> 
> Githubï¼šhttps://github.com/FasterDecoding/Medusa

ç›¸æ¯”äºå¼•å…¥ä¸€ä¸ªç‹¬ç«‹çš„è‰ç¨¿æ¨¡å‹ï¼Œ**Medusa** æå‡ºäº†ä¸€ç§æ›´ç´§å‡‘ä¸”é«˜æ•ˆçš„è®¾è®¡æ€è·¯ï¼šç›´æ¥åœ¨åŸå§‹ä¸»å¹²æ¨¡å‹ä¸Šè¿›è¡Œæ‰©å±•ã€‚å…¶æ ¸å¿ƒåšæ³•æ˜¯åœ¨ä¸»æ¨¡å‹çš„æœ€åä¸€ä¸ªéšè—å±‚ä¸Šæ·»åŠ å¤šä¸ªè½»é‡çº§è§£ç å¤´ï¼ˆMedusa Headsï¼‰ï¼Œæ¯ä¸ªè§£ç å¤´å¹¶è¡Œé¢„æµ‹æœªæ¥ä¸åŒä½ç½®çš„ tokenã€‚Medusa Heads æ˜¯åœ¨åŸå§‹ä¸»å¹²æ¨¡å‹ï¼ˆbackbone modelï¼‰åŸºç¡€ä¸Šä¸€èµ·è®­ç»ƒå¾—åˆ°çš„ã€‚

æ¯ä¸ªé¢„æµ‹å¤´çš„ç»“æ„æå…¶ç®€æ´ï¼Œä»…ç”±ä¸€å±‚æ„æˆï¼Œä¸ä¸»å¹²æ¨¡å‹çš„è¾“å‡ºå±‚ç›¸ä¼¼ï¼Œå› æ­¤ä¸ä¼šå¢åŠ æ¨ç†æœåŠ¡ç³»ç»Ÿçš„å¤æ‚åº¦ã€‚åŒæ—¶ï¼Œé¢„æµ‹å¤´çš„è¾“å‡ºåˆ†å¸ƒä¸ä¸»æ¨¡å‹é«˜åº¦ä¸€è‡´ï¼Œæœ‰æ•ˆç¼“è§£äº†è‰ç¨¿æ¨¡å‹å¸¸è§çš„åˆ†å¸ƒåç§»é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†å€™é€‰ token çš„å‡†ç¡®æ€§ä¸ç¨³å®šæ€§ã€‚

è®­ç»ƒæ—¶ï¼Œä¸»å¹²æ¨¡å‹å¯ä»¥ä¿æŒå†»ç»“çŠ¶æ€ï¼ˆç§°ä¸º MEDUSA-1ï¼‰ï¼Œä¹Ÿå¯ä»¥ä¸é¢„æµ‹å¤´ä¸€èµ·è”åˆè®­ç»ƒï¼ˆç§°ä¸º MEDUSA-2ï¼‰ã€‚è¿™ç§è®¾è®¡ä½¿å¾—å³ä½¿åªä½¿ç”¨å•ä¸ª GPUï¼Œä¹Ÿèƒ½å¯¹å¤§å‹æ¨¡å‹è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼Œå……åˆ†åˆ©ç”¨ä¸»å¹²æ¨¡å‹å·²å­¦åˆ°çš„å¼ºå¤§ç‰¹å¾è¡¨ç¤ºã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506202054347.png)

åœ¨æ¨ç†é˜¶æ®µï¼Œæ¯ä¸ªé¢„æµ‹å¤´ä¼šé’ˆå¯¹å…¶å¯¹åº”çš„ä½ç½®ç”Ÿæˆå¤šä¸ª top å€™é€‰ tokenã€‚ç„¶åï¼Œè¿™äº›å€™é€‰ä¼šè¢«ç»„åˆæˆå¤šä¸ªå€™é€‰åºåˆ—ï¼Œå¹¶é€šè¿‡**æ ‘çŠ¶æ³¨æ„åŠ›æœºåˆ¶ï¼ˆtree attentionï¼‰** å¹¶è¡Œå¤„ç†ã€‚æœ€åä¸€æ­¥æ˜¯é‡‡ç”¨å…¸å‹æ¥å—ç­–ç•¥ï¼ˆtypical acceptanceï¼‰æ¥ç­›é€‰å‡ºåˆç†çš„ç”Ÿæˆè·¯å¾„ï¼Œå¹¶å°†è¢«æ¥å—çš„æœ€é•¿å€™é€‰å‰ç¼€ä½œä¸ºä¸‹ä¸€è½®è§£ç çš„èµ·ç‚¹ã€‚é€šè¿‡åŒæ—¶æ¥å—æ›´å¤šçš„ tokenï¼Œå¯ä»¥å‡å°‘æ‰€éœ€çš„è§£ç æ­¥æ•°ï¼Œä»è€Œæå‡æ•´ä¸ªè§£ç è¿‡ç¨‹çš„æ•ˆç‡ã€‚

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ·±å…¥äº†è§£ Medusa çš„ 3 ä¸ªç»„æˆéƒ¨åˆ†ï¼šMedusa headsã€tree attention å’Œ typical acceptanceã€‚

### 7.1 Medusa heads

Medusa ä¹‹æ‰€ä»¥èƒ½å¤Ÿä¸€æ¬¡æ€§è§£ç å¤šä¸ª tokenï¼Œæ ¸å¿ƒåœ¨äºå®ƒåœ¨åŸå§‹è¯­è¨€æ¨¡å‹çš„**æœ€åéšè—å±‚è¾“å‡ºä¹‹ä¸Šï¼Œé™„åŠ äº†å¤šä¸ªè§£ç å¤´ï¼ˆMedusa headsï¼‰**ã€‚æ¯ä¸ªè§£ç å¤´è´Ÿè´£é¢„æµ‹åºåˆ—ä¸­ä¸åŒåç§»ä½ç½®çš„æœªæ¥ tokenã€‚è¿™äº›è§£ç å¤´ç»“æ„ç±»ä¼¼äºåŸå§‹æ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¤´ï¼Œé€šå¸¸æ˜¯å•å±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼Œå¯ä»¥ç‹¬ç«‹åœ°ä¸ºå…¶ç›®æ ‡ä½ç½®ç”Ÿæˆ token é¢„æµ‹ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ä¸€æ¬¡å‰å‘ä¼ æ’­ä¸­å³å¯**å¹¶è¡Œé¢„æµ‹å¤šä¸ªåç»­ token**ï¼Œè€Œä¸å†åƒä¼ ç»Ÿè‡ªå›å½’ç”Ÿæˆæ–¹å¼é‚£æ ·å¿…é¡»é€æ­¥ç”Ÿæˆå•ä¸ª tokenï¼Œä»è€Œæ˜¾è‘—æå‡è§£ç æ•ˆç‡ã€‚

å…·ä½“æ¥è¯´ï¼š

* åŸå§‹ LM headï¼šé¢„æµ‹å½“å‰ä½ç½® $t$ çš„ä¸‹ä¸€ä¸ª tokenï¼Œå³ä½ç½® $t+1$ï¼›
* ç¬¬ 1 ä¸ª Medusa headï¼šé¢„æµ‹ä½ç½® $t+2$ï¼›
* ç¬¬ 2 ä¸ª Medusa headï¼šé¢„æµ‹ä½ç½® $t+3$ï¼›
* â€¦
* ç¬¬ $k$ ä¸ª Medusa headï¼šé¢„æµ‹ä½ç½® $t+k+1$ã€‚

ä¸ºäº†ä½¿ MEDUSA çš„å¤šä¸ªè§£ç å¤´å…·å¤‡è‰¯å¥½çš„é¢„æµ‹èƒ½åŠ›ï¼Œéœ€è¦å¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯å’Œèµ„æºæ¡ä»¶ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„è®­ç»ƒæ–¹å¼ï¼š

**MEDUSA-1ï¼šå†»ç»“ä¸»å¹²ï¼Œä»…è®­ç»ƒè§£ç å¤´**

åœ¨è¯¥æ–¹æ¡ˆä¸­ï¼ŒåŸå§‹æ¨¡å‹çš„ä¸»å¹²ï¼ˆåŒ…æ‹¬åŸæœ‰çš„è§£ç å¤´ï¼‰ä¿æŒå†»ç»“ï¼Œä»…è®­ç»ƒæ–°å¢çš„ MEDUSA è§£ç å¤´ã€‚é€‚ç”¨äºè®¡ç®—èµ„æºæœ‰é™ï¼Œæˆ–å¸Œæœ›å®Œå…¨ä¿ç•™åŸæ¨¡å‹æ€§èƒ½çš„åœºæ™¯ã€‚

è¯¥æ–¹å¼è¿˜å¯ä»¥ç»“åˆ QLoRA å¯¹è§£ç å¤´è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œä»è€Œè¿›ä¸€æ­¥é™ä½å†…å­˜å’Œè®¡ç®—èµ„æºçš„æ¶ˆè€—ã€‚

å®éªŒè¡¨æ˜ï¼ŒMEDUSA-1 åœ¨ Vicuna-7B ä¸Šå¯å®ç° **2.18Ã— çš„æ¨ç†é€Ÿåº¦æå‡**ã€‚

**MEDUSA-2ï¼šè”åˆè®­ç»ƒä¸»å¹²ä¸è§£ç å¤´**

è¯¥æ–¹æ¡ˆå¯¹åŸæ¨¡å‹ä¸»å¹²å’Œ MEDUSA è§£ç å¤´è¿›è¡Œè”åˆè®­ç»ƒã€‚ç›¸æ¯”äº MEDUSA-1ï¼Œè™½ç„¶èµ„æºå¼€é”€æ›´å¤§ï¼Œä½†ä¹Ÿèƒ½æ›´å……åˆ†åœ°å‘æŒ¥å¤šä¸ªè§£ç å¤´åœ¨æ¨ç†åŠ é€Ÿæ–¹é¢çš„æ½œåŠ›ã€‚

MEDUSA-2 é€šè¿‡è”åˆè®­ç»ƒï¼Œä½¿ MEDUSA è§£ç å¤´çš„åˆ†å¸ƒä¸ä¸»å¹²æ¨¡å‹ä¿æŒä¸€è‡´ï¼Œ**æœ‰æ•ˆç¼“è§£åˆ†å¸ƒæ¼‚ç§»é—®é¢˜ï¼Œæ˜¾è‘—æå‡é¢„æµ‹å‡†ç¡®æ€§**ã€‚

é€‚ç”¨äºè®¡ç®—èµ„æºå……è¶³ï¼Œæˆ–ä» base æ¨¡å‹è¿›è¡Œ SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰çš„åœºæ™¯ã€‚å®éªŒè¯æ˜ï¼ŒMEDUSA-2 åœ¨ Vicuna-7B ä¸Šå¯å®ç° **2.83Ã— çš„é€Ÿåº¦æå‡**ï¼Œä¼˜äº MEDUSA-1ã€‚

ä¸ºä¿è¯è®­ç»ƒæ•ˆæœå’Œç¨³å®šæ€§ï¼ŒMEDUSA-2 å¼•å…¥äº†ä»¥ä¸‹å…³é”®è®­ç»ƒç­–ç•¥ï¼š

- **1. å·®å¼‚åŒ–å­¦ä¹ ç‡ï¼ˆDifferential Learning Ratesï¼‰**

ç”±äºä¸»å¹²æ¨¡å‹å·²ç»é¢„è®­ç»ƒå……åˆ†ã€è¾ƒä¸ºç¨³å®šï¼Œè€Œ MEDUSA è§£ç å¤´æ˜¯æ–°å¢æ¨¡å—ã€ä»å¤„äºæ—©æœŸå­¦ä¹ é˜¶æ®µï¼Œå› æ­¤ä¸ºä¸¤è€…è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡æ˜¯åˆç†çš„é€‰æ‹©ï¼š

* ä¸»å¹²æ¨¡å‹ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œä»¥é¿å…æ‰°åŠ¨å·²æœ‰èƒ½åŠ›ï¼›
* MEDUSA è§£ç å¤´ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ï¼Œä»¥åŠ å¿«å…¶æ”¶æ•›é€Ÿåº¦ã€‚

è¿™æ ·æ—¢èƒ½æå‡è®­ç»ƒæ•ˆç‡ï¼Œåˆèƒ½ä¿æŠ¤ä¸»å¹²æ¨¡å‹ä¸è¢«ç ´åã€‚

- **2. ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼ˆTwo-Stage Trainingï¼‰**

åœ¨è®­ç»ƒåˆæœŸï¼ŒMEDUSA heads çš„æŸå¤±è¾ƒå¤§ï¼Œå¯èƒ½å¯¼è‡´æ¢¯åº¦è¿‡å¤§ï¼Œä»è€Œå¹²æ‰°ä¸»å¹²æ¨¡å‹çš„å‚æ•°æ›´æ–°ã€‚ä¸ºæ­¤ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼š

* **ç¬¬ä¸€é˜¶æ®µ**ï¼šä»…è®­ç»ƒ MEDUSA è§£ç å¤´ï¼Œç›¸å½“äºæ‰§è¡Œ MEDUSA-1ï¼›
* **ç¬¬äºŒé˜¶æ®µ**ï¼šå†ä¸ä¸»å¹²æ¨¡å‹ä¸€èµ·è”åˆè®­ç»ƒã€‚

å…·ä½“å¯é‡‡ç”¨ä¸¤ç§æ–¹å¼ï¼š

* å…ˆå•ç‹¬è®­ç»ƒä¸»å¹²æ¨¡å‹è‹¥å¹² epochï¼Œç„¶åå†ä¸è§£ç å¤´è”åˆè®­ç»ƒï¼›
* æˆ–è€…ä½¿ç”¨æ›´ç²¾ç»†çš„ warmup ç­–ç•¥ï¼š**é€æ­¥å¢åŠ  Î»â‚€ï¼ˆä¸»å¹²æ¨¡å‹æŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡ï¼‰**ï¼Œåœ¨è®­ç»ƒåˆæœŸè®©ä¸»å¹²æ¨¡å‹â€œå‚ä¸è¾ƒå°‘â€ï¼ŒåæœŸé€æ­¥â€œå‚ä¸æ›´å¤šâ€ã€‚

**è®­ç»ƒæ•°æ®çš„è·å–**

* å¦‚æœåŸæ¨¡å‹ä½¿ç”¨çš„ SFT æ•°æ®é›†å¯ç”¨ï¼Œåˆ™å¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒ MEDUSA è§£ç å¤´ï¼›
* å¦‚æœè¯¥æ•°æ®é›†ä¸å¯è·å¾—ï¼Œæˆ–è€…åŸæ¨¡å‹ç»è¿‡äº† RLHFï¼ˆäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼‰é˜¶æ®µï¼Œ**åˆ™å¯ä»¥é€šè¿‡è‡ªè’¸é¦ï¼ˆself-distillationï¼‰æ–¹å¼ç”Ÿæˆè®­ç»ƒæ•°æ®**ã€‚è‡ªè’¸é¦çš„åšæ³•æ˜¯åˆ©ç”¨æ¨¡å‹è‡ªèº«ç”Ÿæˆç¬¦åˆå…¶è¾“å‡ºåˆ†å¸ƒçš„æ ·æœ¬ï¼Œæ„å»ºä¸åŸæ¨¡å‹ä¸€è‡´çš„æ•°æ®åˆ†å¸ƒï¼Œä»è€Œè®­ç»ƒå‡ºä¸ä¸»å¹²æ¨¡å‹è¡Œä¸ºä¸€è‡´çš„ MEDUSA headsã€‚

### 7.2 Tree Attention

Medusa åœ¨æ¨ç†æ—¶ï¼Œæ¯ä¸ªè§£ç å¤´ä¸ä»…è¾“å‡ºä¸€ä¸ªæœ€å¯èƒ½çš„ tokenï¼Œè€Œæ˜¯é‡‡æ ·å¤šä¸ª top-k å€™é€‰ tokenï¼Œå¹¶å°†å®ƒä»¬ç»„åˆæˆä¸€æ£µæ ‘çŠ¶ç»“æ„çš„å€™é€‰åºåˆ—é›†åˆã€‚ä½œè€…åœ¨å®éªŒä¸­å‘ç°ï¼Œå°½ç®¡é¢„æµ‹â€œä¸‹ä¸‹ä¸€ä¸ªâ€ token çš„ top-1 å‡†ç¡®ç‡ä»…çº¦ä¸º 60%ï¼Œä½† top-5 çš„å‡†ç¡®ç‡å´è¶…è¿‡äº† 80%ã€‚è¿™ä¸€æ˜¾è‘—æå‡è¡¨æ˜ï¼Œå¦‚æœèƒ½å¤Ÿåˆç†åˆ©ç”¨è¿™äº›é«˜æ¦‚ç‡é¢„æµ‹ç»“æœï¼Œä¾¿å¯ä»¥åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­ç”Ÿæˆæ›´å¤š tokenï¼Œä»è€Œæ˜¾è‘—åŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚ä¸ºäº†åœ¨ **ä¸å¢åŠ å¤§æ¨¡å‹è°ƒç”¨æ¬¡æ•°** çš„å‰æä¸‹é«˜æ•ˆéªŒè¯å¤šä¸ªå€™é€‰è·¯å¾„ï¼ŒMedusa å¼•å…¥äº† **Tree Attention** æœºåˆ¶ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506202137219.png)

ä»¥ä¸€ä¸ªå…·ä½“ä¾‹å­è¯´æ˜ï¼š

å‡è®¾å½“å‰æœ‰ä¸¤ä¸ª Medusa è§£ç å¤´ï¼š

* ç¬¬ä¸€ä¸ª head è¾“å‡º top-2 tokenï¼š\["It", "I"]
* ç¬¬äºŒä¸ª head è¾“å‡º top-3 tokenï¼š\["is", "'", "the"]

è¿™å°±æ„æˆäº† 2 Ã— 3 = 6 æ¡å¯èƒ½è·¯å¾„ï¼š

```
è·¯å¾„ 1: It â†’ is  
è·¯å¾„ 2: It â†’ '  
è·¯å¾„ 3: It â†’ the  
è·¯å¾„ 4: I â†’ is  
è·¯å¾„ 5: I â†’ '  
è·¯å¾„ 6: I â†’ the
```

æˆ‘ä»¬å°†åŸå§‹è¾“å…¥çœ‹ä½œæ ¹èŠ‚ç‚¹ï¼Œæ¯æ¡è·¯å¾„ä»æ ¹èŠ‚ç‚¹å‡ºå‘ï¼Œç»è¿‡ head1 çš„ä¸€ä¸ª tokenï¼Œå†æ¥ä¸Š head2 çš„ä¸€ä¸ª tokenï¼Œå½¢æˆä¸€ä¸ªäºŒå±‚çš„å€™é€‰æ ‘ã€‚

ä¸ºäº†é¿å…å¯¹æ¯æ¡è·¯å¾„é€ä¸ªè°ƒç”¨å¤§æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼ŒMedusa ä½¿ç”¨ Tree Attentionï¼Œå°†æ‰€æœ‰å€™é€‰è·¯å¾„ä¸­çš„ token æ‰å¹³å±•å¼€ä¸ºä¸€ä¸ªè¿ç»­åºåˆ—ï¼š

```
["It", "I", "is", "'", "the", "is", "'", "the"]
```

* å‰ä¸¤ä¸ª tokenï¼ˆ"It", "I"ï¼‰æ¥è‡ª head1ï¼›
* åå…­ä¸ª token æ˜¯ head2 çš„ä¸‰ä¸ªå€™é€‰ï¼Œåˆ†åˆ«æŒ‚åœ¨ "It" å’Œ "I" ä¹‹ä¸‹ï¼Œå› æ­¤æ¯ä¸ªå‡ºç°ä¸¤æ¬¡ã€‚

æ¥ç€ï¼Œæ„å»º **Tree Mask**ï¼Œç¡®ä¿æ³¨æ„åŠ›æœºåˆ¶åªå‘ç”Ÿåœ¨é€»è¾‘ä¸Šæœ‰å› æœå…³ç³»çš„ token ä¹‹é—´ï¼š

* "It" ä¸å…¶ä¸‰ä¸ªå­èŠ‚ç‚¹ "is"ã€"'"ã€"the" å¯ä»¥ç›¸äº’æ³¨æ„ï¼›
* "I" ä¸å…¶å¯¹åº”çš„å­èŠ‚ç‚¹ä¹Ÿå¯ä»¥ç›¸äº’æ³¨æ„ï¼›
* ä½† "It" å’Œ "I" ä¸åº”è¯¥äº’ç›¸æ³¨æ„ï¼ˆå®ƒä»¬æ˜¯ç‹¬ç«‹çš„è·¯å¾„ï¼‰ï¼›
* åŒæ ·ï¼Œhead2 ä¸­ä¸åŒçˆ¶èŠ‚ç‚¹ä¸‹çš„å­ token ä¹Ÿä¸èƒ½äº’ç›¸æ³¨æ„ï¼›
* åªæœ‰æ²¿æ ‘è·¯å¾„çš„ç¥–å…ˆå’Œåä»£ token ä¹‹é—´æ‰å…è®¸æ³¨æ„åŠ›ä¼ é€’ã€‚

æ‰€ä»¥ï¼Œåˆ©ç”¨ Tree Attention å°±å®ç°äº†ä¸€æ¬¡å¤§æ¨¡å‹è°ƒç”¨å°±æŠŠæ‰€æœ‰çš„è·¯å¾„éƒ½éªŒè¯äº†çš„æ•ˆæœã€‚è€ƒè™‘åˆ°çœŸå®åœºæ™¯ï¼Œå¤§æ¨¡å‹çš„æ¨ç†ç“¶é¢ˆå¾€å¾€åœ¨å†…å­˜è¯»å–ï¼Œè€Œä¸æ˜¯è®¡ç®—ã€‚æ‰€ä»¥é€‚å½“åœ°å¢åŠ è®¡ç®—é‡ï¼ŒåŸºæœ¬ä¸ä¼šå½±å“æ¨ç†è€—æ—¶ï¼Œåè€Œé€šè¿‡ Tree Attention æœ‰å¯èƒ½å¾—åˆ°æ›´é•¿çš„ draftã€‚

### 7.3 Typical acceptance

åœ¨ä¼ ç»Ÿçš„ **Speculative Decoding** ä¸­ï¼Œæœ€å¸¸ç”¨çš„å€™é€‰éªŒè¯æ–¹æ³•æ˜¯ **Rejection Samplingï¼ˆæ‹’ç»é‡‡æ ·ï¼‰**ã€‚å®ƒçš„åšæ³•æ˜¯ï¼šè‰ç¨¿æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªå°æ¨¡å‹ï¼‰å…ˆç”Ÿæˆå¤šä¸ªå€™é€‰ tokenï¼ŒåŸå§‹å¤§æ¨¡å‹é€ä¸ªéªŒè¯è¿™äº› token æ˜¯å¦â€œç¬¦åˆè‡ªå·±æ¦‚ç‡åˆ†å¸ƒâ€ï¼Œä¸ç¬¦åˆå°±å…¨éƒ¨ä¸¢å¼ƒã€‚è¿™ç§æ–¹å¼è™½ç„¶å‡†ç¡®ï¼Œèƒ½ä¿æŒè¾“å‡ºåˆ†å¸ƒå’ŒåŸå§‹æ¨¡å‹ä¸€è‡´ï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€ä¸ªä¸¥é‡é—®é¢˜â€”â€”**æ•ˆç‡ä½**ã€‚å°¤å…¶å½“é‡‡æ ·æ¸©åº¦ï¼ˆtemperatureï¼‰è¾ƒé«˜æ—¶ï¼Œè‰ç¨¿æ¨¡å‹ä¼šç”Ÿæˆæ›´å¤šå¯Œæœ‰åˆ›æ„ã€ä½†åç¦»ä¸»æµåˆ†å¸ƒçš„å€™é€‰ tokenã€‚æ­¤æ—¶åŸå§‹æ¨¡å‹å¾ˆå®¹æ˜“æ‹’ç»å®ƒä»¬ï¼Œå¯¼è‡´è§£ç æ­¥éª¤ç¼©çŸ­ã€é‡å¤è®¡ç®—ï¼Œæ•ˆç‡å¤§å¤§ä¸‹é™ã€‚

ä¸ºäº†æé«˜æ•´ä½“æ¨ç†æ•ˆç‡ï¼Œ**Medusa æå‡ºäº†ä¸€ç§æ›´å®½å®¹ã€æ›´é«˜æ•ˆçš„éªŒè¯ç­–ç•¥ â€”â€” Typical Acceptanceï¼ˆå…¸å‹æ¥å—ï¼‰**ã€‚è¯¥ç­–ç•¥ä» **æˆªæ–­é‡‡æ ·ï¼ˆTruncation Samplingï¼‰** çš„ç ”ç©¶ä¸­æ±²å–çµæ„Ÿï¼Œç›®æ ‡æ˜¯æ‰©å¤§åŸå§‹æ¨¡å‹å¯æ¥å—çš„å€™é€‰èŒƒå›´ã€‚å…·ä½“è€Œè¨€ï¼ŒMedusa ä¸å†è¦æ±‚è‰ç¨¿æ¨¡å‹ç”Ÿæˆçš„ token ä¸åŸå§‹æ¨¡å‹çš„åˆ†å¸ƒå®Œå…¨å¯¹é½ï¼Œè€Œæ˜¯æ ¹æ®åŸå§‹æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡è®¾å®šä¸€ä¸ªæ¥å—é˜ˆå€¼ï¼šåªè¦æŸä¸ªå€™é€‰ token çš„æ¦‚ç‡è¶…è¿‡è¯¥é˜ˆå€¼ï¼Œå°±å¯ä»¥æ¥å—å®ƒä»¥åŠå®ƒä¹‹å‰çš„æ‰€æœ‰ tokenï¼ˆå³å…¶ prefixï¼‰ã€‚åœ¨è¿™äº›è¢«æ¥å—çš„ token ä¸­ï¼ŒMedusa ä½¿ç”¨è´ªå©ªç­–ç•¥ï¼ˆGreedyï¼‰é€‰å– top-kï¼Œä½œä¸ºæœ€ç»ˆçš„å€™é€‰è¾“å‡ºã€‚

**å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šMedusa ä¸å¼ºæ±‚è‰ç¨¿æ¨¡å‹ç”Ÿæˆçš„ token ä¸åŸå§‹æ¨¡å‹çš„åˆ†å¸ƒå®Œå…¨ä¸€è‡´ï¼Œåªè¦è¿™äº› token ä¸æ˜¯æä¸å¯èƒ½çš„ç»“æœï¼Œå°±å¯ä»¥è¢«æ¥å—ã€‚**

å‡è®¾å½“å‰ä¸Šä¸‹æ–‡æ˜¯ï¼šâ€œThe weather isâ€ï¼Œè‰ç¨¿æ¨¡å‹ï¼ˆæ¸©åº¦è¾ƒé«˜ï¼‰ç”Ÿæˆçš„ä¸‹ä¸€ä¸ª token æ˜¯ï¼š

```
"fun"
```

è€ŒåŸå§‹æ¨¡å‹çš„æ¦‚ç‡åˆ†å¸ƒå¦‚ä¸‹ï¼š

| Token   | æ¦‚ç‡   |
| ------- | ---- |
| "nice"  | 0.35 |
| "bad"   | 0.30 |
| "cold"  | 0.15 |
| "fun"   | 0.08 |
| "wet"   | 0.06 |
| "?"     | 0.03 |
| "sad"   | 0.02 |
| "quick" | 0.01 |

æˆ‘ä»¬è®¾å®šä¸€ä¸ªç´¯è®¡æ¦‚ç‡é˜ˆå€¼ä¸º **90%**ï¼Œä»é«˜åˆ°ä½ç´¯åŠ ï¼š

* "nice" â†’ 0.35
* "bad" â†’ 0.65
* "cold" â†’ 0.80
* "fun" â†’ 0.88 âœ…
* "wet" â†’ 0.94 âŒ è¶…å‡ºé˜ˆå€¼

**Rejection Sampling æ˜¯æ€ä¹ˆåšçš„ï¼š**

* draft æ¨¡å‹é‡‡æ ·å‡º `"fun"`ï¼›
* åŸå§‹æ¨¡å‹åˆ¤æ–­ `"fun"` çš„æ¦‚ç‡ä»…ä¸º **0.08**ï¼ˆä¾‹å¦‚ï¼Œè‰ç¨¿æ¨¡å‹é¢„æµ‹ `"fun"` çš„æ¦‚ç‡ä¸º 0.8ï¼Œè€ŒåŸå§‹æ¨¡å‹ä»…ä¸º 0.08ï¼Œå‡è®¾éšæœºæ•° $r = 0.5$ï¼Œç”±äº $r > 0.08 / 0.8 = 0.1$ï¼Œå› æ­¤è¯¥ token è¢«æ‹’ç»ï¼‰ã€‚å…·ä½“å¯å‚è€ƒç¬¬ 2 å°èŠ‚ä¸­çš„æ‹’ç»é‡‡æ ·ç¤ºä¾‹ã€‚
* ç„¶åé‡æ–°é‡‡æ ·ï¼Œç›´åˆ°é‡‡åˆ°åƒ `"nice"` æˆ– `"bad"` è¿™æ ·é«˜æ¦‚ç‡çš„ tokenï¼›
* å¦‚æœ draft å’ŒåŸå§‹æ¨¡å‹æ¸©åº¦ä¸ä¸€è‡´ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¼šä¸æ–­é‡è¯•ï¼Œæ•ˆç‡å˜ä½ã€‚

**Typical Acceptance æ˜¯æ€ä¹ˆåšçš„ï¼š**

* å…ˆæ„é€ å‡ºå‰ 90% ç´¯ç§¯æ¦‚ç‡æ‰€è¦†ç›–çš„ token é›†åˆï¼Œç§°ä¸º **å…¸å‹ token é›†åˆ**ï¼›
* `"fun"` è™½ç„¶ä¸æ˜¯å‰å‡ åï¼Œä½†ç´¯ç§¯ååˆšå¥½è½å…¥è¿™ä¸ªé›†åˆä¸­ï¼›
* å› æ­¤ï¼Œå®ƒè¢«è®¤ä¸ºâ€œè¶³å¤Ÿå…¸å‹â€ï¼Œ**ç›´æ¥æ¥å—ï¼Œæ— éœ€é‡é‡‡**ï¼›
* å¦‚æœåç»­ token ä¹Ÿåœ¨å…¸å‹é›†åˆä¸­ï¼Œé‚£ä¹ˆæ•´ä¸ªè‰ç¨¿åºåˆ—éƒ½å¯ä»¥æ¥å—ï¼›
* æœ€ç»ˆï¼Œæˆ‘ä»¬é€‰å–æœ€é•¿è¢«æ¥å—çš„å‰ç¼€ä½œä¸ºä¸‹ä¸€æ­¥è§£ç ç»“æœã€‚

### 7.4 Medusa çš„ç¼ºç‚¹

æ¯ä¸ª Medusa Head æ˜¯ç‹¬ç«‹æ‰§è¡Œçš„ï¼Œå³â€œé¢„æµ‹ä¸‹ä¸‹ä¸ª  tokenâ€ä¸ä¼šä¾èµ–äºâ€œä¸‹ä¸€ä¸ª tokenâ€ çš„é¢„æµ‹ç»“æœï¼Œç¼ºä¹åºåˆ—é—´çš„ä¾èµ–æ€§ï¼Œå¯¼è‡´ç”Ÿæˆæ•ˆæœä¸ä½³ã€è‰ç¨¿æ¥å—ç‡è¾ƒä½ã€‚


## 8 EAGLE

> è®ºæ–‡ï¼š
> EAGLE: Speculative Sampling Requires Rethinking Feature Uncertaintyï¼šhttps://arxiv.org/pdf/2401.15077
>
> EAGLE-2: Faster Inference of Language Models with Dynamic Draft Treesï¼šhttps://arxiv.org/pdf/2406.16858
>
> EAGLE-3: Scaling up Inference Acceleration of Large Language
Models via Training-Time Testï¼šhttps://arxiv.org/pdf/2503.01840
> 
> Githubï¼šhttps://github.com/SafeAILab/EAGLE

EAGLEï¼ˆExtrapolation Algorithm for Greater Language-model Efficiencyï¼‰æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¨æµ‹é‡‡æ ·æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- åœ¨ç‰¹å¾å±‚çº§è€Œéä¼ ç»Ÿçš„ token å±‚çº§è¿›è¡Œè‡ªå›å½’é¢„æµ‹ã€‚ç‰¹å¾åºåˆ—æ¯” token åºåˆ—æ›´å…·è§„å¾‹æ€§ï¼Œä½¿å¾—é¢„æµ‹æ›´ä¸ºç®€å•æœ‰æ•ˆã€‚
- é€šè¿‡å¼•å…¥æå‰ä¸€æ­¥çš„ token åºåˆ—ï¼Œè§£å†³äº†ç‰¹å¾é¢„æµ‹ä¸­çš„ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œä»è€Œæå‡é¢„æµ‹çš„å‡†ç¡®æ€§å’Œè‰ç¨¿ç”Ÿæˆè´¨é‡ã€‚
- è¯¥æ–¹æ³•æ— éœ€å¯¹ç›®æ ‡ LLM è¿›è¡Œå¾®è°ƒï¼Œä¿è¯ç”Ÿæˆæ–‡æœ¬çš„åˆ†å¸ƒä¸ä¼ ç»Ÿè‡ªå›å½’è§£ç ä¸€è‡´ï¼Œå®ç°æ— æŸåŠ é€Ÿã€‚

EAGLE ç»ç¬¬ä¸‰æ–¹è¯„ä¼°è®¤è¯ï¼Œæ˜¯ç›®å‰æœ€å¿«çš„ Speculative Decoding æ–¹æ³•ï¼š

- æ¯”å¸¸è§„ Speculative Decoding å¿« 3 å€ï¼ˆåœ¨ 13B æ¨¡å‹ä¸Šï¼‰ï¼›
- æ¯” Lookahead å¿« 2 å€ï¼ˆåœ¨ 13B æ¨¡å‹ä¸Šï¼‰ï¼›
- æ¯” Medusa å¿« 1.6 å€ï¼ˆåœ¨ 13B æ¨¡å‹ä¸Šï¼‰ï¼›

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221405754.gif)

åœ¨ vLLM ä¸­ï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹å¼å¯ç”¨ EAGLEã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒEAGLE çš„è‰ç¨¿æ¨¡å‹éœ€åœ¨**ä¸å¯ç”¨å¼ é‡å¹¶è¡Œ**çš„æ¨¡å¼ä¸‹è¿è¡Œï¼Œè€Œç›®æ ‡æ¨¡å‹åˆ™å¯ä»¥æ­£å¸¸ä½¿ç”¨å¼ é‡å¹¶è¡Œä»¥æå‡æ¨ç†æ•ˆç‡ã€‚

```python
from vllm import LLM, SamplingParams

prompts = [
    "The future of AI is",
]
sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

llm = LLM(
    model="meta-llama/Meta-Llama-3-8B-Instruct",
    tensor_parallel_size=4, # å¼ é‡å¹¶è¡Œ
    speculative_config={
        "model": "yuhuili/EAGLE-LLaMA3-Instruct-8B",
        "draft_tensor_parallel_size": 1, # æ— å¼ é‡å¹¶è¡Œ
    },
)

outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f"Prompt: {prompt!r}, Generated text: {generated_text!r}")
```

### 8.1 æ ¸å¿ƒæ€è·¯

EAGLE çš„ä½œè€…æå‡ºäº†ä¸¤ä¸ªæ ¸å¿ƒè§‚ç‚¹ï¼š

**æ ¸å¿ƒè§‚ç‚¹ä¸€ï¼šåœ¨ç‰¹å¾å±‚è¿›è¡Œè‡ªå›å½’æ¯”åœ¨ token å±‚è¿›è¡Œè‡ªå›å½’æ›´ç®€å•**

- **è§£é‡Š**ï¼šè®ºæ–‡ä¸­çš„ã€Œç‰¹å¾ã€æŒ‡çš„æ˜¯ LLM å€’æ•°ç¬¬äºŒå±‚çš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯åœ¨è¿›å…¥ LM Head ä¹‹å‰çš„éšè—çŠ¶æ€ (hidden state)ã€‚ç›¸æ¯”äº token åºåˆ—ï¼Œç‰¹å¾åºåˆ—å…·æœ‰æ›´å¼ºçš„è§„å¾‹æ€§ã€‚
- **æ–¹æ¡ˆ**ï¼šé‡‡ç”¨ä¸€ä¸ªè½»é‡çº§çš„è‡ªå›å½’æ¨¡å‹æ¥é¢„æµ‹ç›®æ ‡æ¨¡å‹çš„ç‰¹å¾åºåˆ—ï¼Œè€Œéç›´æ¥é¢„æµ‹ tokenã€‚é¢„æµ‹å‡ºçš„ç‰¹å¾å†é€šè¿‡ç›®æ ‡æ¨¡å‹çš„ LM Head è½¬æ¢ä¸º token æ¦‚ç‡åˆ†å¸ƒï¼Œç”¨äºåç»­é‡‡æ ·ç”Ÿæˆã€‚è¿™ç§æ–¹æ³•æ¯”ç›´æ¥é¢„æµ‹ token æ›´å®¹æ˜“ï¼Œä¸”æ•ˆæœæ›´å¥½ã€‚

**æ ¸å¿ƒè§‚ç‚¹äºŒï¼šé‡‡æ ·è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§é™åˆ¶äº†ç‰¹å¾é¢„æµ‹çš„æ€§èƒ½**

- **è§£é‡Š**ï¼šåœ¨æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒLLM çš„è¾“å‡ºæ˜¯å¸¦æœ‰éšæœºæ€§çš„ï¼Œå› ä¸º LLM ä¼šå¯¹ token çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·ã€‚è¿™ç§éšæœºæ€§å¯¼è‡´ç‰¹å¾åºåˆ—çš„é¢„æµ‹å˜å¾—ä¸ç¡®å®šã€‚ä¾‹å¦‚ï¼Œç»™å®šç›¸åŒçš„è¾“å…¥ã€ŒIã€ï¼Œæ¥ä¸‹æ¥å¯èƒ½å‡ºç°ã€Œalwaysã€æˆ–è€…ã€Œamã€ï¼Œè¿™å°±å¯¼è‡´äº†ç‰¹å¾é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221606655.png)

- **æ–¹æ¡ˆ**ï¼šEAGLE é€šè¿‡å¼•å…¥ä¸€ä¸ªæ—¶é—´æ­¥é•¿æå‰çš„ token åºåˆ—æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨é¢„æµ‹å½“å‰ç‰¹å¾æ—¶ï¼Œä¸ä»…è€ƒè™‘ä¹‹å‰çš„ç‰¹å¾åºåˆ—ï¼Œè¿˜è€ƒè™‘ä¹‹å‰å·²ç»é‡‡æ ·çš„ token åºåˆ—ï¼Œä»è€Œå‡å°‘ç‰¹å¾é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚ä¸‹å›¾è¡¨ç¤ºï¼Œé€šè¿‡è§£å†³è¿™ä¸ªä¸ç¡®å®šæ€§é—®é¢˜ï¼ŒEAGLE çš„åŠ é€Ÿæ¯”ä» 1.9 å€è¿›ä¸€æ­¥æå‡åˆ° 2.8 å€ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221550390.png)

### 8.2 å®ç°ç»†èŠ‚

EAGLE çš„æ•´ä½“æ¡†æ¶å¦‚ä¸‹ï¼š

**è‰ç¨¿é˜¶æ®µï¼ˆDrafting Phaseï¼‰ï¼š**

- **è¾“å…¥ï¼š** å‰ä¸€ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾åºåˆ—ï¼Œä»¥åŠæå‰ä¸€æ­¥çš„ token åºåˆ—ã€‚
- **å¤„ç†æµç¨‹ï¼š**

  - å°† token åºåˆ—è½¬æ¢ä¸ºå¯¹åº”çš„ embedding å‘é‡åºåˆ—ã€‚
  - å°† embedding åºåˆ—ä¸ç‰¹å¾åºåˆ—åœ¨ç»´åº¦ä¸Šæ‹¼æ¥ã€‚
  - ä½¿ç”¨ä¸€ä¸ªè‡ªå›å½’å¤´ (Autoregression Head) æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªç‰¹å¾ã€‚
  - ä½¿ç”¨ LM Head å°†è¯¥ç‰¹å¾æ˜ å°„ä¸º token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶ä»ä¸­é‡‡æ ·å‡ºä¸‹ä¸€ä¸ª tokenã€‚
  - å°†é¢„æµ‹å¾—åˆ°çš„ç‰¹å¾ä¸é‡‡æ ·çš„ token æ·»åŠ è‡³è¾“å…¥åºåˆ—ä¸­ï¼Œç»§ç»­ä¸‹ä¸€è½®é¢„æµ‹ã€‚
- **è¾“å‡ºï¼š** ä¸€æ£µç”±å¤šä¸ªå€™é€‰ token æ„æˆçš„è‰ç¨¿æ ‘ï¼ˆdraft treeï¼‰ã€‚

**éªŒè¯é˜¶æ®µï¼ˆVerification Phaseï¼‰ï¼š**

- **è¾“å…¥ï¼š** è‰ç¨¿æ ‘ã€‚
- **å¤„ç†æµç¨‹ï¼š** ä½¿ç”¨ç›®æ ‡ LLM å¯¹è‰ç¨¿æ ‘ä¸­çš„ token é€ä¸€è¿›è¡ŒéªŒè¯ï¼Œåˆ¤æ–­å…¶æ˜¯å¦ç¬¦åˆåŸå§‹æ¨¡å‹çš„åˆ†å¸ƒã€‚
- **è¾“å‡ºï¼š** æœ€ç»ˆè¢«æ¥å—çš„ token åºåˆ—ï¼Œä½œä¸ºæ¨¡å‹è¾“å‡ºçš„ä¸€éƒ¨åˆ†ã€‚

ä¸‹å›¾å±•ç¤ºäº† EAGLE å¦‚ä½•é€šè¿‡ç‰¹å¾å±‚çº§çš„è‡ªå›å½’æ¨¡å‹é«˜æ•ˆç”Ÿæˆè‰ç¨¿ token åºåˆ—ã€‚æ•´ä¸ª Draft Modelï¼ˆè‰ç¨¿æ¨¡å‹ï¼‰ä¸»è¦ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼š**Embedding å±‚**ã€**Autoregression Head**ã€**LM Head**ã€‚å…¶ä¸­ï¼ŒEmbedding å’Œ LM Head éƒ½å¤ç”¨ç›®æ ‡ LLM çš„å‚æ•°ï¼Œæ— éœ€è®­ç»ƒï¼›å”¯ä¸€éœ€è¦è®­ç»ƒçš„æ˜¯ Autoregression Headï¼Œç”±ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆFCï¼‰å’Œä¸€ä¸ª decoder å±‚ç»„æˆã€‚

æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š

1. å‡è®¾å½“å‰å·²ç”Ÿæˆçš„ token ä¸º `"How"`, `"can"`, `"I"`ã€‚ä»åŸå§‹ LLM ä¸­å–å‡º token `"How"` å’Œ `"can"` åœ¨æœ€åä¸€å±‚çš„è¾“å‡ºç‰¹å¾å‘é‡ï¼Œåˆ†åˆ«è®°ä½œ $f_{\text{how}}$ã€$f_{\text{can}}$ï¼Œä»¥åŠ token `"can"` å’Œ `"I"` åœ¨è¾“å…¥ç«¯çš„ embedding å‘é‡ï¼Œåˆ†åˆ«ä¸º $e_{\text{can}}$ã€$e_{\text{I}}$ã€‚å°† $f_{\text{how}}$ ä¸ $e_{\text{can}}$ æ‹¼æ¥ï¼Œ$f_{\text{can}}$ ä¸ $e_{\text{I}}$ æ‹¼æ¥ï¼Œæ„æˆè¾“å…¥åºåˆ—ã€‚

2. æ‹¼æ¥åçš„åºåˆ—è¾“å…¥åˆ° Autoregression Headï¼Œç»è¿‡é™ç»´å’Œè§£ç å™¨å¤„ç†ï¼Œé¢„æµ‹å‡º token `"I"` çš„ç‰¹å¾å‘é‡ $f_{\text{I}}$ã€‚ç„¶åå°† $f_{\text{I}}$ è¾“å…¥åˆ°ç›®æ ‡ LLM çš„ LM Headï¼Œå¾—åˆ°ä¸‹ä¸€ä¸ª token çš„åˆ†å¸ƒï¼Œå¹¶ä»ä¸­é‡‡æ ·å‡º tokenï¼Œä¾‹å¦‚ `"make"` æˆ– `"help"`ã€‚

3. å°†é‡‡æ ·å¾—åˆ°çš„æ–° tokenï¼ˆå¦‚ `"make"` æˆ– `"help"`ï¼‰é€å…¥ä¸‹ä¸€è½® forwardï¼Œæå–å…¶ embedding å‘é‡ï¼ˆå¦‚ $e_{\text{make}}$ã€$e_{\text{help}}$ï¼‰ï¼Œä¸ä¸Šä¸€è½®çš„é¢„æµ‹ç‰¹å¾ $f_{\text{I}}$ æ‹¼æ¥ï¼Œä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ï¼Œç»§ç»­é¢„æµ‹ä¸‹ä¸€æ­¥çš„ç‰¹å¾ï¼ˆå¦‚ $f_{\text{make}}$ã€$f_{\text{help}}$ï¼‰ï¼Œå†ç”± LM Head æ˜ å°„ä¸º tokenï¼ˆå¦‚ `"a"`ã€`"our"` æˆ– `"with"`ã€`"you"`ï¼‰ã€‚

4. æ¯è½® forward å¹¶éåªé¢„æµ‹ä¸€ä¸ª tokenï¼Œè€Œæ˜¯åŸºäºå½“å‰æ‰€æœ‰è·¯å¾„å¹¶è¡Œæ‰©å±•å¤šä¸ªåˆ†æ”¯ã€‚ä¾‹å¦‚ï¼š`"make"` é¢„æµ‹å‡º `"a"` æˆ– `"our"`ï¼Œ`"help"` é¢„æµ‹å‡º `"with"` æˆ– `"you"`ã€‚ç¬¬ä¸‰è½®ç»§ç»­æ‰©å±•ä¸º `"the"`ã€`"your"`ã€`"to"`ã€`"feel"`ï¼Œå½¢æˆä¸€æ£µ token è‰ç¨¿æ ‘ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221355255.png)

> è¡¥å……ä¸€ç‚¹ï¼Œç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­æ— æ³•åŠ é€Ÿï¼Œå› ä¸ºéœ€è¦é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­æ‰èƒ½å¾—åˆ°åç»­ EAGLE æ‰€éœ€è¦çš„ç‰¹å¾ã€‚

ä¸ºäº†ä¸€æ¬¡éªŒè¯å¤šä¸ªåºåˆ—ï¼ŒEAGLE é‡‡ç”¨äº† Tree Attention æ¥ç”Ÿæˆæ ‘çŠ¶ç»“æ„çš„è‰ç¨¿ï¼Œè¿™æ ·å¯ä»¥åœ¨ä¸€ä¸ªå‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç”Ÿæˆå¤šä¸ª tokenã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221525233.png)

### 8.3 Speculative Samplingã€Lookaheadã€Medusaã€EAGLE å¯¹æ¯”

EAGLE è®ºæ–‡ä¸­ç”¨ä¸‹å›¾å¯¹æ¯”äº† Speculative Samplingã€Lookaheadã€Medusaã€EAGLE ä¸åŒæ–¹æ³•ç”Ÿæˆè‰ç¨¿çš„å¯¹æ¯”ã€‚

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202506221355726.png)

- **Speculative Sampling**ï¼šä½¿ç”¨ä¸€ä¸ªè¾ƒå°çš„è‰ç¨¿æ¨¡å‹å¿«é€Ÿç”Ÿæˆå¤šä¸ª tokenï¼Œç„¶åç”±ç›®æ ‡ LLM å¯¹è¿™äº› token å¹¶è¡ŒéªŒè¯ã€‚è¯¥æ–¹æ³•ä¾èµ–è‰ç¨¿æ¨¡å‹çš„è´¨é‡ï¼Œè‹¥è‰ç¨¿ä¸ä½³ï¼ŒéªŒè¯ä»£ä»·é«˜ï¼Œæ•´ä½“æé€Ÿæœ‰é™ã€‚

- **Lookahead**ï¼šåˆ©ç”¨ n-gram æˆ– Jacobi ç­‰å¯å‘å¼ç­–ç•¥ï¼ŒåŸºäºå·²ç”Ÿæˆçš„ token æ¨æµ‹æœªæ¥ tokenã€‚è¯¥æ–¹æ³•æ— éœ€å¼•å…¥æ–°æ¨¡å‹ï¼Œå»¶è¿Ÿä½ï¼Œä½†è‰ç¨¿è´¨é‡è¾ƒå·®ï¼Œé€šå¸¸ä»…é€‚ç”¨äºè´ªå©ªè§£ç åœºæ™¯ã€‚

- **Medusa**ï¼šé€šè¿‡å¤šä¸ª MLP Headï¼Œå¯¹ç›®æ ‡ LLM å€’æ•°ç¬¬äºŒå±‚çš„éšè—ç‰¹å¾ï¼ˆsecond-to-top-layer featureï¼‰è¿›è¡Œå¹¶è¡Œé¢„æµ‹ï¼Œç”Ÿæˆå¤šä¸ªå€™é€‰ tokenã€‚ä¾‹å¦‚ä½¿ç”¨ fâ‚‚ åŒæ—¶é¢„æµ‹ tâ‚„ å’Œ tâ‚…ã€‚å°½ç®¡å…·å¤‡å¹¶è¡Œç”Ÿæˆèƒ½åŠ›ï¼Œä½†è¯¥æ–¹æ³•æ— æ³•æ•æ‰ token é—´çš„ä¸Šä¸‹æ–‡ä¾èµ–åŠ¨æ€ï¼Œå¯¼è‡´ç”Ÿæˆåˆ†å¸ƒä¸ç›®æ ‡ LLM åç¦»ï¼Œå°¤ä»¥éè´ªå©ªé‡‡æ ·åœºæ™¯ä¸‹æœ€ä¸ºæ˜æ˜¾ã€‚

- **EAGLE**ï¼šEAGLE åˆ›æ–°æ€§åœ°å°†æŠ•æœºè§£ç å‰ç§»è‡³ç‰¹å¾å±‚ï¼Œä½¿ç”¨ç›®æ ‡æ¨¡å‹è‡ªèº«è¾“å‡ºçš„éšè—ç‰¹å¾ä½œä¸ºè‰ç¨¿æ¨¡å‹è¾“å…¥ï¼Œè¿›è¡Œç‰¹å¾å±‚çº§çš„è‡ªå›å½’é¢„æµ‹ï¼ˆAutoregressive Decodingï¼‰ã€‚è‰ç¨¿æ¨¡å‹ä¸ç›®æ ‡æ¨¡å‹å…±äº« embedding å±‚ä¸ LM Headï¼Œä»…æ–°å¢ä¸€ä¸ªè½»é‡çº§çš„ Auto-regression Headã€‚å…·ä½“è€Œè¨€ï¼Œå¦‚å›¾æ‰€ç¤ºï¼ŒEAGLE å°† `(fâ‚, eâ‚œâ‚‚)` ä¸ `(fâ‚‚, eâ‚œâ‚ƒ)` æ‹¼æ¥åè¾“å…¥ Auto-regression Head é¢„æµ‹å‡º `fâ‚ƒ`ï¼Œå†é€šè¿‡ `LM Head(fâ‚ƒ)` å¾—åˆ° token `tâ‚„`ã€‚

## 9 æ€»ç»“

æ¨æµ‹è§£ç ï¼ˆSpeculative Decodingï¼‰æ˜¯ä¸€ç§é€šè¿‡é¢„ç”Ÿæˆå¤šä¸ªå€™é€‰ token å¹¶å¹¶è¡ŒéªŒè¯ä»¥åŠ é€Ÿ LLM æ¨ç†çš„æŠ€æœ¯ï¼Œæ—¨åœ¨çªç ´ä¼ ç»Ÿè‡ªå›å½’è§£ç ä¸­çš„å†…å­˜å¸¦å®½ç“¶é¢ˆã€‚æœ¬æ–‡ç³»ç»Ÿä»‹ç»äº†ä»æ—©æœŸè‰ç¨¿æ¨¡å‹æ–¹æ³•ã€Prompt Lookup åˆ° Jacobi Decodingã€Lookaheadã€Medusaï¼Œå†åˆ°å½“å‰é€Ÿåº¦é¢†å…ˆçš„ EAGLE ç­‰å¤šç§æ–¹æ¡ˆã€‚å°½ç®¡å„æ–¹æ¡ˆå®ç°æ–¹å¼ä¸åŒï¼Œå®ƒä»¬çš„å…±åŒç›®æ ‡æ˜¯æå‡è§£ç æ•ˆç‡ã€é™ä½æ¨ç†å»¶è¿Ÿï¼ŒåŒæ—¶ä¿è¯ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€‚

## 10 é™„å½•

### 10.1 ä»€ä¹ˆæ˜¯ Logitsï¼Ÿ

åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­ï¼Œlogits æŒ‡çš„æ˜¯æ¨¡å‹è¾“å‡ºå±‚çš„åŸå§‹å¾—åˆ†å‘é‡ï¼Œè¿™äº›æ•°å€¼æ˜¯æœªç»è¿‡å½’ä¸€åŒ–å¤„ç†çš„å®æ•°ï¼Œè¡¨ç¤ºæ¨¡å‹å¯¹æ¯ä¸ª token ä½œä¸ºä¸‹ä¸€ä¸ªç”Ÿæˆ token çš„â€œç½®ä¿¡åº¦â€æˆ–â€œå€¾å‘æ€§â€ã€‚å…·ä½“æ¥è¯´ï¼š

- logits æ˜¯æ¨¡å‹æœ€åä¸€å±‚ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªçº¿æ€§å˜æ¢å±‚ï¼‰çš„è¾“å‡ºï¼Œå‘é‡çš„æ¯ä¸ªå…ƒç´ å¯¹åº”è¯è¡¨ä¸­ä¸€ä¸ª token çš„å¾—åˆ†ï¼Œè¿™äº›å¾—åˆ†å¯ä»¥æ˜¯æ­£æ•°æˆ–è´Ÿæ•°ï¼ŒèŒƒå›´ä»è´Ÿæ— ç©·åˆ°æ­£æ— ç©·ã€‚è¯è¡¨æ˜¯è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶å®šä¹‰å¥½çš„ï¼ŒåŒ…å«æ¨¡å‹å¯èƒ½ç”Ÿæˆçš„æ‰€æœ‰ tokenã€‚å‡è®¾å½“å‰çš„ä¸Šä¸‹æ–‡æ˜¯ "This apple"ï¼Œè¦é¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼š

```bash
# å‡è®¾è¯è¡¨ï¼š
vocab = ["This", "apple", "is", "very", "delicious", "bad", "today"]

# æ¨¡å‹è¾“å‡ºçš„ logitsï¼ˆä¸€ä¸ªå‘é‡ï¼Œå¯¹åº”è¯è¡¨ä¸­æ¯ä¸ª token çš„å¾—åˆ†ï¼‰ï¼š
logits = [1.8, 2.0, 2.5, 1.2, 0.5, 0.1, -0.7]
```

- è¿™äº›å¾—åˆ†æœ¬èº«ä¸æ˜¯æ¦‚ç‡ï¼Œéœ€è¦é€šè¿‡ softmax å‡½æ•°å°† logits è½¬æ¢æˆæ¦‚ç‡åˆ†å¸ƒï¼Œæ¦‚ç‡å€¼ä»‹äº 0 å’Œ 1 ä¹‹é—´ä¸”æ€»å’Œä¸º 1ï¼Œä»è€Œç¡®å®šç”Ÿæˆä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡ã€‚softmax å…¬å¼å¦‚ä¸‹ï¼š

$$
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}
$$

è®¡ç®—æ¯ä¸ªå…ƒç´ çš„æŒ‡æ•°ï¼š

$$
\exp(\text{logits}) = [e^{1.8},\ e^{2.0},\ e^{2.5},\ e^{1.2},\ e^{0.5},\ e^{0.1},\ e^{-0.7}]
\approx [6.05,\ 7.39,\ 12.18,\ 3.32,\ 1.65,\ 1.11,\ 0.50]
$$

æ±‚æŒ‡æ•°å’Œï¼š

$$
\sum_{i=1}^{7} e^{x_i} = 6.05 + 7.39 + 12.18 + 3.32 + 1.65 + 1.11 + 0.50 = 32.20
$$

æœ€ç»ˆ softmax æ¦‚ç‡ä¸ºï¼š

$$
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}} \Rightarrow
\left[
\frac{6.05}{32.20},\ 
\frac{7.39}{32.20},\ 
\frac{12.18}{32.20},\ 
\frac{3.32}{32.20},\ 
\frac{1.65}{32.20},\ 
\frac{1.11}{32.20},\ 
\frac{0.50}{32.20}
\right]
\approx [0.188,\ 0.229,\ 0.378,\ 0.103,\ 0.051,\ 0.034,\ 0.016]
$$

- logits å€¼è¶Šå¤§ï¼Œè¡¨ç¤ºæ¨¡å‹è®¤ä¸ºè¯¥è¯ä½œä¸ºä¸‹ä¸€ä¸ªè¯çš„å¯èƒ½æ€§è¶Šé«˜ï¼›å€¼è¶Šå°ï¼Œå¯èƒ½æ€§è¶Šä½ã€‚

| Token         | Logit | Softmaxæ¦‚ç‡   |
| ------------- | ----- | ----------- |
| `"This"`      | 1.8   | 0.188       |
| `"apple"`     | 2.0   | 0.229       |
| `"is"`        | 2.5   | 0.378 âœ…ï¼ˆæœ€é«˜ï¼‰ |
| `"very"`      | 1.2   | 0.103       |
| `"delicious"` | 0.5   | 0.051       |
| `"bad"`       | 0.1   | 0.034       |
| `"today"`     | -0.7  | 0.016       |

æ€»çš„æ¥è¯´ï¼Œlogits æ˜¯ LLM ä¸­é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„â€œæœªå½’ä¸€åŒ–æ¦‚ç‡å¾—åˆ†â€ï¼Œæ˜¯ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å…³é”®ä¸­é—´è¡¨ç¤ºï¼Œå†³å®šäº†æ¨¡å‹å¦‚ä½•é€‰æ‹©ä¸‹ä¸€ä¸ªè¾“å‡º tokenã€‚**logits çš„é•¿åº¦ç­‰äºè¯è¡¨ï¼ˆvocabularyï¼‰çš„å¤§å°ã€‚**

### 10.2 é›…å¯æ¯”è¿­ä»£æ³•ï¼ˆJacobi methodï¼‰

é›…å¯æ¯”è¿­ä»£æ³•ï¼ˆJacobi methodï¼‰æ˜¯ä¸€ç§ç”¨äºæ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„çš„è¿­ä»£ç®—æ³•ã€‚å®ƒé€šè¿‡è¿­ä»£åœ°æ›´æ–°æ–¹ç¨‹ç»„ä¸­æ¯ä¸ªæœªçŸ¥æ•°çš„è¿‘ä¼¼å€¼ï¼Œé€æ­¥é€¼è¿‘çœŸå®çš„è§£ã€‚è¿™ç§æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºå¤§å‹ã€ç¨€ç–çš„çº¿æ€§æ–¹ç¨‹ç»„ã€‚

é›…å¯æ¯”è¿­ä»£æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†å¤æ‚çš„çº¿æ€§æ–¹ç¨‹ç»„åˆ†è§£ä¸ºç®€å•çš„å¯¹è§’éƒ¨åˆ†å’Œéå¯¹è§’éƒ¨åˆ†ï¼Œç„¶ååˆ©ç”¨å½“å‰è¿­ä»£å€¼è®¡ç®—ä¸‹ä¸€æ¬¡è¿­ä»£å€¼ï¼Œå®ç°å¹¶è¡Œè®¡ç®—ã€‚å½“çŸ©é˜µæ»¡è¶³å¯¹è§’å ä¼˜æ¡ä»¶æ—¶ï¼ˆå³å¯¹è§’å…ƒç´ çš„ç»å¯¹å€¼å¤§äºåŒè¡Œå…¶ä»–å…ƒç´ ç»å¯¹å€¼ä¹‹å’Œï¼‰ï¼Œä¸è®ºåˆå§‹å€¼å¦‚ä½•é€‰å–ï¼Œè¿­ä»£è¿‡ç¨‹éƒ½ä¼šæ”¶æ•›åˆ°å”¯ä¸€è§£ï¼Œå› ä¸ºæ¯æ¬¡è¿­ä»£éƒ½ä¼šä½¿è¯¯å·®é€æ­¥å‡å°ã€‚

#### 10.2.1 å…¬å¼

ç»™å®šä¸€ä¸ª $n \times n$ çš„çº¿æ€§æ–¹ç¨‹ç»„ï¼š

$$
Ax = b
$$

å…¶ä¸­ï¼š

$$
A = \begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{bmatrix}, \quad
x = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}, \quad
b = \begin{bmatrix}
b_1 \\
b_2 \\
\vdots \\
b_n
\end{bmatrix}
$$

å°†çŸ©é˜µ $A$ åˆ†è§£ä¸ºå¯¹è§’çŸ©é˜µéƒ¨åˆ† $D$ ä¸å…¶ä½™éƒ¨åˆ† $R$ï¼š

$$
A = D + R \quad å…¶ä¸­ \quad D = \begin{bmatrix}
a_{11} & 0 & \cdots & 0 \\
0 & a_{22} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & a_{nn}
\end{bmatrix}, \quad
R = \begin{bmatrix}
0 & a_{12} & \cdots & a_{1n} \\
a_{21} & 0 & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & 0
\end{bmatrix}
$$

æ­¤æ—¶çº¿æ€§æ–¹ç¨‹å¯ä»¥å˜å½¢ä¸ºï¼š

$$
Dx = b - Rx
$$

å³å°†åŸæ–¹ç¨‹æ‹†æˆä¸¤éƒ¨åˆ†ï¼Œæ–¹ä¾¿åˆ©ç”¨å·²çŸ¥çš„ $x$ å»è¿­ä»£æ±‚è§£ã€‚

**è¿­ä»£è¡¨è¾¾å¼ï¼š**

$$
x^{(k+1)} = D^{-1}(b - Rx^{(k)})
$$

è¡¨ç¤ºä½¿ç”¨å½“å‰ç¬¬ $k$ æ¬¡è¿­ä»£çš„ç»“æœï¼Œå»è®¡ç®—ç¬¬ $k+1$ æ¬¡çš„è¿‘ä¼¼è§£ã€‚

**ä¹Ÿå¯ä»¥å†™ä¸ºå•å…ƒç´ æ›´æ–°å…¬å¼ï¼Œå¯ä»¥ç›´æ¥çœ‹åˆ°ç¬¬ $i$ ä¸ªæœªçŸ¥é‡å¦‚ä½•å—å…¶ä»–åˆ†é‡å½±å“ï¼š**

$$
x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j \neq i} a_{ij} x_j^{(k)} \right), \quad i = 1, 2, \ldots, n
$$

#### 10.2.2 å…·ä½“ä¾‹å­

ä»¥ä¸€ä¸ª $3 \times 3$ çº¿æ€§æ–¹ç¨‹ç»„ä¸ºä¾‹ï¼š

$$
\begin{cases}
4x_1 + x_2 + x_3 = 6 \\
x_1 + 5x_2 + x_3 = 7 \\
x_1 + x_2 + 6x_3 = 8
\end{cases}
$$

ç”¨çŸ©é˜µå½¢å¼è¡¨ç¤ºä¸ºï¼š

$$
A = \begin{bmatrix} 
4 & 1 & 1 \\ 
1 & 5 & 1 \\ 
1 & 1 & 6 
\end{bmatrix}, \quad
b = \begin{bmatrix} 6 \\ 7 \\ 8 \end{bmatrix}
$$

åº”ç”¨é›…å¯æ¯”è¿­ä»£æ³•çš„å•å…ƒç´ æ›´æ–°å…¬å¼ï¼š

å¯¹äº $x_1$ï¼š

$$
x_1^{(k+1)} = \frac{1}{a_{11}} \left( b_1 - \sum_{j \ne 1} a_{1j} x_j^{(k)} \right)
= \frac{1}{4} \left( 6 - 1 \cdot x_2^{(k)} - 1 \cdot x_3^{(k)} \right)
$$

å¯¹äº $x_2$ï¼š

$$
x_2^{(k+1)} = \frac{1}{a_{22}} \left( b_2 - \sum_{j \ne 2} a_{2j} x_j^{(k)} \right)
= \frac{1}{5} \left( 7 - 1 \cdot x_1^{(k)} - 1 \cdot x_3^{(k)} \right)
$$

å¯¹äº $x_3$ï¼š

$$
x_3^{(k+1)} = \frac{1}{a_{33}} \left( b_3 - \sum_{j \ne 3} a_{3j} x_j^{(k)} \right)
= \frac{1}{6} \left( 8 - 1 \cdot x_1^{(k)} - 1 \cdot x_2^{(k)} \right)
$$

å‡è®¾åˆå§‹å€¼ä¸ºï¼š

$$
x^{(0)} = 
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
$$

è¿›è¡Œè¿­ä»£è®¡ç®—ï¼š

ç¬¬ä¸€æ¬¡è¿­ä»£ï¼š

$$
x_1^{(1)} = \frac{1}{4}(6 - 0 - 0) = 1.5
$$

$$
x_2^{(1)} = \frac{1}{5}(7 - 0 - 0) = 1.4
$$

$$
x_3^{(1)} = \frac{1}{6}(8 - 0 - 0) = 1.333
$$

æ‰€ä»¥ï¼š

$$
x^{(1)} = 
\begin{bmatrix}
1.5 \\
1.4 \\
1.333
\end{bmatrix}
$$

ç¬¬äºŒæ¬¡è¿­ä»£ï¼š

$$
x_1^{(2)} = \frac{1}{4}(6 - 1.4 - 1.333) = \frac{3.267}{4} \approx 0.817
$$

$$
x_2^{(2)} = \frac{1}{5}(7 - 1.5 - 1.333) = \frac{4.167}{5} \approx 0.833
$$

$$
x_3^{(2)} = \frac{1}{6}(8 - 1.5 - 1.4) = \frac{5.1}{6} \approx 0.85
$$

æ‰€ä»¥ï¼š

$$
x^{(2)} = 
\begin{bmatrix}
0.817 \\
0.833 \\
0.85
\end{bmatrix}
$$

ç»§ç»­è¿­ä»£ï¼Œæœ€ç»ˆä¼šæ”¶æ•›åˆ°ç²¾ç¡®è§£ï¼š

$$
x = 
\begin{bmatrix}
1 \\
1 \\
1
\end{bmatrix}
$$

å¯ä»¥éªŒè¯ï¼š

$$
\begin{bmatrix}
4 & 1 & 1 \\
1 & 5 & 1 \\
1 & 1 & 6
\end{bmatrix}
\begin{bmatrix}
1 \\
1 \\
1
\end{bmatrix}
\=
\begin{bmatrix}
6 \\
7 \\
8
\end{bmatrix}
$$


è¿™ä¸ªä¾‹å­å±•ç¤ºäº†é›…å¯æ¯”è¿­ä»£æ³•å¦‚ä½•é€šè¿‡åå¤åº”ç”¨å•å…ƒç´ æ›´æ–°å…¬å¼ï¼Œé€æ­¥é€¼è¿‘ä¸‰ç»´çº¿æ€§æ–¹ç¨‹ç»„çš„è§£ã€‚

#### 10.2.3 æ›´é€šä¿—çš„ä¾‹å­

å‡è®¾ä½ ã€å°æ˜ã€å°çº¢ä¸‰äººä¸€èµ·ç©ä¸€ä¸ªçŒœæ•°å­—æ¸¸æˆï¼Œæ¯äººçŒœä¸€ä¸ªæ•°å­—ï¼Œä½†ä½ ä»¬çš„æ•°å­—å¿…é¡»æ»¡è¶³ä»¥ä¸‹è§„åˆ™ï¼š

**ä½ çš„æ•°å­—**ï¼š

$$
x_{\text{ä½ }} = \frac{6 - x_{\text{å°æ˜}} - x_{\text{å°çº¢}}}{4}
$$

**å°æ˜çš„æ•°å­—**ï¼š

$$
x_{\text{å°æ˜}} = \frac{7 - x_{\text{ä½ }} - x_{\text{å°çº¢}}}{5}
$$

**å°çº¢çš„æ•°å­—**ï¼š

$$
x_{\text{å°çº¢}} = \frac{8 - x_{\text{ä½ }} - x_{\text{å°æ˜}}}{6}
$$

ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªäººçš„æ•°å­—éƒ½éœ€è¦å‚è€ƒå¦å¤–ä¸¤ä¸ªäººçš„æ•°å­—ã€‚

**æ¸¸æˆè¿‡ç¨‹ï¼ˆè¯¦ç»†è¿­ä»£ç¤ºä¾‹ï¼‰**

**ç¬¬ 0 è½®ï¼ˆåˆå§‹çŒœæµ‹ï¼‰**

åˆšå¼€å§‹ï¼Œä½ ä»¬éƒ½æ²¡æœ‰å¤´ç»ªï¼Œäºæ˜¯éƒ½ä» 0 å¼€å§‹çŒœï¼š

| ç©å®¶ | çŒœæµ‹æ•°å­— |
| -- | ---- |
| ä½   | 0    |
| å°æ˜ | 0    |
| å°çº¢ | 0    |

**ç¬¬ 1 è½®**

æ¯ä¸ªäººæ ¹æ®ä¸Šè½®å…¶ä»–äººçš„çŒœæµ‹æ›´æ–°è‡ªå·±çš„æ•°å­—ï¼š

**ä½ çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{ä½ }}^{(1)} = \frac{6 - 0 - 0}{4} = 1.5
$$

**å°æ˜çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°æ˜}}^{(1)} = \frac{7 - 0 - 0}{5} = 1.4
$$

**å°çº¢çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°çº¢}}^{(1)} = \frac{8 - 0 - 0}{6} = 1.333
$$

**ç¬¬ 2 è½®**

ç»§ç»­è¿­ä»£ï¼Œç”¨ç¬¬1è½®çš„ç»“æœæ›´æ–°ï¼š

**ä½ çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{ä½ }}^{(2)} = \frac{6 - 1.4 - 1.333}{4} = 0.817
$$

* **å°æ˜çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°æ˜}}^{(2)} = \frac{7 - 1.5 - 1.333}{5} = 0.833
$$

* **å°çº¢çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°çº¢}}^{(2)} = \frac{8 - 1.5 - 1.4}{6} = 0.85
$$

**ç¬¬ 3 è½®**

ç»§ç»­è¿­ä»£ï¼Œç”¨ç¬¬2è½®çš„ç»“æœæ›´æ–°ï¼š

**ä½ çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{ä½ }}^{(3)} = \frac{6 - 0.833 - 0.85}{4} = 1.079
$$

**å°æ˜çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°æ˜}}^{(3)} = \frac{7 - 0.817 - 0.85}{5} = 1.067
$$

**å°çº¢çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°çº¢}}^{(3)} = \frac{8 - 0.817 - 0.833}{6} = 1.058
$$

**ç¬¬ 4 è½®**

ç»§ç»­è¿­ä»£ï¼Œç”¨ç¬¬3è½®çš„ç»“æœæ›´æ–°ï¼š

* **ä½ çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{ä½ }}^{(4)} = \frac{6 - 1.067 - 1.058}{4} = 0.969
$$

* **å°æ˜çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°æ˜}}^{(4)} = \frac{7 - 1.079 - 1.058}{5} = 0.973
$$

* **å°çº¢çš„æ–°æ•°å­—**ï¼š

$$
x_{\text{å°çº¢}}^{(4)} = \frac{8 - 1.079 - 1.067}{6} = 0.976
$$

**æŒç»­è¿›è¡Œè¿­ä»£ï¼ˆç›´åˆ°æ”¶æ•›ï¼‰**

éšç€è¿­ä»£æ¬¡æ•°å¢åŠ ï¼Œä½ ä»¬çš„çŒœæµ‹ä¼šè¶Šæ¥è¶Šç¨³å®šï¼Œæœ€ç»ˆé€æ¸æ”¶æ•›åˆ°ï¼š

| ç©å®¶ | æœ€ç»ˆçŒœæµ‹ï¼ˆè¶‹è¿‘å€¼ï¼‰ |
| -- | --------- |
| ä½   | 1.0       |
| å°æ˜ | 1.0       |
| å°çº¢ | 1.0       |

æ­¤æ—¶ï¼Œä¸‰ä¸ªäººçš„æ•°å­—å‡ ä¹ä¸ä¼šå†å˜åŠ¨ï¼Œæ¸¸æˆå¯ä»¥ç»“æŸã€‚

**ä¸ºä»€ä¹ˆæ¸¸æˆå¯ä»¥æ”¶æ•›åˆ°æ­£ç¡®ç­”æ¡ˆï¼Ÿ**

- **ç›¸äº’ä¾èµ–**ï¼šæ¯ä¸ªäººçš„æ•°å­—å–å†³äºå…¶ä»–äººçš„æ•°å­—ï¼Œç±»ä¼¼äºæ•°å­¦ä¸­çº¿æ€§æ–¹ç¨‹ç»„çš„å˜é‡é—´çš„å…³ç³»ã€‚
- **ä¿¡æ¯ä¼ é€’**ï¼šæ¯è½®è¿­ä»£ï¼Œæ¯ä¸ªäººéƒ½å‚è€ƒäº†ä¸Šä¸€è½®å…¶ä»–äººçš„ç»“æœï¼Œä¸æ–­ä¿®æ­£è‡ªèº«çŒœæµ‹ã€‚
- **å¹¶è¡Œæ›´æ–°**ï¼šæ‰€æœ‰äººéƒ½åŒæ—¶è¿›è¡Œæ›´æ–°ï¼Œè¿™æ­£æ˜¯ Jacobi è¿­ä»£æ³•çš„ç‰¹ç‚¹ä¹‹ä¸€ã€‚
- **å¿…ç„¶æ”¶æ•›**ï¼šç”±äºæ»¡è¶³å¯¹è§’å ä¼˜æ¡ä»¶ï¼Œæ— è®ºåˆå§‹å€¼å¦‚ä½•é€‰æ‹©ï¼Œæœ€ç»ˆéƒ½ä¼šæ”¶æ•›åˆ°ç›¸åŒçš„ç­”æ¡ˆã€‚

è¿™ç§çŒœæ•°å­—æ¸¸æˆä¸ä»…ä»…æ˜¯ä¸ªæ•°å­¦æ¸¸æˆï¼Œè¿˜èƒ½åæ˜ ç°å®ä¸–ç•Œä¸­å¾ˆå¤šåœºæ™¯ï¼Œæ¯”å¦‚ï¼š

- **äº¤é€šç½‘ç»œæµé‡**ï¼šæ¯ä¸ªè·¯å£çš„æµé‡éƒ½ä¼šå—åˆ°ç›¸é‚»è·¯å£çš„å½±å“ï¼Œæœ€ç»ˆå½¢æˆç¨³å®šçš„è½¦æµçŠ¶æ€ã€‚
- **ç»æµå¸‚åœºå‡è¡¡**ï¼šå¸‚åœºä¸­çš„æ¯ä¸ªå‚ä¸è€…çš„è¡Œä¸ºå—åˆ°å…¶ä»–äººçš„è¡Œä¸ºå½±å“ï¼Œç»è¿‡å¤šæ¬¡åšå¼ˆåè¾¾åˆ°å¸‚åœºå‡è¡¡ã€‚

> Jacobi è¿­ä»£æ³•çš„æ ¸å¿ƒï¼Œå°±æ˜¯ä¸æ–­åº”ç”¨ç®€å•çš„**å±€éƒ¨æ›´æ–°è§„åˆ™**ï¼ˆå±€éƒ¨ä¿¡æ¯ï¼‰ï¼Œæœ€ç»ˆè¾¾åˆ°**å…¨å±€å¹³è¡¡çŠ¶æ€**ï¼ˆæ–¹ç¨‹ç»„è§£ï¼‰ã€‚

### 10.3 Jacobi Decoding è¯¦è§£

å‡è®¾ç›®æ ‡è¾“å…¥ï¼š

```
x = ["Alan", "Turing"]
```

æœ€ç»ˆæƒ³ç”Ÿæˆçš„ç†æƒ³ token åºåˆ—æ˜¯ï¼š

```
["who", "was", "a"]
```

**Step 0ï¼šåˆå§‹çŒœæµ‹**

å‡è®¾ç»™å®šä¸€ä¸ªåˆå§‹ä¸å¤ªé è°±çš„åˆå§‹çŒœæµ‹åºåˆ—ï¼š

$$
\mathbf{y}^{(0)} = ["the", "computer", "engineer"]
$$

**Step 1ï¼šæ ¹æ® $\mathbf{y}^{(0)}$ å¹¶è¡Œè®¡ç®— $\mathbf{y}^{(1)}$**

æˆ‘ä»¬æ ¹æ® $\mathbf{y}^{(0)}$ çš„å‰ç¼€ä¾æ¬¡é¢„æµ‹æ¯ä¸ª tokenï¼š

* $y_1^{(1)} = \text{LM}(["Alan", "Turing"]) = \text{"who"}$ âœ… ä¿®æ­£äº†ç¬¬ä¸€ä¸ª token
* $y_2^{(1)} = \text{LM}(["Alan", "Turing", "the"]) = \text{"is"}$ âš ï¸ æ²¡æœ‰ç›´æ¥ä¿®æ­£ä¸º "was"ï¼Œä½†æ¯” "computer" æ›´åˆç†
* $y_3^{(1)} = \text{LM}(["Alan", "Turing", "the", "computer"]) = \text{"pioneer"}$ âŒ ä»æœªå¯¹ï¼Œä½†æ›´ç›¸å…³

å› æ­¤ï¼š

$$
\mathbf{y}^{(1)} = ["who", "is", "pioneer"]
$$

**Step 2ï¼šä½¿ç”¨ $\mathbf{y}^{(1)}$ ç»§ç»­è¿­ä»£**

æ­¤è½®ä¸­ï¼Œæ‰€æœ‰é¢„æµ‹éƒ½åŸºäº $\mathbf{y}^{(1)}$ï¼š

* $y_1^{(2)} = \text{LM}(["Alan", "Turing"]) = \text{"who"}$ âœ… æ”¶æ•›ï¼Œç»§ç»­ä¿æŒ
* $y_2^{(2)} = \text{LM}(["Alan", "Turing", "who"]) = \text{"was"}$ âœ… ä¿®æ­£äº† "is"
* $y_3^{(2)} = \text{LM}(["Alan", "Turing", "who", "is"]) = \text{"a"}$ âœ… è™½ç„¶å‰ç¼€éç›®æ ‡ "was"ï¼Œä½†ä»ç„¶æˆåŠŸé¢„æµ‹å‡ºæ­£ç¡® tokenï¼

å¾—åˆ°ï¼š

$$
\mathbf{y}^{(2)} = ["who", "was", "a"]
$$

ä¸ç›®æ ‡å®Œå…¨ä¸€è‡´ï¼Œæ”¶æ•›ï¼

**æµç¨‹æ€»ç»“ï¼š**

| æ­¥éª¤ | yâ‚  | yâ‚‚       | yâ‚ƒ       | è¯´æ˜        |
| -- | --- | -------- | -------- | --------- |
| yâ° | the | computer | engineer | åˆå§‹çŒœæµ‹ï¼Œå®Œå…¨é”™è¯¯ |
| yÂ¹ | who | is       | pioneer  | ç¬¬ä¸€è½®ï¼Œéƒ¨åˆ†ä¿®æ­£  |
| yÂ² | who | was      | a        | ç¬¬äºŒè½®ï¼Œå®Œå…¨æ”¶æ•›  |

## 11 å‚è€ƒèµ„æ–™

- Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Headsï¼šhttps://sites.google.com/view/medusa-llm
- Speculative Sampling â€” Intuitively and Exhaustively Explainedï¼šhttps://medium.com/intuitively-and-exhaustively-explained/speculative-sampling-intuitively-and-exhaustively-explained-2daca347dbb9
- Logits as Confidence: The Hidden Power AI Engineers Need to Unlock in LLMs and VLMsï¼šhttps://medium.com/@adkananthi/logits-as-confidence-the-hidden-power-ai-engineers-need-to-unlock-in-llms-and-vlms-194d512c31f2
- å¤§æ¨¡å‹æ¨ç†å¦™æ‹›â€”æŠ•æœºé‡‡æ ·ï¼ˆSpeculative Decodingï¼‰ï¼šhttps://zhuanlan.zhihu.com/p/651359908
- æ¢ç§˜Transformerç³»åˆ—ä¹‹ï¼ˆ31ï¼‰--- Medusaï¼šhttps://blog.csdn.net/weixin_47364682/article/details/147569594
- Speculative Decoding and Beyond: A Survey of Speculative Decoding Techniquesï¼šhttps://blog.codingconfessions.com/p/a-selective-survey-of-speculative-decoding
- EAGLE: Extrapolation Algorithm for Greater Language-model Efficiencyï¼šhttps://sites.google.com/view/eagle-llm
- Assisted Generation: a new direction toward low-latency text generationï¼šhttps://huggingface.co/blog/assisted-generation
- [V1][Spec Decode] Ngram Spec Decodeï¼šhttps://github.com/vllm-project/vllm/pull/12193
- apoorvumang/prompt-lookup-decodingï¼šhttps://github.com/apoorvumang/prompt-lookup-decoding
- æ¢ç§˜Transformerç³»åˆ—ä¹‹ï¼ˆ32ï¼‰--- Lookahead Decodingï¼šhttps://www.cnblogs.com/rossiXYZ/p/18859771
- Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Headsï¼šhttps://sites.google.com/view/medusa-llm
- ã€è®ºæ–‡è§£è¯»ã€‘EAGLEï¼šåœ¨ç‰¹å¾å±‚è¿›è¡Œè‡ªå›å½’çš„æŠ•æœºé‡‡æ ·æ¡†æ¶ï¼šhttps://zhuanlan.zhihu.com/p/15955544919
- ä¸‡å­—ç»¼è¿° 10+ ç§ LLM æŠ•æœºé‡‡æ ·æ¨ç†åŠ é€Ÿæ–¹æ¡ˆï¼šhttps://mp.weixin.qq.com/s/PyAKiFzbQNq6w7HmaTnSEw
- EAGLE and EAGLE-2: Lossless Inference Acceleration for LLMs - Hongyang Zhangï¼šhttps://www.youtube.com/watch?v=oXRSorx-Llg
- DeepSeek-V3 MTP å·¥ç¨‹å®ç°æ€è€ƒï¼šhttps://zhuanlan.zhihu.com/p/29082207943
- æ¢ç§˜ Transformerç³»åˆ—ä¹‹ï¼ˆ33ï¼‰--- DeepSeek MTPï¼šhttps://www.cnblogs.com/rossiXYZ/p/18880573
- Accelerating Large Language Models: A Deep Dive into Speculative Decoding and its vLLM Implementationï¼šhttps://medium.com/@abhinaykrishna/accelerating-large-language-models-a-deep-dive-into-speculative-decoding-and-its-vllm-9208e8e6e6c6
- Speculative Decoding è®ºæ–‡é˜…è¯»åˆè®¢æœ¬ï¼šhttps://zhuanlan.zhihu.com/p/684217993
- Andrej Karpathy Xï¼šhttps://x.com/karpathy/status/1697318534555336961
- Lookahead Decoding å›¾æ–‡è¯¦è§£ï¼šhttps://zhuanlan.zhihu.com/p/701015670

## æ¬¢è¿å…³æ³¨

![](https://chengzw258.oss-cn-beijing.aliyuncs.com/Article/202503222156941.png)
