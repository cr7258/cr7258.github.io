---
title: Elasticsearch
author: Se7en
categories:
  - Interview
tags:
  - AI
---


## 为什么模型训练通常需要分布式进行，而分布式模型预测并不常见？

计算模式不同：

- 训练需要各个 worker 保持通信，从而协调统一地更新模型参数。
- 预测中的模型参数是固定的，各个 worker 分别使用只读副本，无需相互通信协调。

## AI 集群规模越大越好？大集群拥有大算力？

集群训练引入通信开销，集群的算力并不是线性增长，增加 GPU 计算节点，并不能线性地提升算力收益。
要想通过 AI 集群提升更多算力，需要优化服务器间通信、拓扑、模型并行、分布式框架等软硬件协同。

对于网络而言，高速、低延迟的网络可以缩短节点间同步梯度的时间，加快训练过程；对于计算而言，降低不必要的计算资源消耗，使计算节点能够专注于训练任务。


## 什么是 Tensor Core？

Tensor Core 是英伟达推出专门用于深度学习和 AI 计算的硬件单元。Tensor Core 的设计旨在加速矩阵乘法运算，这在深度学习中是非常常见的计算操作。Tensor Core 主要有以下特点和优势：

- 并行计算能力：Tensor Core 能够同时处理多个矩阵乘法运算，从而大幅提高计算效率。
- 混合精度计算：Tensor Core 支持混合精度计算，即同时使用浮点 16 位（half-precision）和浮点 32 位（single-precision）数据类型进行计算，以在保证计算精度的同时提高计算速度。
- 高性能计算：Tensor Core 具有非常高的计算性能，能够快速处理大规模的神经网络模型和数据集。
- 节能优势：由于其高效的并行计算和混合精度计算能力，Tensor Core 在相同计算任务下通常能够比传统的计算单元更节能。